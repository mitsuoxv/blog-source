{
  "hash": "23f6bd0e0d3008ed3e871102e7499e55",
  "result": {
    "markdown": "---\ntitle: Assist Prof Narita tests us by his mistakes\nauthor: Mitsuo Shiota\ndate: '2023-06-10'\ndate-modified: '2023-06-14'\ncategories:\n  - economics\n  - Media\n  - R\nknitr: \n  opts_chunk: \n    out.width: '70%'\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dagitty)\n\ntheme_set(theme_light())\n```\n:::\n\n\n## Assist Prof Narita did a meta-analysis on the effectiveness of EBPM\n\n[Assistant Professor Narita of Yale University](https://economics.yale.edu/people/yusuke-narita) wrote an article in [a book on EBPM (Evidence-Based Policy-Making) which was published in Japan in December 2022](https://www.amazon.co.jp/-/en/%E5%A4%A7%E7%AB%B9%E6%96%87%E9%9B%84/dp/429611526X). In his article, he did a meta-analysis on the effectiveness of EBPM by checking whether [RFI (Results First Initiative)](https://www.pewtrusts.org/en/projects/archived-projects/results-first-initiative), which supported states in the U.S. from 2010 to 2023 by EBPM methods and is now concluded, really helped states reduce crimes. From his article, I quote two pages below:\n\n![A part of meta-analysis](images/image0.jpeg)\n\n\"***\" in the right table means p-value is less than 0.01. This table looks too good to be true to me. So I try to reproduce his meta-analysis.\n\n## This is not a natural experiment, contrary to his assertion\n\nHe asserts this is a natural experiment, as some states joined RFI and others didn't.\n\nIf joining states are selected at random by some accidents, it is a natural experiment. In this case states voluntarily joins RFI, so this is not a natural experiment. Z (states' willingness to join RFI) is a confound between X (RFI support) and Y (an outcome) like below. Even if X is associated with Y, it may be caused by Z.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrfi_dag <- dagitty(\"dag{\n  X <- Z -> Y\n  X -> Y\n}\")\n\ncoordinates(rfi_dag) <- list(x = c(X = 0, Z = 1, Y = 2),\n                            y = c(X = 1, Z = 0, Y = 1))\n\nrethinking::drawdag(rfi_dag)\n```\n\n::: {.cell-output-display}\n![DAG with a confound](index_files/figure-html/fig-rfi_dag-1.png){#fig-rfi_dag fig-align='center' width=70%}\n:::\n:::\n\n\nX: RFI support based on EBPM\n\nY: Outcome of crimes\n\nZ: Governor or State Congress\n\nFor now, however, I pretend this is a natural experiment, and move on.\n\n## Which states joined RFI, and when?\n\nI get the info on which states joined RFI and when from [this page](https://www.pewtrusts.org/en/projects/archived-projects/results-first-initiative/where-we-work). As there must be 27 states, I count Salt Lake County, Utah as Utah state. Although some California counties joined in 2013, I count California in 2016 when California state joined.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstates_join <- tribble(\n  ~state, ~year_join,\n  \"North Carolina\", \"December 2017\",\n  \"Alabama\", \"August 2017\",\n  \"Minnesota\", \"June 2015\",\n  \"California\", \"January 2016\",\n  \"Mississippi\", \"December 2012\",\n  \"Colorado\", \"summer 2014\",\n  \"New Mexico\", \"2011\",\n  \"Illinois\", \"fall of 2011\",\n  \"New York\", \"late 2011\",\n  \"Iowa\", \"May 2011\",\n  \"Alaska\", \"March 2015\",\n  \"Nevada\", \"August 2014\",\n  \"Oregon\", \"January 2012\",\n  \"Connecticut\", \"March 2011\",\n  \"Pennsylvania\", \"March 2017\",\n  \"Rhode Island\", \"March 2013\",\n  \"Delaware\", \"August 2015\",\n  \"Utah\", \"June 2017\",\n  \"Florida\", \"October 2015\",\n  \"Texas\", \"December 2011\",\n  \"Idaho\", \"February 2011\",\n  \"Vermont\", \"November 2011\",\n  \"Kansas\",  \"2011\",\n  \"West Virginia\", \"July 2014\",\n  \"Massachusetts\", \"March 2012\",\n  \"Wisconsin\", \"fall 2013 Several months later\",\n  \"Montana\", \"May 2017\"\n) |> \n  mutate(year_join = parse_number(year_join)) |> \n  arrange(state)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstates_join |> \n  mutate(state = state |> \n           fct_reorder(year_join) |> \n           fct_rev()) |> \n  ggplot(aes(year_join, state)) +\n  geom_point() +\n  scale_x_continuous(breaks = 2011:2017) +\n  labs(x = NULL, y = NULL,\n       title = \"27 states joined RFI from 2011 to 2017\") +\n  theme(panel.grid.minor = element_blank())\n```\n\n::: {.cell-output-display}\n![27 states joined RFI (Results First Initiative)](index_files/figure-html/fig-plot_states_join-1.png){#fig-plot_states_join fig-align='center' width=70%}\n:::\n:::\n\n\n## Replicate the quoted figure\n\nStatistically significant at 0.01 items in the quoted table above are all U.S. prison data, like prisoners, sentenced prisoners, custody population, admissions and releases. So, I have prepared those data in [my GitHub repo](https://github.com/mitsuoxv/us-prison). For simplicity, I use only prisoners here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprisoners <- read_csv(\"https://raw.githubusercontent.com/mitsuoxv/us-prison/main/prisoners.csv\")\n\nprisoners_long <- prisoners |> \n  pivot_longer(-state, names_to = \"year\", values_to = \"prisoners\") |> \n  mutate(year = as.numeric(year)) |> \n  arrange(state, year)\n```\n:::\n\n\nJudging from the quoted figure, I guess he regards 17 states which joined between 2011 and 2014 as treatment group, and the rest 33 states as control group. I replicate the quoted figure in the left below.\n\nI also plot both treatment and control groups in Y-axis including zero in the right below. I set 2012 as 0 in X-axis in the control group.\n\n\n::: {.cell layout-ncol=\"2\" fig.asp='1.2'}\n\n```{.r .cell-code}\nstates_join_upto_2014 <- states_join |> \n  filter(year_join <= 2014)\n\nprisoners_long2 <- prisoners_long |> \n  left_join(states_join_upto_2014, by = \"state\") |> \n  mutate(\n    group = if_else(is.na(year_join), \"Control\", \"Treatment\"),\n    year_join = coalesce(year_join, 2012),\n    diff_year = year - year_join\n  )\n\nprisoners_long2 |> \n  filter(group == \"Treatment\") |> \n  filter(between(diff_year, -3, 3)) |> \n  group_by(diff_year) |> \n  summarize(prisoners = mean(prisoners)) |> \n  ggplot(aes(diff_year, prisoners)) +\n  geom_line() +\n  geom_vline(xintercept = 0, lty = 2) +\n  scale_x_continuous(breaks = -3:3) +\n  labs(x = \"years before or after the joined year\",\n       title = \"Average number of prisoners in treatment group (17 states)\") +\n  theme(panel.grid.minor = element_blank())\n\nprisoners_long2 |> \n  filter(between(diff_year, -3, 3)) |> \n  group_by(group, diff_year) |> \n  summarize(prisoners = mean(prisoners), .groups = \"drop\") |> \n  ggplot(aes(diff_year, prisoners)) +\n  geom_line(aes(color = group)) +\n  geom_vline(xintercept = 0, lty = 2) +\n  scale_x_continuous(breaks = -3:3) +\n  expand_limits(y = 0) +\n  labs(x = \"years before or after the joined year\",\n       title = \"Average number of prisoners per state\") +\n  theme(panel.grid.minor = element_blank(),\n        legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![Replica of the quoted figure](index_files/figure-html/fig-quoted_figure-1.png){#fig-quoted_figure-1 width=70%}\n:::\n\n::: {.cell-output-display}\n![Modified version of the replica](index_files/figure-html/fig-quoted_figure-2.png){#fig-quoted_figure-2 width=70%}\n:::\n:::\n\n\n## Replicate the row of prisoners in the quoted table\n\nAs the quoted figure shows -3 to 3 years from the joined year of the states which joined from 2011 to 2014, I use data from 2008 to 2017, and set \"rfi\" 0 in the years upto the joined year and 1 in the years beyond the joined year. Alaska, Delaware, Florida and Minnesota which joined in 2015 get 1 in \"rfi\" in 2016 and 2017, and California which joined in 2016 gets 1 in \"rfi\" in 2017. So the treatment group is now 22 states, and the control group is 28 states.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- prisoners_long |> \n  left_join(states_join, by = \"state\") |> \n  filter(between(year, 2008, 2017)) |> \n  mutate(\n    year_join = coalesce(year_join, Inf),\n    rfi = if_else(year > year_join, 1, 0),\n    state = factor(state),\n    year = factor(year)\n    ) |> \n  select(!year_join)\n```\n:::\n\n\nHe asserts he has used DiD (Difference-in-Difference) method to make the quoted table, writes standard errors are clustered by state with the two-way (state and year) fixed effect model equation in the footnote of the table.\n\nAs he refers to the 4th chapter in [Primer for causal inference by Shota Yasui](https://www.amazon.co.jp/%E5%8A%B9%E6%9E%9C%E6%A4%9C%E8%A8%BC%E5%85%A5%E9%96%80%E3%80%9C%E6%AD%A3%E3%81%97%E3%81%84%E6%AF%94%E8%BC%83%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E5%9B%A0%E6%9E%9C%E6%8E%A8%E8%AB%96-%E8%A8%88%E9%87%8F%E7%B5%8C%E6%B8%88%E5%AD%A6%E3%81%AE%E5%9F%BA%E7%A4%8E-%E5%AE%89%E4%BA%95-%E7%BF%94%E5%A4%AA/dp/4297111179), he must have used miceadds::lm.cluster() to get clustered standard errors. So I also use miceadds::lm.cluster().\n\nThe table below comes from two-way (state and year) fixed effect model: DiD. Coefficient \"rfi\" estimate is -248, and p-value is 0.709. This does not look like the quoted table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_2fe_summary <- miceadds::lm.cluster(formula = prisoners ~ state + year + rfi,\n                     data = dat, cluster = \"state\") |> \n  summary()\n```\n:::\n\n::: {#tbl-2fe .cell tbl-cap='Coefficient \"rfi\" from two-way (state and year) fixed effect model that is DiD'}\n\n```{.r .cell-code}\nlm_2fe_summary[60, ] |> \n  knitr::kable()\n```\n\n::: {.cell-output-display}\n|                   |            x|\n|:------------------|------------:|\n|Estimate           | -248.0280061|\n|Std. Error         |  664.0861555|\n|t value            |   -0.3734877|\n|Pr(>&#124;t&#124;) |    0.7087855|\n:::\n:::\n\n\nSo I try the one-way (state) fixed effect model in the right table. Now, estimate is -1415, and p-value is 0.019. Although p-value is slightly larger than 0.01, this looks similar to the quoted table. The problem is this is not DiD. Negative estimate merely reflects downward trend in nearly all states.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_1fe_summary <- miceadds::lm.cluster(formula = prisoners ~ state + rfi,\n                     data = dat, cluster = \"state\") |> \n  summary()\n```\n:::\n\n::: {#tbl-1fe .cell tbl-cap='Coefficient \"rfi\" from one-way (state) fixed effect model that is not DiD'}\n\n```{.r .cell-code}\nlm_1fe_summary[51, ] |> \n  knitr::kable()\n```\n\n::: {.cell-output-display}\n|                   |             x|\n|:------------------|-------------:|\n|Estimate           | -1415.3431579|\n|Std. Error         |   602.4018194|\n|t value            |    -2.3495001|\n|Pr(>&#124;t&#124;) |     0.0187986|\n:::\n:::\n\n\n## Conclusion\n\nWhile I try to reproduce his work, I find that he wrongly recognized the data came from a natural experiment, and that he failed to do DiD, probably due to a coding error. Is he so careless? Maybe. Or maybe not. I suspect he may have tested us. If we are easily deceived by statistical junks, EBPM can be harmful. After all, he titled his article as \"Wish Death of EBPM!\"\n\nThis is my second post to criticize Assist. Prof. Narita's work. First one is [here](https://mitsuoxv.rbind.io/2022/10/08/does-democracy-cause-slower-economic-growth-in-the-21st-century/).\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}