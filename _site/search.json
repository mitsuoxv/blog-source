[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog posts",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\nJun 15, 2023\n\n\nMigrated to Quarto\n\n\n1 min\n\n\n\n\nJun 10, 2023\n\n\nAssist Prof Narita tests us by his mistakes\n\n\n8 min\n\n\n\n\nApr 27, 2023\n\n\nWill higher public spending for family lead to higher fertility rate?\n\n\n8 min\n\n\n\n\nMar 15, 2023\n\n\nQuestionnaires can be confusing by order\n\n\n3 min\n\n\n\n\nMar 13, 2023\n\n\nUse Hugo Themes with Netlify\n\n\n1 min\n\n\n\n\nFeb 17, 2023\n\n\nCross-country productivity analysis is orange to apple comparison\n\n\n6 min\n\n\n\n\nDec 16, 2022\n\n\nDoes repeated vaccination cause excess mortality?\n\n\n14 min\n\n\n\n\nNov 21, 2022\n\n\nFake market research for ads\n\n\n1 min\n\n\n\n\nOct 17, 2022\n\n\nCrowd out by zero interest rate?\n\n\n3 min\n\n\n\n\nOct 15, 2022\n\n\nBond vigilantes or runners for cash in panic?\n\n\n3 min\n\n\n\n\nOct 14, 2022\n\n\nWill higher interest rates increase high-return investments?\n\n\n2 min\n\n\n\n\nOct 8, 2022\n\n\nDoes democracy cause slower economic growth in the 21st century?\n\n\n6 min\n\n\n\n\nOct 4, 2022\n\n\nCan you say it is high or low by looking at one time data?\n\n\n6 min\n\n\n\n\nOct 4, 2022\n\n\nRetained earnings are not retained cash\n\n\n2 min\n\n\n\n\nMay 15, 2022\n\n\nI updated BIOS, and installed a new CPU in my PC\n\n\n3 min\n\n\n\n\nMay 3, 2022\n\n\nDo persistent low interest rates stifle growth?\n\n\n3 min\n\n\n\n\nApr 7, 2022\n\n\nQuick to raise, but slow to cut gas prices?\n\n\n8 min\n\n\n\n\nMar 9, 2022\n\n\nOverestimate of gasoline price control effects by METI\n\n\n2 min\n\n\n\n\nFeb 17, 2022\n\n\nWill higher wages lead to higher labor productivity?\n\n\n2 min\n\n\n\n\nFeb 15, 2022\n\n\nWhat is your specialty, Prof Kobayashi?\n\n\n2 min\n\n\n\n\nFeb 13, 2022\n\n\nMust fiscal stimulus aim to enhance long term economic growth?\n\n\n2 min\n\n\n\n\nFeb 12, 2022\n\n\nDoes gov’t debt deter economic growth?\n\n\n7 min\n\n\n\n\nFeb 8, 2022\n\n\nUpdate: city competition to consume in 2021\n\n\n1 min\n\n\n\n\nNov 17, 2021\n\n\nIs a subsidy to gasoline wholesaler effective?\n\n\n1 min\n\n\n\n\nNov 11, 2021\n\n\nDoes gasoline explain the inflation difference between US and Euro?\n\n\n1 min\n\n\n\n\nNov 6, 2021\n\n\nAre subsidies for domestic semiconductor fabs effective for economic security?\n\n\n2 min\n\n\n\n\nOct 29, 2021\n\n\nAre Tokyo Olympics-Paralympics volunteers satisfied?\n\n\n1 min\n\n\n\n\nOct 13, 2021\n\n\nUpdate: IMF World Economic Outlook Database, October 2021\n\n\n1 min\n\n\n\n\nSep 30, 2021\n\n\nLost in translation\n\n\n2 min\n\n\n\n\nSep 11, 2021\n\n\nAnother kind of immaculate inflation doctrine\n\n\n6 min\n\n\n\n\nAug 31, 2021\n\n\nNobel laureate Dr Omura is misinformed\n\n\n2 min\n\n\n\n\nAug 22, 2021\n\n\nCan the Black-Scholes model predict future stock prices?\n\n\n2 min\n\n\n\n\nAug 2, 2021\n\n\nMoney pegged to the dollar is prone to runs\n\n\n2 min\n\n\n\n\nAug 1, 2021\n\n\nCentral gov’t, not municipalities, has vaccine stocks\n\n\n5 min\n\n\n\n\nJul 26, 2021\n\n\nNHK is trapped in bothsideism on US politics\n\n\n2 min\n\n\n\n\nJul 17, 2021\n\n\nDo some municipalities have superfluous stocks of Pfizer vaccines?\n\n\n3 min\n\n\n\n\nJul 16, 2021\n\n\nLauncher saved me from a pop shell bug\n\n\n2 min\n\n\n\n\nJun 16, 2021\n\n\nStrange version of quoting out of context by NHK\n\n\n2 min\n\n\n\n\nJun 5, 2021\n\n\nDark side of fiscal soundness advocacy\n\n\n1 min\n\n\n\n\nMay 19, 2021\n\n\nDon’t be afraid of negative real interest rates by inflation\n\n\n6 min\n\n\n\n\nMay 13, 2021\n\n\nHow to finance war against Godzilla\n\n\n22 min\n\n\n\n\nMay 6, 2021\n\n\nGov’t debt is savings of the workers for retirement\n\n\n19 min\n\n\n\n\nApr 30, 2021\n\n\nBounce back at the speed of potential GDP growth rates?\n\n\n2 min\n\n\n\n\nApr 27, 2021\n\n\nDoes exorbitant privilege separate dollar from yen?\n\n\n3 min\n\n\n\n\nApr 27, 2021\n\n\nConfidence fairy in disguise\n\n\n2 min\n\n\n\n\nApr 21, 2021\n\n\nUpdate: City Competition to Consume: “by city” panel\n\n\n1 min\n\n\n\n\nApr 15, 2021\n\n\nUpdate: add World (map) to Covid-19\n\n\n1 min\n\n\n\n\nApr 11, 2021\n\n\nNHK is a deficit hawk\n\n\n1 min\n\n\n\n\nApr 9, 2021\n\n\nShiny app and environments\n\n\n5 min\n\n\n\n\nApr 7, 2021\n\n\nUpdate: IMF World Economic Outlook Database, April 2021\n\n\n1 min\n\n\n\n\nMar 5, 2021\n\n\nUpdate: 2021 Economic Report of the President\n\n\n1 min\n\n\n\n\nMar 3, 2021\n\n\nUpdate: add USA map to Covid-19 app\n\n\n2 min\n\n\n\n\nFeb 5, 2021\n\n\nHamamatsu-city came back\n\n\n1 min\n\n\n\n\nJan 21, 2021\n\n\nProxy Blues\n\n\n2 min\n\n\n\n\nDec 19, 2020\n\n\nAre suicide cases rapidly surging in Japan?\n\n\n1 min\n\n\n\n\nOct 28, 2020\n\n\nMy first pull request: imfr\n\n\n3 min\n\n\n\n\nOct 27, 2020\n\n\nCorrection: who pays tariffs\n\n\n1 min\n\n\n\n\nOct 14, 2020\n\n\nUpdate: IMF World Economic Outlook Database, October 2020\n\n\n1 min\n\n\n\n\nAug 27, 2020\n\n\nUpdate: add Japan prefecture map to jp-household\n\n\n1 min\n\n\n\n\nAug 18, 2020\n\n\nUpdate: I have found a csv file in WHO Dashboard\n\n\n1 min\n\n\n\n\nJul 26, 2020\n\n\nUpdate: let President Reagan speak\n\n\n2 min\n\n\n\n\nJul 17, 2020\n\n\nUpdate: let POTUS speak\n\n\n3 min\n\n\n\n\nJun 14, 2020\n\n\nLet the Presidents speak\n\n\n2 min\n\n\n\n\nJun 11, 2020\n\n\nComplaint to WHO, and memo to myself\n\n\n1 min\n\n\n\n\nMay 31, 2020\n\n\nI built a PC, installed Pop!_OS, and am running RStudio\n\n\n6 min\n\n\n\n\nMay 26, 2020\n\n\nCovid-19 in the United States\n\n\n1 min\n\n\n\n\nMay 11, 2020\n\n\nHerfindahl-Hirschman Index of world export by product\n\n\n1 min\n\n\n\n\nApr 15, 2020\n\n\nIMF World Economic Outlook Database, April 2020\n\n\n1 min\n\n\n\n\nMar 11, 2020\n\n\nCoronavirus csv files\n\n\n1 min\n\n\n\n\nMar 7, 2020\n\n\nCoronavirus newly confirmed cases by each area\n\n\n1 min\n\n\n\n\nMar 2, 2020\n\n\nSentiment analysis of the economic report of the president\n\n\n1 min\n\n\n\n\nFeb 27, 2020\n\n\nTf-idf analysis of the economic report of the president\n\n\n1 min\n\n\n\n\nFeb 7, 2020\n\n\nHamamatsu-city defeated\n\n\n1 min\n\n\n\n\nSep 9, 2019\n\n\nDecember 15 tariffs target imports which China has more than 75 percent shares\n\n\n1 min\n\n\n\n\nAug 6, 2019\n\n\nWho replaces China in US imports?\n\n\n1 min\n\n\n\n\nJul 19, 2019\n\n\nMy first package, tqr, is add-on to tsibble\n\n\n2 min\n\n\n\n\nJun 21, 2019\n\n\nCorrection: China hits back as much as the size of its claim\n\n\n1 min\n\n\n\n\nJun 18, 2019\n\n\nUpdate: China retaliation values caluculated from China data, not from the US data\n\n\n1 min\n\n\n\n\nJun 12, 2019\n\n\nUpdate: USTR grants product exclusions periodically\n\n\n1 min\n\n\n\n\nMay 30, 2019\n\n\nJapan international trade\n\n\n1 min\n\n\n\n\nMay 21, 2019\n\n\nIMF World Economic Outlook Databases, April 2019\n\n\n1 min\n\n\n\n\nMay 15, 2019\n\n\nUpdate: China retaliation, even if less than claimed, hurt US exports\n\n\n1 min\n\n\n\n\nMay 13, 2019\n\n\nWho pays tariffs?\n\n\n1 min\n\n\n\n\nMay 10, 2019\n\n\nMy first shinyapps.io\n\n\n1 min\n\n\n\n\nApr 26, 2019\n\n\nFor a starter, you had better not git clone the themes\n\n\n1 min\n\n\n\n\nApr 25, 2019\n\n\nCity competition to consume more dumplings\n\n\n1 min\n\n\n\n\nApr 25, 2019\n\n\nChinese retaliation is half the size of their claim\n\n\n1 min\n\n\n\n\nApr 25, 2019\n\n\nMy first post\n\n\n1 min\n\n\n\n\nApr 25, 2019\n\n\nThe most (least) euro-ic country is Greece (Ireland)\n\n\n1 min\n\n\n\n\nApr 25, 2019\n\n\nYellen Dashboard\n\n\n1 min\n\n\n\n\nApr 25, 2019\n\n\nUS tariffs on China\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mitsuo Shiota",
    "section": "",
    "text": "an economist and data scientist"
  },
  {
    "objectID": "studies.html",
    "href": "studies.html",
    "title": "Studies",
    "section": "",
    "text": "Japan international trade (monthly update)\nIMF World Economic Outlook Database (twice a year)\nCity competition to consume in Japan (annual)\nWHO, Covid-19 situation report (weekly)"
  },
  {
    "objectID": "about.html#name",
    "href": "about.html#name",
    "title": "About",
    "section": "",
    "text": "Mitsuo Shiota"
  },
  {
    "objectID": "about.html#occupation",
    "href": "about.html#occupation",
    "title": "Mitsuo Shiota",
    "section": "",
    "text": "an economist and data scientist"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Mitsuo Shiota",
    "section": "Education",
    "text": "Education\n\n1991 MBA, economics major, NYU\n1983 Bachelor of Laws, University of Tokyo"
  },
  {
    "objectID": "studies.html#shiny-apps",
    "href": "studies.html#shiny-apps",
    "title": "Studies",
    "section": "",
    "text": "Japan international trade (monthly update)\nIMF World Economic Outlook Database (twice a year)\nCity competition to consume in Japan (annual)\nWHO, Covid-19 situation report (weekly)"
  },
  {
    "objectID": "studies.html#package",
    "href": "studies.html#package",
    "title": "Studies",
    "section": "Package",
    "text": "Package\n\ntqr: add-on to tsibble, inspired by tidyquant"
  },
  {
    "objectID": "studies.html#research",
    "href": "studies.html#research",
    "title": "Studies",
    "section": "Research",
    "text": "Research\n\nUS prison data from Bureau of Justice Statistics (annual)\nRetail and wholesale gasoline prices in Japan (monthly)\nJapan suicide cases reported by National Police Agency (monthly)\nWHO, Covid-19 situation report (daily)\nUSA, Covid-19 situation by state (daily)\nJapan, Covid-19 situation by prefecture (daily)\nYellen dashboard (monthly)\nChinese shares in US imports by tariff schedule (monthly)\nWho replaces China in US imports? (quarterly)\nGDP movement in Europe by euro or not (quarterly)\nJapan Family Income and Expenditure Survey, city competition (annual)"
  },
  {
    "objectID": "studies.html#translation-into-japanese",
    "href": "studies.html#translation-into-japanese",
    "title": "Studies",
    "section": "Translation into Japanese",
    "text": "Translation into Japanese\n\nForecasting: Principles and Practice (3rd ed) by Rob J Hyndman and George Athanasopoulos"
  },
  {
    "objectID": "studies.html#past-research",
    "href": "studies.html#past-research",
    "title": "Studies",
    "section": "Past research",
    "text": "Past research\n\nTf-idf analysis of the economic report of the president (annual)\nSentiment analysis of the economic report of the president (annual)\nHerfindahl-Hirschman Index of world export by product (by 5 years)\nCompare US CPI and Euro HICP by excluding gasoline\nWho pays tariffs?\nChina hits back as much as the size of its claim\nUS exports to China by tariff schecule\nEconomic and Trade Policies of the Trump Administration and Their Effects, March 2017\nFuture of Japanese-style management, Japanese only, October 2010"
  },
  {
    "objectID": "posts/2021-01-21-proxy-blues/index.html",
    "href": "posts/2021-01-21-proxy-blues/index.html",
    "title": "Proxy Blues",
    "section": "",
    "text": "They Say It Will Work\nIt Won’t Work\nDon’t Be Noisy\nHate Proxy\nI am writing this post from my Company PC (Panasonic notebook with Windows 10), which connects to the Internet via a proxy server with authentication. I am required to change my password every 3 month. I got the mail to do so today, so I just changed my password.\nThen I must modify several setting files for data science tools, like R, Git, conda, and Jupyter Notebook. I will show you how I modify below.\nSuppose my ID is MYID, my password is MYPW, and the proxy server (domain:port number, like xxx.xxx.xxx:xx) is PROXY. In my case, as the proxy server is set by .pac file, I have to ask IT Department to get the proxy server.\n.Renviron in Documents\nDon’t forget to URL encode MYPW.\n# Proxy setting\nhttp_proxy=http://MYID:MYPW@PROXY\n\nhttps_proxy=http://MYID:MYPW@PROXY\n.Rprofile in Documents\nI have to set download.file.method as “libcurl”.\n# Start-up options\noptions(internet.info = 0)\n\noptions(download.file.method = \"libcurl\")\n.bash_profile in (a kind of) Home (in my case, one stage upper of Documents)\nDon’ forget to escape special characters in MYPW, if any.\n# generated by Git for Windows\ntest -f ~/.profile && . ~/.profile\ntest -f ~/.bashrc && . ~/.bashrc\n\nCONNECT_USER=MYID\n\nCONNECT_PASSWORD=MYPW\n\nexport CONNECT_USER CONNECT_PASSWORD\n.gitconfig in Home\nURL encode MYPW.\n[http]\n    proxy = http://MYID:MYPW@PROXY\n[https]\n    proxy = http://MYID:MYPW@PROXY\n.condarc in Home\nURL encode MYPW.\nchannels:\n  - defaults\n\nproxy_servers:\n  http: http://MYID:MYPW@PROXY\n  https: http://MYID:MYPW@PROXY\n\nssl_verify: false\nreport_errors: false\n00-startup.py in startup in profile_default in .ipython in Home\nURL encode MYPW.\nos.environ['HTTP_PROXY'] = \"http://MYID:MYPW@PROXY\" os.environ['HTTPS_PROXY'] = \"http://MYID:MYPW@PROXY\"\nIs everything OK? Unfortunately no. In RStudio, Git Pull or Push button never works for me. I go around this issue by typing git commands in Tools &gt; Shell. I just hate proxy."
  },
  {
    "objectID": "posts/2019-05-10-my-first-shinyapps-io/index.html",
    "href": "posts/2019-05-10-my-first-shinyapps-io/index.html",
    "title": "My first shinyapps.io",
    "section": "",
    "text": "I have made my first shinyapps.io, based on my study on city competition to consume in Japan.\nYou can check which city consumed most in each item in each year from 2007 to 2018."
  },
  {
    "objectID": "posts/2019-06-21-correction-china-hits-back-as-much-as-the-size-of-its-claim/index.html",
    "href": "posts/2019-06-21-correction-china-hits-back-as-much-as-the-size-of-its-claim/index.html",
    "title": "Correction: China hits back as much as the size of its claim",
    "section": "",
    "text": "I have downloaded China customs data on imports from the US by HS 8 digit code in 2017 from IHS Markit’s Global Trade Atlas, and caluculated its retaliation values. I have found that Chinese caluculated on HS 8 digit codes, not on 6 digit codes. Based on the US customs data, I had guessed that they calculated on 6, not on 8 digit codes. I was wrong on my guess."
  },
  {
    "objectID": "posts/2023-03-15-questionnaires-can-be-confusing-by-order/index.html",
    "href": "posts/2023-03-15-questionnaires-can-be-confusing-by-order/index.html",
    "title": "Questionnaires can be confusing by order",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\ntheme_set(theme_light())"
  },
  {
    "objectID": "posts/2023-03-15-questionnaires-can-be-confusing-by-order/index.html#a-surprise-result-from-a-survey",
    "href": "posts/2023-03-15-questionnaires-can-be-confusing-by-order/index.html#a-surprise-result-from-a-survey",
    "title": "Questionnaires can be confusing by order",
    "section": "A surprise result from a survey",
    "text": "A surprise result from a survey\nI have found a tweet which refers to a survey result that high school students in the U.S. feel uneasy when they don’t go along with their friends, more than those in Japan, China and Korea.\nSimply unbelievable! The source is a survey published by National Institution For Youth Education of Japan in 2018 (Japanese). You can read questionnaires here in English, and find Question 33 like below."
  },
  {
    "objectID": "posts/2023-03-15-questionnaires-can-be-confusing-by-order/index.html#my-hypothesis-is-that-confusion-has-caused-a-surprise",
    "href": "posts/2023-03-15-questionnaires-can-be-confusing-by-order/index.html#my-hypothesis-is-that-confusion-has-caused-a-surprise",
    "title": "Questionnaires can be confusing by order",
    "section": "My hypothesis is that confusion has caused a surprise",
    "text": "My hypothesis is that confusion has caused a surprise\nQuestion 33 is about relations with parents, teachers and friends. Left (“Agree”) means positive and Right (“Disagree”) means negative in most questionnaires, except h and i where Left and Right is reversed. You can see response results by country in columns and question in rows below.\nAs participants respond by question order, they tend to repeat the same response in successive questions. So some auto-correlation or momentum is moving vertically in below chart. My hypothesis is the U.S. participants are so positive and quick to answer that some of them may have missed the reversed meanings in questions h and i.\nHowever, I am not sure. Korean participants who are more positive than the U.S. didn’t fall in the same trap in questions h and i. Difference of questionnaire structure by language may have affected.\n\n\nCode\n# posts/2023-03-15-questionnaires-can-be-confusing-by-order/\n\nresults &lt;- read_csv(\"data/q33results.csv\")\n\n\n\n\nCode\nresults |&gt; \n  mutate(question = str_to_lower(question)) |&gt; \n  pivot_longer(Japan:Korea, names_to = \"country\") |&gt; \n  mutate(\n    country = factor(country,\n                     levels = c(\"US\", \"Japan\", \"China\", \"Korea\")),\n    res2 = factor(res2,\n                  levels = c(\"Agree\", \"Somewhat agree\",\n                             \"Somewhat disagree\", \"Disagree\"))\n  ) |&gt; \n  ggplot(aes(res2, value)) +\n  geom_col(aes(fill = res2)) +\n  scale_y_continuous(breaks = c(0, 50)) +\n  scale_fill_brewer(palette = \"RdBu\") +\n  facet_grid(rows = vars(question), cols = vars(country)) +\n  labs(x = NULL, y = \"Percent\") +\n  theme(\n    axis.text.x = element_text(angle = 90),\n    strip.background = element_blank(),\n    strip.text = element_text(color = \"black\"),\n    strip.text.y = element_text(angle = 0),\n    legend.position = \"none\"\n  )\n\n\n\n\n\nFigure 1: Survey results by question and country"
  },
  {
    "objectID": "posts/2022-05-15-i-updated-bios-and-installed-a-new-cpu-in-my-pc/index.html",
    "href": "posts/2022-05-15-i-updated-bios-and-installed-a-new-cpu-in-my-pc/index.html",
    "title": "I updated BIOS, and installed a new CPU in my PC",
    "section": "",
    "text": "My PC is 2 years old. I built it myself, and it worked fine. As my motto is “Don’t fix it, as long as it works,” I had no plan to upgrade my CPU. However, I sometimes betray my motto, and do some risky fixes. This time was one of them.\nThe story began when I read an annoying news, “Rakuten Mobile raises fees for users of less than 1GB per month usage (Japanese)”. I am one of such users. I accessed Rakuten Mobile app to get more information, and found an unrelated fact that I had 20,000 points, which were given to me when I changed my mobile carrier, and these points would expire in this month! Suddenly I felt obliged to buy something in Rakuten Market as soon as possible. And I decided to buy AMD Ryzen 5 5600, which was priced at 27,500 JPY. If I deduct 10 percent consumption tax and exchange by 130 JPY per USD, the price is 192 USD. As MSRP is 199 USD, this is not a bad deal. I used my 20,000 points, and paid 7,500 JPY, or 58 USD.\nTo replace CPU, I must update BIOS, as BIOS in my 2 year old motherboard does not recognize Zen 3 architecture. I prepared a FAT formatted USB flash drive. To do so, I struggled with “Disks” app in Pop-os. Initially I thought the drive would be mountable, once formatted. I was wrong. To create new partition was also necessary. Then I downloaded BIOS zip file from the vendor (in my case, Asrock) site, and extracted a file into a USB flash drive. My CPU soon to be replaced was AMD Ryzen 5 1600 AF. Asrock does not recommend the updated BIOS to this old CPU. So once BIOS was updated, there would be no way of return.\nToday, a new CPU was delivered. Should I update BIOS before or after installing a new CPU? Definitely before. Otherwise BIOS screen would not appear. I updated BIOS, following the instructions in this page. Pop-os appeared with an old CPU and a new BIOS, and I powered off. Then I struggled with my hardware for nearly an hour. To remove an air cooler attached to CPU, I had to remove a part of the chassis beforehand. When I finished removing an air cooler, I heard a sound of a part falling in the opposite side of motherboard. I had to open the opposite side panel. While replacing CPU was easy, installing a new air cooler was hard. Anyway, I managed to finish CPU and air cooler replacement.\nThe moment of truth came. I pushed power button. A message appeared, saying it detected new CPU, asked me to input either y or n, and I typed y. I waited a while, and found Pop-os appeared. Yes, I succeeded! I am writing this post on my updated PC. Whether the update worth the trouble remains to be seen. I hope my updated PC will work stable and serve me long."
  },
  {
    "objectID": "posts/2020-02-27-tf-idf-analysis-of-the-economic-report-of-the-president/index.html",
    "href": "posts/2020-02-27-tf-idf-analysis-of-the-economic-report-of-the-president/index.html",
    "title": "Tf-idf analysis of the economic report of the president",
    "section": "",
    "text": "I have found “Text Mining Fedspeak” by Len Kiefer, which applies tidytext techniques to analyze the annual Federal Reserve Monetary Policy Report, very interesting. Especially the td-idf analysis part is fascinating, as it reveals what the Fed is talking abount most by year. For example, they talked a lot about “iraq”, “war” and “sars” in 2003, and “subprime” in 2007 and 2008. I could feel the history.\nI have got an idea that if I apply the same techniques to the Economic Report of the President, I may know what the Presidents and the fellow Coucil of Economic Advisers talk about most every year. So I have downloaded the reports from 1947 to 2020, and made a new study, “Tf-idf analysis of the economic report of the president”. Tf-idf (term frequency–inverse document frequency) analysis scores high the words which appear frequently in this year’s report, but seldom appear in the other years’ reports. And the highest score over all reports goes to “opioids” in 2020."
  },
  {
    "objectID": "posts/2019-04-26-for-a-starter-you-had-better-not-git-clone-the-themes/index.html",
    "href": "posts/2019-04-26-for-a-starter-you-had-better-not-git-clone-the-themes/index.html",
    "title": "For a starter, you had better not git clone the themes",
    "section": "",
    "text": "I am happy to arrive here at rbind.io via netlify.com. But I nearly failed because of netlify-recognizes-theme-as-submodule issue.\nI am a starter of Git and GitHub, just use Git as some sort of FTP, don’t know what submodules mean. I struggled to remove .git in the theme directory. In the end, I deleted the theme directory, newly downloaded zip theme files, and it worked. So, if you are a starter like me, don’t git clone the themes, instead download zip."
  },
  {
    "objectID": "posts/2022-10-14-will-higher-interest-rates-increase-high-return-investments/index.html",
    "href": "posts/2022-10-14-will-higher-interest-rates-increase-high-return-investments/index.html",
    "title": "Will higher interest rates increase high-return investments?",
    "section": "",
    "text": "Prof Keiichiro Kobayashi of Keio University proposed a model, where higher interest rates prompt businesses to invest in high-risk high-return projects instead of low-risk low-return ones, in his “Lecture on Economics” in Nikkei news paper on October 12, 2022 (Japanese).\nHis model is built in the following manner.\n\nBusinesses must borrow money, invest in either always-1%-return project or half-negative-10%-half-positive-20%-return project, and pay back the principal and the required interest rate. If businesses fail to pay back full amount, they will be punished heavily.\nBusinesses will choose always-1%-return project when the required interest rate is zero, and that they will choose half-negative-10%-half-positive-20%-return project when the rate is 3%. So higher interest rates prompt businesses to invest in high-risk high-return projects, instead of low-risk low-return ones.\nLow interest rates cause low rates of return of the whole economy, while high interest rates cause high rates of return of the whole economy.\n\nI think that the rates of return of the whole economy determine the interest rates , in the reversed causal direction of 3, in the real world. There must be a hidden and unrealistic assumption in his model. It turns out, at 2, he implicitly assumes that businesses are not allowed to make any contracts to share returns among them. If they can share their returns, they will choose half-negative-10%-half-positive-20%-return project even when the required interest rate is zero. Financial institutions usually intermediate flow of funds to bring about the same effect. I would like to say his model has no implications in the real world."
  },
  {
    "objectID": "posts/2020-12-19-are-suicide-cases-rapidly-surging-in-japan/index.html",
    "href": "posts/2020-12-19-are-suicide-cases-rapidly-surging-in-japan/index.html",
    "title": "Are suicide cases rapidly surging in Japan?",
    "section": "",
    "text": "I was watching News Center 9, an NHK nightly news program, on December 16. It told suicide cases have been rapidly surging since July 2020 in Japan. It showed a chart which displays January to December in x axis, number of cases in y axis, and two lines of 2020 and Mean (2017-2019). While the line Mean (2017-2019) has downward slope, the line of 2020 has a rapid upward slope. Two lines cross around July.\nYou can see the chart I replicated, and a more simple time series chart since 2008 in “Japan suicide cases reported by National Police Agency”. It turned out that suicide cases had been declining since 2010, but bottomed out in early 2020. I suspect that discovery delay in the Covid-19 emergency period has caused some downs in spring and ups thereafter, and that the surge is not as fast as the NHK program suggests."
  },
  {
    "objectID": "posts/2019-07-19-my-first-package-tqr-is-add-on-to-tsibble/index.html",
    "href": "posts/2019-07-19-my-first-package-tqr-is-add-on-to-tsibble/index.html",
    "title": "My first package, tqr, is add-on to tsibble",
    "section": "",
    "text": "tqr package is my first package, and is for my use only for now. This is basically a replacement of self-made functions I wrote in yellen-dashboard. Part of the package name tq comes from tidyquant package. I added r to make the package name tqr.\nFor my old functions to work, I had to prepare a data frame of 3 columns named “date”, “symbol” and “price”. tqr package does not require fixed column names, but requires a tsibble (tbl_ts class) instead. In a tsibble, you must specify one column as index (time pointing column like “date”) and one or more columns as key (category columns like “symbol”). tqr assumes all the others are measurement columns of numeric values like “price”. As tqr works with more than one measurement columns (wide format), you don’t have to gather to one measurement column (tidy or long format). Actually, if you need speed, you had better spread to wide format.\nA tsibble has interval attribute, like “1M” for monthly data. (Actual attribute is a list, but is printed like “1M”) For a tsibble to get the right interval, you have to pre-format index by functions like yearmonth for monthly and yearquarter for quarterly data.\nAlthough it takes some steps to convert a tibble to a tsibble, I think it is worthwhile, as I can check missing rows in a tsibble. As missing rows are dangerous to the functions in tqr package, I make a tsibble as required input.\ntq_diff, tq_ma, tq_gr and tq_sa in the package are, except for requiring a tsibble, backward compatible with my old functions. They calculate differences, moving averages, growth rates and seasonally adjusted values respectively.\ntq_diff, tq_ma and tq_gr are manufactured by function factory cal_factory, and tq_sa is manufactured by function factory cal_factory_ts. Other function factories are cal_factory_zoo and cal_factory_xts. When I find myself manufacturing the same functions, like maybe tq_logdiff, I will add them to the package."
  },
  {
    "objectID": "posts/2021-04-27-does-exorbitant-privilege-separate-dollar-from-yen/index.html",
    "href": "posts/2021-04-27-does-exorbitant-privilege-separate-dollar-from-yen/index.html",
    "title": "Does exorbitant privilege separate dollar from yen?",
    "section": "",
    "text": "I sometimes feel uneasy about the guest essays named “Lecture on Economics” in Nikkei news paper. The theme is the same as the previous one, “Policy proposal for post-Covid-19”. The guest is Shumpei Takemori, an economics professor and a member of Council on Economic and Fiscal Policy, on April 27, 2021.\nI first felt uneasy about his proposal, “Watch out deterioration in net international investment position, if fiscal stimulus is excessive in Japan.” Should we worry about international investment position, when its net asset is 65 percent of GDP at the end of 2019, and current account balance has been continuously positive since 1981? But, if fiscal stimulus is unimaginably huge, interest rates can go up, the yen can appreciate, and current account balance can be negative.\nLet us think in the framework of “Swan Diagram”, in which x axis is domestic absorption and y axis is real exchange rate (up is appreciation). Internal balance line is a upward slope, of which the left is unemployment and the right is inflation. External balance line is a downward slope, of which the left is current account surplus and the right is current account deficit. Cross point is both internally and externally balanced. Imagine unimaginably huge fiscal stimulus increases domestic absorption, and moves the point to the right of both lines. In the “Mundell–Fleming model”, as the yen is under the flexible exchange rate regime and stimulus comes from fiscal policy, the interest rates go up and the yen appreciates, so the point moves along the internal balance line. This means no inflation, but current account deficit. In the real world, in which nominal and real exchange rates fluctuate frequently, the point is sometimes on the internal balance line, but mostly in the region of the right of both lines. This means both inflation and current account deficit.\nSo, unimaginably huge fiscal stimulus can cause deterioration in net international investment position eventually in Japan. But is it a problem to watch out?\nHe continues, “If fiscal stimulus is excessive in the U.S., only inflation can be a problem. As the dollar is widely used in the international transactions, investors’ confidence in the dollar solely depend on inflation.”\nIf he implies that the U.S. can continue to be in current account deficits, as the dollar has exorbitant privileges, he is wrong. There are many other countries, like New Zealand and Australia (up to 2018), with continuous current account deficits. I am not saying the dollar’s exorbitant privileges don’t exist. As the dollar has exorbitant privileges, the U.S. banks can dominate international transaction clearing, the U.S. government can impose economic sanctions on foreigners, and the U.S. can benefit from zero interest rate finance by floating greenbacks abroad. But the U.S. continuous current account deficits is not due to the dollar’s exorbitant privileges.\nIf he implies that the yen will lose investors’ confidence once Japan falls into current account deficits, he suggests currency crisis can be the problem in Japan. Currency crisis starts from accumulated foreign currency denominated short-term debt. And it will take some time to accumulate. In the mean while, the yen depreciates, the current account balance increases, and debt stops to accumulate. Although the yen does not have exorbitant privileges, it is unlikely that Japan falls into currency crisis because of fiscal stimulus, however huge it is.\nAfter all, I don’t understand why he proposes that we should watch out current account balance when we consider fiscal stimulus in Japan. I feel uneasy at his saying about current account balance deterioration without mentioning interest and exchange rates."
  },
  {
    "objectID": "posts/2020-06-11-complaint-to-who-and-memo-to-myself/index.html",
    "href": "posts/2020-06-11-complaint-to-who-and-memo-to-myself/index.html",
    "title": "Complaint to WHO, and memo to myself",
    "section": "",
    "text": "Every morning, I update Covid-19, WHO situation report, and shiny app.\nThis morning, WHO situation report was No. 142, which I downloaded at 7:43 am, June 11, Japan Time. And its Table 1 was a mess. Check sum alerted me something is wrong. I found:\n\nThe numbers of Kosovo are not of Kosovo, but of Isle of Man.\nKosovo and Puerto Rico are missing.\nFrench Guiana and Jersey are duplicated.\n\nFrom the grand total, I know total new_conf of Kosovo and Puerto Rico is 139. I speculate 69 for Kosovo, and 70 for Puerto Rico. I have to correct them later.\nUpdate: I re-downloaded No. 142 at 7:37 am, June 12, Japan Time, and found it was corrected. Thank you, WHO. It turned out that new_conf was 0 for Kosovo, and 139 for Puerto Rico."
  },
  {
    "objectID": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html",
    "href": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html",
    "title": "Does gov’t debt deter economic growth?",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(OECD)\nlibrary(janitor)\nlibrary(countrycode)\nlibrary(ggrepel)\n\ntheme_set(theme_light())"
  },
  {
    "objectID": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#prof-morikawas-article-in-nikkei",
    "href": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#prof-morikawas-article-in-nikkei",
    "title": "Does gov’t debt deter economic growth?",
    "section": "Prof Morikawa’s article in Nikkei",
    "text": "Prof Morikawa’s article in Nikkei\nProf Masayuki Morikawa at Hitotsubashi University published an article titled “We should emphasize soft infrastructure in government expenditures to enhance productivity” (Japanese) in “Lecture on Economics” in Nikkei news paper on February 10, 2022. In his article he shows the chart which I will soon replicate, and suggests that higher debt may reduce economic growth rates."
  },
  {
    "objectID": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#get-data-from-oecd-stats",
    "href": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#get-data-from-oecd-stats",
    "title": "Does gov’t debt deter economic growth?",
    "section": "Get data from OECD Stats",
    "text": "Get data from OECD Stats\nI follow “Alternative data-acquisition strategy” in https://github.com/expersso/OECD.\n\n\nCode\n# GDP per hour worked, constant prices\nproductivity &lt;- get_dataset(\"PDB_GR\",\n                    filter = \"AUS+AUT+BEL+CAN+CHL+COL+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.T_GDPHRS_V.2015Y\",\n                    start_time = 2008,\n                    end_time = 2019,\n                    pre_formatted = TRUE) %&gt;% \n  clean_names()\n\nprod_growth &lt;- productivity %&gt;% \n  mutate(obs_value = as.numeric(obs_value)) %&gt;% \n  filter(time %in% c(\"2008\", \"2019\")) %&gt;% \n  select(location, time, obs_value) %&gt;% \n  pivot_wider(names_from = time, values_from = obs_value) %&gt;% \n  mutate(prod_growth = (`2019` / `2008`)^(1/11) * 100 - 100)\n\n\n\n\nCode\ngdp &lt;- get_dataset(\"SNA_TABLE1\",\n                    filter = \"AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.GDP+B1GVO_Q+B1GVR_U+P119+D21_D31+D21S1+D31S1+DB1_GA+B1_GE+P3_P5+P3+P31S14_S15+P31S14+P31S15+P3S13+P31S13+P32S13+P41+P5+P51+P51N1111+P51N1112+P51N1113+P51N11131+P51N11132+P51N1113I+P51N1113O+P51N1114+P51N112+P52_P53+P52+P53+B11+P6+P61+P62+P7+P71+P72+DB1_GE+B1_GI+D1+D1A_B+D1C_E+D1D+D1F+D1G_I+D1J_K+D1L_P+D1VA+D1VB_E+D1VC+D1VF+D1VG_I+D1VJ+D1VK+D1VL+D1VM_N+D1VO_Q+D1VR_U+D11+D11A_B+D11C_E+D11D+D11F+D11G_I+D11J_K+D11L_P+D11VA+D11VB_E+D11VC+D11VF+D11VG_I+D11VJ+D11VK+D11VL+D11VM_N+D11VO_Q+D11VR_U+D12+D12VA+D12VB_E+D12VC+D12VF+D12VG_I+D12VJ+D12VK+D12VL+D12VM_N+D12VO_Q+D12VR_U+B2G_B3G+D2_D3+D2S1+D3S1+DB1_GI.V+VIXOB+DOB+G\",\n                    start_time = 2008,\n                    end_time = 2019,\n                    pre_formatted = TRUE) %&gt;% \n  clean_names()\n\ngdp_growth &lt;- gdp %&gt;% \n  mutate(obs_value = as.numeric(obs_value)) %&gt;% \n  filter(transact == \"B1_GE\", measure == \"V\",\n         time %in% c(\"2008\", \"2019\")) %&gt;% \n  select(location, time, obs_value) %&gt;% \n  pivot_wider(names_from = time, values_from = obs_value) %&gt;% \n  mutate(gdp_growth = (`2019` / `2008`)^(1/11) * 100 - 100) %&gt;% \n  select(location, gdp_growth)\n\n\nAs Columbia and Turkey don’t have complete 12 data from 2008 to 2019 in general government debts per GDP, I drop them.\n\n\nCode\ngov &lt;- get_dataset(\"GOV\",\n                    filter = \"AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.GGD_GDP+GTR_GDP+GTE_GDP+GINV_GDP\",\n                    start_time = 2008,\n                    end_time = 2019,\n                    pre_formatted = TRUE) %&gt;% \n  clean_names()\n\ngov %&gt;% \n  filter(ind == \"GGD_GDP\") %&gt;% \n  group_by(cou) %&gt;% \n  summarize(n = n()) %&gt;% \n  filter(n != 12) # drop \"COL\", \"TUR\"\n\n\n# A tibble: 2 × 2\n  cou       n\n  &lt;chr&gt; &lt;int&gt;\n1 COL       5\n2 TUR      10\n\n\nCode\nggd_gdp &lt;- gov %&gt;% \n  mutate(obs_value = as.numeric(obs_value)) %&gt;% \n  filter(ind == \"GGD_GDP\", !cou %in% c(\"COL\", \"TUR\")) %&gt;% \n  group_by(cou) %&gt;% \n  summarize(ggd_gdp = mean(obs_value), .groups = \"drop_last\") %&gt;% \n  rename(location = cou)"
  },
  {
    "objectID": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#replicate-the-chart-in-the-article",
    "href": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#replicate-the-chart-in-the-article",
    "title": "Does gov’t debt deter economic growth?",
    "section": "Replicate the chart in the article",
    "text": "Replicate the chart in the article\nHe draws a scatter plot of government debts per GDP and economic growth rates from 2008 to 2019 (probably selected as the year of full employment) in OECD members.\nAlthough he cautions that the relationship is correlation, not causation, he says that high government debts may reduce economic growth.\nAlthough he labels only Japan, Greece, Italy, France, Germany, United Kingdom and United States in the chart in his article, I label all countries here.\n\n\nCode\ngdp_growth %&gt;% \n  left_join(ggd_gdp, by = \"location\") %&gt;% \n  mutate(\n    country = countrycode(location, origin = \"iso3c\", destination = \"country.name\")) %&gt;% \n  ggplot(aes(ggd_gdp, gdp_growth)) +\n  geom_hline(yintercept = 0, color = \"white\", size = 1.5) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_text_repel(aes(label = country)) +\n  scale_y_continuous(breaks = -3:5) +\n  labs(x = \"Average gross government debt per GDP (percent)\",\n       y = \"Average real GDP growth rates (percent)\",\n       title = \"Replication of the chart in the article\",\n       subtitle = \"from 2008 to 2019\",\n       caption = \"Source: OECD\")\n\n\n\n\n\nFigure 1: Government debt and economic growth"
  },
  {
    "objectID": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#replace-economic-growth-rates-with-productivity-gdp-per-hours-worked-growth-rates",
    "href": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#replace-economic-growth-rates-with-productivity-gdp-per-hours-worked-growth-rates",
    "title": "Does gov’t debt deter economic growth?",
    "section": "Replace economic growth rates with productivity (GDP per hours worked) growth rates",
    "text": "Replace economic growth rates with productivity (GDP per hours worked) growth rates\nAs this article is about how to enhance productivity by fiscal expentitures, and Japan economic growth is suffering from decreasing population and labor force, I replace economic growth rates with productivity (GDP per hours worked) growth rates. The slope of the linear regression line is now flatter.\n\n\nCode\nprod_growth %&gt;% \n  left_join(ggd_gdp, by = \"location\") %&gt;% \n  mutate(\n    country = countrycode(location, origin = \"iso3c\", destination = \"country.name\")) %&gt;% \n  ggplot(aes(ggd_gdp, prod_growth)) +\n  geom_hline(yintercept = 0, color = \"white\", size = 1.5) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_text_repel(aes(label = country)) +\n  scale_y_continuous(breaks = -3:5) +\n  labs(x = \"Average gross government debt per GDP (percent)\",\n       y = \"Average productivity growth rates (percent)\",\n       title = \"Differences narrow based on productivity growth rates\",\n       subtitle = \"from 2008 to 2019\",\n       caption = \"Source: OECD\")\n\n\n\n\n\nFigure 2: Government debt and productivity growth"
  },
  {
    "objectID": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#exclude-euro-countries-except-germany-and-separate-into-two-charts-by-whether-oecd-original-member-or-not",
    "href": "posts/2022-02-12-does-gov-t-debt-deter-economic-growth/index.html#exclude-euro-countries-except-germany-and-separate-into-two-charts-by-whether-oecd-original-member-or-not",
    "title": "Does gov’t debt deter economic growth?",
    "section": "Exclude Euro countries except Germany and separate into two charts by whether OECD original member or not",
    "text": "Exclude Euro countries except Germany and separate into two charts by whether OECD original member or not\nAs Euro countries, like Greece and Italy, don’t borrow in its own currency but in the euro, and were forced into austerity by Germany from 2008 to 2019, I exclude Euro countries except Germany. I also exclude Denmark as its currency is pegged to the euro. As a result, I just consider the relationship between gov’t debts in its own currency and productivity growth.\nI also separate the OECD countries by whether they are the original members or not, to take account of the development stages by each country.\nNow there is no relationship between gov’t debts and productivity growth. Am I cherry picking the data? I believe not.\n\n\nCode\neuro_cou &lt;- c(\"AUT\", \"BEL\", \"NLD\", \"FIN\", \"FRA\", \"IRL\", \"ITA\", \"LUX\",\n                     \"PRT\", \"ESP\", \"GRC\", \"SVN\", \"CYP\", \"MLT\", \"SVK\", \"EST\",\n                     \"LVA\", \"LTU\", \"DNK\")\n\nprod_growth %&gt;% \n  filter(!location %in% euro_cou) %&gt;% \n  mutate(original_member = if_else(\n    location %in% c(\"MEX\", \"CZE\", \"HUN\", \"POL\", \"KOR\", \"CHL\",\n                    \"ISR\"), \"Joined later\", \"Original OECD members\"\n  )) %&gt;% \n  left_join(ggd_gdp, by = \"location\") %&gt;% \n  mutate(\n    country = countrycode(location, origin = \"iso3c\", destination = \"country.name\")) %&gt;% \n  ggplot(aes(ggd_gdp, prod_growth)) +\n  geom_hline(yintercept = 0, color = \"white\", size = 1.5) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_text_repel(aes(label = country)) +\n  scale_y_continuous(breaks = -3:5) +\n  facet_wrap(vars(original_member)) +\n  labs(x = \"Average gross government debt per GDP (percent)\",\n       y = \"Average productivity growth rates (percent)\",\n       title = \"No relationship between gov't debts and productivity growth rates,\\nif taking account of development stage of each country\",\n       subtitle = \"from 2008 to 2019\",\n       caption = \"Source: OECD\")\n\n\n\n\n\nFigure 3: Government debt and productivity growth in non-original and original OECD countries excluding Euro area except Germany"
  },
  {
    "objectID": "posts/2022-10-04-retained-earnings-are-not-retained-cash/index.html",
    "href": "posts/2022-10-04-retained-earnings-are-not-retained-cash/index.html",
    "title": "Retained earnings are not retained cash",
    "section": "",
    "text": "NHK caster Maho Kuwako, Mr. Shunsuke Kobayashi, Chief Economist of Mizuho Securities, and others talked about inflation and wage in the evening NHK program “Close-up Gendai” on October 4.\nThey talked about how to make businesses pay more wages and invest more from the accumulated retained earnings. Ms Kuwako introduced retained earnings as “money businesses save at hand”, and showed it has increased to 516 trillion yen, which is 8 times of annual government tax revenues. Being asked why retained earnings increased to this level, Mr Kobayashi answered one reason is that businesses which hold plenty of cash have survived through the past four crises.\nI was surprised that they misunderstand retained earnings are retained cash. They should learn accounting. Retained earnings are in the right side of the balance sheet, while cash is in the left side. Businesses which have large retained earnings do not always hold large cash. After they invest more and pay cash, they still hold the same amount of retained earnings. Retained earnings can be reduced by paying more dividends, but not by investing more. Even if businesses paid more wages in the past, retained earnings might have increased to the same level by cutting dividends, as composition of the right side of the balance sheet is determined by the strategy about how to best finance capital.\nIf they think businesses are too greedy to pay more wages, they should talk about income share between labor and capital, instead of retained earnings."
  },
  {
    "objectID": "posts/2022-05-03-do-persistent-low-interest-rates-stifle-growth/index.html",
    "href": "posts/2022-05-03-do-persistent-low-interest-rates-stifle-growth/index.html",
    "title": "Do persistent low interest rates stifle growth?",
    "section": "",
    "text": "Prof Keiichiro Kobayashi of Keio University referred to an article in his “Lecture on Economics” in Nikkei news paper on May 2, 2022 (Japanese).\nHe writes, “a group, including Prof Nobuhiro Kiyotaki of Princeton University, Prof John Moore of London School of Economics, theoretically proved that persistent low interest policy stifles growth, if borrowers can’t get finance based on their future cash flows, in their 2021 article.”\nI found the referred article is “Credit Horizons”, read it briefly, and watched “2020 Princeton Initiative: Nobuhiro Kiyotaki on credit horizons” on YouTube.\nThe authors propose a model, assuming a small open economy whose interest rate equals to exogenously determined world interest rate. They also assume that investment is either plant or building, that plant in building is the only productive asset, and that engineers/entrepreneurs and savers make a very peculiar arrangement, in which plant investment decreases and building investment increases, as interest rate decreases. (For the details of the arrangement, please read the article.) They try to provide a perspective to “the credit and asset booms in Japan in the late 1980s and in southern Europe in the early 2000s” and their aftermath, and state “a persistently lower real interest rate leads to an initial credit and asset boom, but stagnation in the long run” in Chapter 7 “Final Speculative Remark.”\nI think the authors propose a framework, and speculate that persistent low interest rates might stifle growth. I don’t think they prove so theoretically.\nI also think empirically, if you want to examine Japan in the late 1980s and later, southern Europe in the early 2000s and later, your model should incorporate real exchange rate, which is not in the authors’ model.\nIn Japan in the late 1980s, trade frictions with the US prompted change from export-oriented to domestic-demand-oriented growth. At the same time, restrictions on capital flow were being abolished, and the Cold War was ending. These factors led to less trade surplus, higher yen, lower interest rate, and eventually credit and asset boom and bust. As the export market shrank, plant investment stagnated.\nIn southern Europe in the early 2000s, joining Euro prompted capital inflow and lower interest rate, and credit and asset boom. However, productivity growth was lower and inflation was higher than in Germany, so real exchange rate appreciated, and plant investment stagnated. It led to bigger deficits in current account balance and in target 2 balance, which is equivalent to foreign reserves in the fixed exchange rate regime, and eventually debt crisis.\nIn both cases, increased capital inflow (or less capital outflow in Japan case) caused lower real interest rates and higher real exchange rates. The reason why plant investment was sluggish was not a peculiar arrangement the authors assumes, but an appreciated real exchange rate.\nNow the real exchange rate of the yen depreciated to the level before late 1980s, but plant investment is still sluggish. We may need to add inertia of manufacturing sector and demography to the model."
  },
  {
    "objectID": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html",
    "href": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html",
    "title": "Does democracy cause slower economic growth in the 21st century?",
    "section": "",
    "text": "Code\nlibrary(dagitty)"
  },
  {
    "objectID": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html#curse-of-democracy",
    "href": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html#curse-of-democracy",
    "title": "Does democracy cause slower economic growth in the 21st century?",
    "section": "Curse of democracy?",
    "text": "Curse of democracy?\nI briefly read the article, “Curse of Democracy: Evidence from the 21st Century”, by Yusuke Narita and Ayumi Sudo, September 28, 2021, which claims direct effect from democracy to economic growth was positive in the 1980s and 1990s, but was negative in the 2000s and 2010s. To claim this relationship is not just association but causal, the authors use instrumental variables, which are (1) mortality of European colonial settlers, (2) population density in the 1500s, (3) availability of crops and minerals, (4) fraction of the population speaking English and a Western European language and (5) legal origin.\nAs I happen to be reading “Statistical Rethinking, 2nd Edition” by Richard McElreath, CRC Press, 2020, I would like to show instrumental variable strategy in the DAG (Directed Acyclic Graph) as below.\n\n\nCode\ndag_intended &lt;- dagitty(\"dag{\n                  U [unobserved]\n                  D &lt;- U -&gt; G\n                  V -&gt; D\n                  D -&gt; G\n                  }\")\ncoordinates(dag_intended) &lt;- list(x = c(V = 0, D = 1, U = 2, G = 3),\n                               y = c(V = 0, D = 1, U = 0, G = 1))\nrethinking::drawdag(dag_intended)\n\n\n\n\n\nFigure 1: No path from V to G except via D\n\n\n\n\nV: Instrumental variable\nD: Democracy index\nG: GDP growth rate\nU: Unobserved confound on D and G\nThis strategy aims to estimate the direct effect from D to G. It requires the only path from V to G is V -&gt; D -&gt; G.\nThe authors do 2 stage least square regression on cross-country data, and find their claim."
  },
  {
    "objectID": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html#gdp-per-capita-as-a-confound",
    "href": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html#gdp-per-capita-as-a-confound",
    "title": "Does democracy cause slower economic growth in the 21st century?",
    "section": "GDP per capita as a confound",
    "text": "GDP per capita as a confound\nHowever, if I add Per capita GDP as P to the DAG, it looks like below.\n\n\nCode\ndag_ctrl &lt;- dagitty(\"dag{\n                  U [unobserved]\n                  D &lt;- U -&gt; G\n                  V -&gt; D\n                  D -&gt; G\n                  D &lt;- P -&gt; G\n                  V -&gt; P\n                  }\")\ncoordinates(dag_ctrl) &lt;- list(x = c(V = 0, D = 1, U = 2, G = 3, P = 2),\n                               y = c(V = 0, D = 1, U = 0.5, G = 1, P = 0))\nrethinking::drawdag(dag_ctrl)\n\n\n\n\n\nFigure 2: There is a path from V to G other than via D\n\n\n\n\nHere, the requirement is broken, as there are paths like V -&gt; P -&gt; G.\nV -&gt; P: The instrumental variables the authors use suggest higher per capita GDP.\nP -&gt; D: Higher per capita GDP leads to democracy, or democracy is luxury.\nP -&gt; G: Already high per capita GDP leads to lower productivity growth due to fewer low hanging fruits of growth, and leads to lower population growth due to higher opportunity cost of raising children.\nThe authors may have expected this criticism, so they condition on P, and find little changes, and tell their claim is robust.\nIndeed, conditioning on P shuts the paths from V to G through P, so V cannot influence G except through D."
  },
  {
    "objectID": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html#resource-e.g.-oil-and-gas-richness-as-a-confound",
    "href": "posts/2022-10-08-does-democracy-cause-slower-economic-growth-in-the-21st-century/index.html#resource-e.g.-oil-and-gas-richness-as-a-confound",
    "title": "Does democracy cause slower economic growth in the 21st century?",
    "section": "Resource (e.g. oil and gas) richness as a confound",
    "text": "Resource (e.g. oil and gas) richness as a confound\nHowever, if I replace U with resource-richness as R to the DAG, it looks like below.\n\n\nCode\ndag_r &lt;- dagitty(\"dag{\n                  D &lt;- R -&gt; G\n                  V -&gt; D\n                  D -&gt; G\n                  D &lt;- P -&gt; G\n                  V -&gt; P &lt;- R\n                  }\")\ncoordinates(dag_r) &lt;- list(x = c(V = 0, D = 1, R = 2, G = 3, P = 2),\n                               y = c(V = 0, D = 1, R = 0.5, G = 1, P = 0))\nrethinking::drawdag(dag_r)\n\n\n\n\n\nFigure 3: There is a path from V to G via P and R\n\n\n\n\nR -&gt; P: Resource-rich countries tend to have higher per capita GDP.\nR -&gt; D: Resource-rich countries tend to have concentration of power, as lower competitiveness of manufacturing sector due to higher exchange rate fails to create middle income class, and/or small number of people who hold resources try to monopolize politics.\nR -&gt; G: Resource-rich countries can grow rapidly by depleting resources, when resource prices are high.\nHere, conditioning P makes P a collider, and opens the path like V -&gt; P &lt;- R -&gt; G.\nSo I suspect the estimates the authors get by conditioning on P (Per capita GDP) are not the direct effect from D to G, but reflect the resource price movements, which were lower in 1980s and 1990s, and higher in 2000s and 2010s."
  },
  {
    "objectID": "posts/2020-07-17-update-let-potus-speak/index.html",
    "href": "posts/2020-07-17-update-let-potus-speak/index.html",
    "title": "Update: let POTUS speak",
    "section": "",
    "text": "I put the cleaned-up files in texts/presidents/ of this GitHub repo. I name a file as 1947_pres.txt. These files include only texts of the president part, not including those of the Council of Economic Advisers part.\nI cleaned up by:\n\ncorrecting word order, where digitization made mistakes in shaping lines;\ncorrecting words, where optical recognition made mistakes due to dirt, or the author apparently misspelled;\nmaking punctuation common over reports, following my memory of “The Mac is Not a Typewriter” by Robin P. Williams, which I must have, but could not find now. As an exception, using minus mark instead of hyphen; and\nchanging lines, where I encounter “;”, “:”, “—” or “,” and when I feel changed lines are natural if they were in President Johnson’s reports.\n\nI tried to be consistent over reports of different authors. Honestly, I am not sure whether “text” has become more consistent or not, as a result."
  },
  {
    "objectID": "posts/2020-07-17-update-let-potus-speak/index.html#i-have-finished-manually-cleaned-up-text-files-from-1947-to-2020",
    "href": "posts/2020-07-17-update-let-potus-speak/index.html#i-have-finished-manually-cleaned-up-text-files-from-1947-to-2020",
    "title": "Update: let POTUS speak",
    "section": "",
    "text": "I put the cleaned-up files in texts/presidents/ of this GitHub repo. I name a file as 1947_pres.txt. These files include only texts of the president part, not including those of the Council of Economic Advisers part.\nI cleaned up by:\n\ncorrecting word order, where digitization made mistakes in shaping lines;\ncorrecting words, where optical recognition made mistakes due to dirt, or the author apparently misspelled;\nmaking punctuation common over reports, following my memory of “The Mac is Not a Typewriter” by Robin P. Williams, which I must have, but could not find now. As an exception, using minus mark instead of hyphen; and\nchanging lines, where I encounter “;”, “:”, “—” or “,” and when I feel changed lines are natural if they were in President Johnson’s reports.\n\nI tried to be consistent over reports of different authors. Honestly, I am not sure whether “text” has become more consistent or not, as a result."
  },
  {
    "objectID": "posts/2020-07-17-update-let-potus-speak/index.html#i-tried-google-colab-but-failed",
    "href": "posts/2020-07-17-update-let-potus-speak/index.html#i-tried-google-colab-but-failed",
    "title": "Update: let POTUS speak",
    "section": "I tried Google Colab, but failed",
    "text": "I tried Google Colab, but failed\nThe file in the same repository, let_pres_speak_failed.ipynb, is my failed attempt to use Google Colab to create a model.\nIt timed out at 186th among 500 epochs."
  },
  {
    "objectID": "posts/2020-07-17-update-let-potus-speak/index.html#i-tried-docker-struggled-with-an-error-of-dnn-implementation-and-eventually-found-a-solution",
    "href": "posts/2020-07-17-update-let-potus-speak/index.html#i-tried-docker-struggled-with-an-error-of-dnn-implementation-and-eventually-found-a-solution",
    "title": "Update: let POTUS speak",
    "section": "I tried docker, struggled with an error of dnn implementation, and eventually found a solution",
    "text": "I tried docker, struggled with an error of dnn implementation, and eventually found a solution\nSo I came back to docker, and tried tensorflow 2.3.0rc1, hoping newer version had fixed the errors.\ndocker run -u $(id -u):$(id -g) \\\n  --gpus all -it -p 8888:8888 -v `pwd`:/tf/notebooks \\\n  tensorflow/tensorflow:2.3.0rc1-gpu-jupyter\nHowever, I encountered the same problem of dnn implementation. I searched and found tensorflow: Fail to find dnn implementation in StackOverflow. I added the lines:\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)\nAnd it worked! To allow GPU grow was the key."
  },
  {
    "objectID": "posts/2020-07-17-update-let-potus-speak/index.html#i-created-a-model-and-generated-a-text",
    "href": "posts/2020-07-17-update-let-potus-speak/index.html#i-created-a-model-and-generated-a-text",
    "title": "Update: let POTUS speak",
    "section": "I created a model, and generated a text",
    "text": "I created a model, and generated a text\nThe file in the same repository, let_em_speak_retry.ipynb, is the result I’ve got.\nTo my surprise, docker working in my machine was 4 times faster than Google Colab. It took approximately 8 hours.\nThen I seeded the text, “I have some proposals to the Congress”. The model continued:\n“of the first months of the past year have been accomplished to keep that matter up their abundance ending upon the war ii and hearts inflation continues to adjust peoples testifies nor paperwork proposals know moreover coverage to assures visible in our economic destabilizing coverage overregulated that skillfully assures we beef destabilizing coverage under coverage implies antitrust destabilizing fiscally testify to approve urban coverage coverage coverage and stymies consumption authorities dividend coverage appropriated coverage reaching else coverage propose proposals propose proposals stymies preference loans continued values meant that urgent coverage downward know coverage fostered that referred sdr disease coverage for”\nGrammar is not correct, and the word “coverage” appears repeatedly. However, some sets of words sound natural, as the model guesses next word after word."
  },
  {
    "objectID": "posts/2020-07-17-update-let-potus-speak/index.html#you-can-try",
    "href": "posts/2020-07-17-update-let-potus-speak/index.html#you-can-try",
    "title": "Update: let POTUS speak",
    "section": "You can try",
    "text": "You can try\nAlthough this model has no practical use, I have saved it as “ErpPresModel.h5”. You can play with it, by opening you_can_try.ipynb in Google Colab."
  },
  {
    "objectID": "posts/2021-08-22-can-the-black-scholes-model-predict-future-stock-prices/index.html",
    "href": "posts/2021-08-22-can-the-black-scholes-model-predict-future-stock-prices/index.html",
    "title": "Can the Black-Scholes model predict future stock prices?",
    "section": "",
    "text": "NHK and other media reported a supplement and cosmetics vendor listed on the first section of the Tokyo Stock Exchange demonstrated an air flight using biofuels it produced from euglena and used cook oil on June 29, 2021 (Japanese).\nNikkei didn’t report this demonstration, I guess, as Nikkei Business had reported those biofuels were made mainly from used cook oil on March 24, 2021 (Japanese, subscription required). But one of its commentators praised its CEO for his performance on July 28, 2021 (Japanese, subscription required).\nIts vice-president had admitted those biofuels were made mainly from used cook oil, as the production cost from euglena were currently too high, on June 23, 2021 (Japanese).\nThen, was that demonstration a company effort to shore up its stock prices? Did the CEO speak in good faith?\nAlthough development of biofuels from algae, including euglena, face criticism (reported here and here), I can’t rule out their future possibilities. So I briefly read the books of both its CEO and CTO to check their good faith, and found some annoying writings.\nThe CEO wrote he and the CTO won stock investment contests both in Sky Perfect TV and TV Tokyo using the Black-Scholes model in their university days in his book (Japanese). He wrote the CTO could calculate the proper stock prices using the Black-Scholes model, and found the undervalued stocks. It is not possible, as the Black-Scholes model is a mathematical model for pricing an options contract. Did the CEO misunderstand the CTO doing?\nThe CTO wrote he used the differential equation, on which the Black-Scholes model relies, in his book publised by Nikkei BP. That equation must be here. For call option price, substitute C(S, T) = max(S - K, 0) in the last differential equation, and we get the Black-Scholes model. For stock price, substitute C = S in the last differential equation, and we get the identity equation rS - rS = 0. I don’t know how this differential equation helped the CTO win the stock investment contest."
  },
  {
    "objectID": "posts/2023-03-13-use-hugo-themes-with-netlify/index.html",
    "href": "posts/2023-03-13-use-hugo-themes-with-netlify/index.html",
    "title": "Use Hugo Themes with Netlify",
    "section": "",
    "text": "Almost four years ago, I posted For a starter, you had better not git clone the themes. Then I wrote “don’t git clone the themes, instead download zip.” As time passed, however, I felt it necessary to update the theme. So, I referred to Host on Netlify and followed the instruction in the section “Use Hugo Themes with Netlify.” So far, I failed to replace a default icon with my face, but it is OK. I would like to say “don’t git clone the themes, instead git submodule add them.”\nUpdate on 2023-03-19: I could replace a default icon with my face, when I create static/images directory in the project root, put mitsuoxv.jpeg (my face jpeg file) there, and change “logo.png” to “mitsuoxv.jpeg” in params.logo section of config.toml."
  },
  {
    "objectID": "posts/2021-07-16-launcher-saved-me-from-a-pop-shell-bug/index.html",
    "href": "posts/2021-07-16-launcher-saved-me-from-a-pop-shell-bug/index.html",
    "title": "Launcher saved me from a pop shell bug",
    "section": "",
    "text": "I have been using Pop!_OS 20.04 since I built my PC 14 months ago. It worked fine until it didn’t yesterday.\nI pushed Super key, and clicked an application icon as usual, but an application didn’t appear on the screen. Instead, icons didn’t go away from the screen, even if I pushed Super key again.\nI thought it was a bug of pop shell, as this happened just after I upgraded pop shell, and was sure System 76 would fix this bug. The problem was how to upgrade to the fixed version under the current condition, in which I couldn’t even launch an application.\nI checked Pop!_OS Keyboard Shortcuts on my iPad, and found Super key + / would activate a launcher. I tried it, and then typed terminal in the launcher and hit Enter. I could launch Terminal, so I felt at rest.\nThis morning I launched Terminal, typed sudo apt update and sudo apt dist-upgrade, found pop shell was upgraded, and restarted my PC. Everything is fine now.\nWhat lessons should I learn from this experience?\n\nTo have multiple devices helps. Without my iPad, I could not have found a solution.\nTo learn multiple ways to do the same thing helps. Activities and Launcher both can launch an application.\nFrequent module upgrade may be a bad idea. I guess System 76 is too busy to finish up COSMIC on 21.04 and to backport some parts to older versions. Several days ago tile windows failed to work, and yesterday Activities never went away. Both bugs were fixed on the next day. It has been my habit to upgrade modules every day, but I may have to reconsider my habit.\n\nAnyway, I always appreciate System 76 for providing a very useful OS."
  },
  {
    "objectID": "posts/2021-04-15-update-add-world-map-to-covid-19/index.html",
    "href": "posts/2021-04-15-update-add-world-map-to-covid-19/index.html",
    "title": "Update: add World (map) to Covid-19",
    "section": "",
    "text": "I added “World (map)” panel to my Shiny app. You can see where are the relatively hot areas.\nUnder the hood, I moved preprocess out of Shiny to make start up quicker."
  },
  {
    "objectID": "posts/2022-11-21-fake-market-research-for-ads/index.html",
    "href": "posts/2022-11-21-fake-market-research-for-ads/index.html",
    "title": "Fake market research for ads",
    "section": "",
    "text": "An advertisement on Nikkei newspaper, published in Tokyo in the evening of November 18, 2022, caught my eye. It was a full page ad by Euglena Co. Ltd. on its supplement product. As I had some doubts on the company, I read the ad and found an annoying assertion.\nIt asserts the product was rated as No.1 (top 1) both in supplements medical workers recommend, and in supplements registered dietitians want to drink every day. It displays the source is the survey on supplements done by Japan Marketing Research Organization, Inc. in October 2021.\nJapan Marketing Research Organization, Inc. is selling “No.1 survey” service, so that advertisers can evade accusation of misleading representations (Japanese).\n“No.1 survey” is not a genuine survey, but a fake, claims Japan Marketing Research Association (Japanese), which is an association of marketing research firms. Japan Marketing Research Organization, Inc. is not a member of Japan Marketing Research Association.\nNHK broadcast a program (Japanese) on this issue on May 17, 2022.\nAnything can be made No.1 by biased samples and arbitrary definitions. I feel sad about “No.1 survey” and advertisers who use it, as marketing research is one of the important applications of statistics."
  },
  {
    "objectID": "posts/2019-05-21-imf-world-economic-outlook-databases-april-2019/index.html",
    "href": "posts/2019-05-21-imf-world-economic-outlook-databases-april-2019/index.html",
    "title": "IMF World Economic Outlook Databases, April 2019",
    "section": "",
    "text": "I have downloaded the entire dataset of IMF World Economic Outlook Database, April 2019, and somehow managed to make a shiny app.\nhttps://mitsuoxv.shinyapps.io/imf-weo/"
  },
  {
    "objectID": "posts/2019-04-25-the-most-least-euro-ic-country-is-greece-ireland/index.html",
    "href": "posts/2019-04-25-the-most-least-euro-ic-country-is-greece-ireland/index.html",
    "title": "The most (least) euro-ic country is Greece (Ireland)",
    "section": "",
    "text": "I often read “European (EU or Euro-area) economy is …”, but there are many countries there. So I have made charts of real GDP movements of each country in my GitHub repo “euro-or-not-gdp”. I paint different colors on the line depending on whether the country was in the euro area or not at each time point.\nNext I have calculated the growth rates before and after the beginning of the financial crisis, and have plotted each country in y-axis of before growth rates and x-axis of after growth rates. The chart looks like a classifying task. So I have tried the classifier, logistic regression, and have got the possibility of each country to be in the euro-area at the beginning of the financial crisis. The highest probability euro country is Greece, and the lowest probability (so low as mis-classified as non-euro) euro country is Ireland."
  },
  {
    "objectID": "posts/2021-06-05-dark-side-of-fiscal-soundness-advocacy/index.html",
    "href": "posts/2021-06-05-dark-side-of-fiscal-soundness-advocacy/index.html",
    "title": "Dark side of fiscal soundness advocacy",
    "section": "",
    "text": "I felt relieved when I read the guest essay “Is the government bond a burden of future generations?” by Kazuo Momma, an ex-central banker, in the corner named “Economist 360 degree view point” of Nikkei newspaper on June 4, 2021 (Japanese, subscription required), as it points out correctly that the government bond is both an asset and a liability. I would like to show my thumbs up to Nikkei for this article.\nI felt depressed when I found a book by Prof. Kazumasa Oguro, to whom I referred as a fiscal soundness advocate in the previous post. The book includes an interview with Prof. Kazumasa Oguro, who is credited as a co-author. The book was actually written and published by a scammer, who targets the wealthy, infuses them with aftermath images of a fiscal collapse, and invites them to his investment club with hefty fees. I will not name him here, but you can search if you can read Japanese. Prof. Kazumasa Oguro, be aware that your crying wolf is a good advertisement for a scammer."
  },
  {
    "objectID": "posts/2019-04-25-yellen-dashboard/index.html",
    "href": "posts/2019-04-25-yellen-dashboard/index.html",
    "title": "Yellen Dashboard",
    "section": "",
    "text": "As a statistics learner, I hate time series data, because it requires me to take more caution, like stationarity, than cross sectional data. As a R learner, I also hate time series data, because I have to learn other packages than tidyverse. As most economic data are time series, I have to find some way.\nThen I have found tidyquant package. I am attracted by the function to download economic data from FRED, and the concept of long format data frame with 3 columns, “date”, “symbol” and “price”.\nSo I try it, and have made “yellen-dashboard” in my GitHub repos. This shows the dashboard of US labor market charts, which Janet Yellen, former Fed chair, was said to be watching. As I can easily update the dashboard, I can be more frequently bothered to guess Fed’s next move."
  },
  {
    "objectID": "posts/2022-10-15-bond-vigilantes-or-runners-for-cash-in-panic/index.html",
    "href": "posts/2022-10-15-bond-vigilantes-or-runners-for-cash-in-panic/index.html",
    "title": "Bond vigilantes or runners for cash in panic?",
    "section": "",
    "text": "Nikkei posted an article titled “UK turmoil can be a lesson for Japan. Fiscal System Council unusually discussed policies by a foreign government.” on October 14, 2022. Indeed, a working group in Fiscal System Council, which reports to Minister of Finance, looked at the material (Japanese) in the meeting on October 13. It showed UK 10-year government bond yields and UK sterling pound vs US dollar exchange rates, before and after Prime Minister Truss announced her growth plan on September 23.\nNikkei writes, “Markets rang an alarming bell, as the proposed tax cuts, which are untargeted and massive, can damage fiscal position and economic growth.” Nikkei thinks that sellers of bonds and sterling pounds are bond vigilantes, who punish governments that propose expansionary and inflationary fiscal policies.\nI doubt it. If they are bond vigilantes, they should have sold more sterling pounds, when the Bank of England intervened the bond market to buy bonds on September 28. They should have seen this intervention as a sign of fiscal dominance, in which the BoE would lose independence from the government, monetize fiscal deficits, and allow inflation to accelerate. But, they didn’t.\nI suspect they are runners for cash in panic.\nFirst, we have to learn what is LDI (Liability-Driven Investment) strategy by defined benefit pension funds. As defined benefit pension funds have long-term fixed payment liability, they are vulnerable for interest rate changes. So they make an LDI derivative contract with financial institutions like Black Rock, which is basically an interest rate swap to have additional fixed income assets and variable payment liabilities in effect. With this contract, if interest rates go down, the present value of original long-term liabilities increases and that of new variable payment liabilities is unchanged, while, on the asset side, the present value of original and new fixed income assets increase. As both sides of asset and liability equally increase in the present value, balance is unchanged in total. If interest rates go up, both sides shrink, and balance is unchanged as well. LDI is a strategy to avoid exposure to interest rate change risks.\nSounds good. But, a hitch is that an amount of cash, which pension funds must hand to derivative contractors as a collateral, changes in real time as interest rates move, as new asset and new liability created by a contract does not balance in the present value. On September 23, interest rates began to rise, as Prime Minister Truss’s plan was bigger than the market had expected. Derivative contractors began to require more cash to pension funds. As pension funds didn’t hold enough cash at hand, they began to sell some assets, mainly government bonds, to get cash. Prices of government bonds decreased, and interest rates rose. This positive feedback continued and people in the market got panic, until the BoE intervened the bond market. People in panic tend to buy US dollars, just as they did when Lehman Brothers collapsed in September 2008. They again bought US dollars, and sold UK sterling pounds.\nAs pension funds are solvent, the BoE expects they have enough cash at hand by October 14. We shall see soon.\nWhat lesson should the Japanese government learn? If I am right, forget about bond vigilantes. Instead, watch out hidden vulnerabilities in the financial markets, which potentially make people run for cash."
  },
  {
    "objectID": "posts/2021-04-11-nhk-is-a-deficit-hawk/index.html",
    "href": "posts/2021-04-11-nhk-is-a-deficit-hawk/index.html",
    "title": "NHK is a deficit hawk",
    "section": "",
    "text": "I watch NHK News at evening almost every day. And I sometimes feel uneasy at the way NHK delivers news. One example is suicide-cases-increase-news which I complained about. Another example is when NHK showed Covid-19 confirmed cases in France and Germany side by side in two charts, whose y axes are scaled differently.\nToday’s news is more annoying. NHK said “The U.S. changes its course to increase corporate tax rates to finance Covid-19 measures”. It is not true.\nAmerican Rescue Plan, which finances Covid-19 measures by deficits, is already enacted. The Biden Administration is now proposing American Jobs Plan to invest in infrastructures and others for the future, and Made in America Tax Plan alongside it to finance investments. NHK messed up all.\nNHK once made a documentary in which the members in the Ministry of Finance made enormous efforts to sell the Japanese Government Bonds, hinting how Japan is close to the debt crisis. I was surprised then. They could publicly say it was hard to sell, as it was in fact easy to sell.\nToday, I am sad to know NHK is still a deficit hawk."
  },
  {
    "objectID": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html",
    "href": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html",
    "title": "Quick to raise, but slow to cut gas prices?",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tsibble)\nlibrary(lubridate)\nlibrary(patchwork)\nlibrary(tidyquant)\n\ntheme_set(theme_light())\nCode\nfred_data &lt;- tq_get(c(\"GASREGW\", \"WCOILWTICO\", \"WCOILBRENTEU\"),\n                    get = \"economic.data\", from = \"2003-01-01\") %&gt;% \n  mutate(week = yearweek(date)) %&gt;% \n  select(-date) # USD per gallon\n\nus_data &lt;- fred_data %&gt;% \n  filter(symbol == \"GASREGW\") %&gt;% \n  select(week, price_incl_tax = price) %&gt;% \n  mutate(price = price_incl_tax - 0.184 - 0.50)\n\nuk_data &lt;- read_csv(\"data/CSV_040422.csv\", \n    skip = 2) %&gt;% \n  select(1, 2, 4, 6) %&gt;% \n  setNames(c(\"week\", \"price_incl_tax\", \"duty\", \"vat_rate\")) %&gt;% \n  mutate(\n    week = dmy(week),\n    week = yearweek(week),\n    price = price_incl_tax / (1 + vat_rate / 100) - duty\n    ) %&gt;% \n  select(week, price_incl_tax, price) # pence per litre\n\nretail &lt;- read_excel(\"data/220406s5.xls\", \n                     sheet = \"レギュラー\",\n                        col_types = c(\"text\", \"date\", rep(\"text\", 59)))\n\njp_data &lt;- retail %&gt;% \n  slice_head(n = nrow(retail) - 1) %&gt;% \n  select(date = \"調査日\", price_incl_tax = \"全         国\") %&gt;% \n  mutate(\n    date = as.Date(date),\n    price_incl_tax = as.numeric(price_incl_tax)\n    ) %&gt;% \n  filter(date &gt;= \"2003-01-01\") %&gt;% \n  mutate(\n    vat_rate = case_when(\n      date &lt; \"2004-04-01\" ~ 0,\n      date &lt; \"2014-04-01\" ~ .05,\n      date &lt; \"2019-10-01\" ~ .08,\n      TRUE ~ .1\n                       ),\n    price = price_incl_tax / (1 + vat_rate) - 53.8,\n    week = yearweek(date)\n  ) %&gt;% \n  select(week, price_incl_tax, price) # yen per litre\n\nbrent &lt;- fred_data %&gt;% \n  filter(symbol == \"WCOILBRENTEU\") %&gt;% \n  mutate(\n    country = \"Brent\",\n    price_incl_tax = price\n    ) %&gt;% \n  select(-symbol)\n\ncombo &lt;- bind_rows(us_data %&gt;% mutate(country = \"United States\"),\n          uk_data %&gt;% mutate(country = \"United Kingdom\"),\n          jp_data %&gt;% mutate(country = \"Japan\"),\n          brent) %&gt;% \n  mutate(date = as.Date(week))"
  },
  {
    "objectID": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html#nikkei-article-on-gasoline-prices",
    "href": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html#nikkei-article-on-gasoline-prices",
    "title": "Quick to raise, but slow to cut gas prices?",
    "section": "Nikkei article on gasoline prices",
    "text": "Nikkei article on gasoline prices\nNikkei reported on April 7, 2022 that the subsidy to wholesalers, which began in late January, led to less rapid rise of gasoline prices in Japan than the US, the UK, Germany and France, and that this price-control policy may distort the economy.\nAlthough I agree to the opposition to price-control, I think this Nikkei article has two problems."
  },
  {
    "objectID": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html#st-problem-prices-include-taxes",
    "href": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html#st-problem-prices-include-taxes",
    "title": "Quick to raise, but slow to cut gas prices?",
    "section": "1st problem: Prices include taxes",
    "text": "1st problem: Prices include taxes\nBelow left, I replicate the chart in the Nikkei article, though I add Brent crude oil prices, and omit Germany and France, as I can’t get those data.\nThe problem of this chart is that prices include taxes. In the most recent week, taxes occupy 19 percent in the US, 49 percent in the UK, and 40 percent in Japan. The more shares taxes occupy, the less prices can change.\nBelow right, I remove taxes. The US approaces to Brent, and the UK approaches to US. However, Japan still lags behind. Is this thanks to METI’s subsidy? No, I would like to claim Japan usually lags behind.\n\n\nCode\np1 &lt;- combo %&gt;% \nfilter(date &gt;= as.Date(\"2022-01-01\"), date &lt; as.Date(\"2022-04-07\")) %&gt;% \n  group_by(country) %&gt;% \n  mutate(index = price_incl_tax / first(price_incl_tax) * 100) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(week, index, color = country)) +\n  geom_line(size = 1) +\n  scale_x_yearweek(date_label = \"%m/\\n%d\", date_break = \"1 month\") +\n  ylim(90, 160) +\n  theme(panel.grid.minor.x = element_blank()) +\n  labs(x = NULL, y = \"Index (Jan 3, 2022 = 100)\",\n       color = NULL,\n       title = \"Gasoline prices\\nincluding taxes\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nCode\np2 &lt;- combo %&gt;% \nfilter(date &gt;= as.Date(\"2022-01-01\"), date &lt; as.Date(\"2022-04-07\")) %&gt;% \n  group_by(country) %&gt;% \n  mutate(index = price / first(price) * 100) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(week, index, color = country)) +\n  geom_line(size = 1) +\n  scale_x_yearweek(date_label = \"%m/\\n%d\", date_break = \"1 month\") +\n  ylim(90, 160) +\n  theme(panel.grid.minor.x = element_blank()) +\n  labs(x = NULL, y = NULL,\n       color = NULL,\n       title = \"Gasoline prices\\nexcluding taxes\")\n\np1 + p2 + plot_layout(guides = \"collect\")\n\n\n\n\n\nFigure 1: Crude oil prices (Brent) and gasoline prices with or without taxes in Japan, the US and the UK\n\n\n\n\nTo support my claim, I must use weekly data of crude oil prices. As I can’t get Dubai prices, I use Brent prices. Basically crude oil prices are global, so it should not be a problem when I use Brent instead of Dubai.\n\n\nCode\nfred_data %&gt;% \n  filter(symbol %in% c(\"WCOILWTICO\", \"WCOILBRENTEU\")) %&gt;% \n  mutate(symbol = recode(symbol,\n                         \"WCOILWTICO\" = \"WTI\",\n                         \"WCOILBRENTEU\" = \"Brent\")) %&gt;% \n  ggplot(aes(week, price, color = symbol)) +\n  geom_line(size = 1) +\n  scale_x_yearweek(date_label = \"%Y\") +\n  labs(x = NULL, y = \"USD per barrel\", color = NULL,\n       title = \"Crude oil prices (weekly)\")\n\n\n\n\n\nFigure 2: Weekly crude oil prices (Brent and WTI)"
  },
  {
    "objectID": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html#nd-problem-blindly-believing-metis-assertion",
    "href": "posts/2022-04-07-quick-to-raise-but-slow-to-cut-gas-prices/index.html#nd-problem-blindly-believing-metis-assertion",
    "title": "Quick to raise, but slow to cut gas prices?",
    "section": "2nd problem: Blindly believing METI’s assertion",
    "text": "2nd problem: Blindly believing METI’s assertion\nNikkei states that price rise in Japan is suppressed, thanks to subsidies by METI. Really? I doubt it.\nWhen I compared wholesale gasoline prices with imported crude oil prices in February 2022, I could not find the evidence that the subsidy lowered wholesale prices. Refer to my GitHub page.\nI even suspect the subsidy raised prices, as METI shows suggested retail prices, which is responsive to Dubai prices and incorporate historically high margin between Dubai prices and retail prices, every week. As METI’s counterfactual retail prices without sibsidy reflect Dubai prices of 2 weeks ago, they are as volatile as Dubai prices.\nAs you see below, retail prices in Japan were less responsive to changes of crude oil prices than the US and the UK. Look at rise, fall and rise again from 2007 to 2009, you see Japan lags Brent both in rise and fall. You can see the same pattern in 2020. In rise of 2021, Japan still lags, though it catches up to Brent in the end.\nI can say wholesalers in Japan were slow to raise, and slow to cut prices in the past. I guess it’s because Japan imports crude oil mainly from Middle East, one month carrying distance away, while the US and the UK produce crude oil domestically. However, wholesalers are now quick to raise, thanks to METI’s subsidy, but slow to cut prices as usual, unless monitored by METI.\n\n\nCode\ndraw_by_year &lt;- function(year) {\n  df &lt;- combo %&gt;% \n    filter(date &gt;= as.Date(paste0(year, \"-01-01\")),\n           date &lt;= as.Date(paste0(year + 1, \"-01-01\")))\n  \n  first_date = df %&gt;% \n    head(1) %&gt;% \n    pull(date)\n  \n  df %&gt;% \n    group_by(country) %&gt;% \n    mutate(index = price / first(price) * 100) %&gt;% \n    ungroup() %&gt;% \n    ggplot(aes(week, index, color = country)) +\n    geom_line(size = 1) +\n    scale_x_yearweek(date_label = \"%b\") +\n    theme(panel.grid.minor.x = element_blank()) +\n    labs(x = NULL, y = paste0(first_date, \" = 100\"),\n         color = NULL,\n         title = as.character(year))\n}\n\ncharts &lt;- vector(\"list\", length(2004:2021))\ncharts &lt;- map(2004:2021, draw_by_year)\n\np_charts &lt;- charts[[1]] + charts[[2]] + charts[[3]] +\n  charts[[4]] + charts[[5]] + charts[[6]] + \n  charts[[7]] + charts[[8]] + charts[[9]] + \n  charts[[10]] + charts[[11]] + charts[[12]] +\n  charts[[13]] + charts[[14]] + charts[[15]] + \n  charts[[16]] + charts[[17]] + charts[[18]]\n\np_charts + plot_layout(ncol = 3, guides = \"collect\")\n\n\n\n\n\nFigure 3: Crude oil prices (Brent) and gasoline prices without taxes in Japan, the US and the UK\n\n\n\n\nP.S.\nI learned the title of this post, “quick to raise, but slow to cut gas prices”, is called “rockets and feathers” in the US from Paul Krugman’s blog post."
  },
  {
    "objectID": "posts/2023-02-17-cross-country-productivity-analysis-is-orange-to-apple-comparison/index.html",
    "href": "posts/2023-02-17-cross-country-productivity-analysis-is-orange-to-apple-comparison/index.html",
    "title": "Cross-country productivity analysis is orange to apple comparison",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(patchwork)\n\nlibrary(scales)\ntheme_set(theme_light())\n\nlibrary(OECD)\nlibrary(gghighlight)"
  },
  {
    "objectID": "posts/2023-02-17-cross-country-productivity-analysis-is-orange-to-apple-comparison/index.html#productivity-comparison-between-the-u.s.-and-japan",
    "href": "posts/2023-02-17-cross-country-productivity-analysis-is-orange-to-apple-comparison/index.html#productivity-comparison-between-the-u.s.-and-japan",
    "title": "Cross-country productivity analysis is orange to apple comparison",
    "section": "Productivity comparison between the U.S. and Japan",
    "text": "Productivity comparison between the U.S. and Japan\nProf Tetsuji Okazaki of the University of Tokyo shows Japan lags the US in labor productivity level, and the gap is widening, in his “Lecture on Economics” in Nikkei news paper on February 17, 2023 (Japanese).\n\n\nCode\ncountries &lt;- c(\"USA\", \"JPN\", \"GBR\", \"DEU\", \"FRA\", \"ITA\", \"CAN\")\n\nexchange_rate &lt;- get_dataset(\n  \"SNA_TABLE4\",\n  filter = list(countries, c(\"PPPGDP\")),\n  start_time = 2005, end_time = 2021\n) |&gt; \n  mutate(across(c(ObsValue, Time), as.numeric))\n\ngdp &lt;- get_dataset(\n  \"SNA_TABLE1\",\n  filter = list(countries, \"B1_GE\", c(\"DOB\", \"C\", \"V\")),\n  start_time = 2005, end_time = 2021\n) |&gt; \n  mutate(across(c(ObsValue, Time), as.numeric))\n\nlabor &lt;- get_dataset(\n  \"ALFS_SUMTAB\",\n  filter = list(countries, \"YGTT08L1_ST\"),\n  start_time = 2005, end_time = 2021\n) |&gt; \n  mutate(across(c(ObsValue, Time), as.numeric))\n\nhours_worked &lt;- get_dataset(\n  \"ANHRS\",\n  filter = list(countries, \"TE\"),\n  start_time = 2005, end_time = 2021\n) |&gt; \n  mutate(across(c(ObsValue, Time), as.numeric))\n\n\n\n\nCode\nus_deflator &lt;- gdp |&gt; \n  filter(LOCATION == \"USA\", MEASURE == \"DOB\") |&gt; \n  mutate(deflator = ObsValue / 100) |&gt; \n  select(Time, deflator)\n\nemployment &lt;- labor |&gt; \n  select(LOCATION, Time, employment = ObsValue)\n\nppp &lt;- exchange_rate |&gt; \n  select(LOCATION, Time, ppp = ObsValue)\n\n\n\n\nCode\nppp_method &lt;- gdp |&gt; \n  filter(MEASURE == \"C\") |&gt; \n  left_join(employment, by = c(\"LOCATION\", \"Time\")) |&gt; \n  left_join(ppp, by = c(\"LOCATION\", \"Time\")) |&gt; \n  left_join(us_deflator, by = \"Time\") |&gt; \n  mutate(\n    nominal_prod_loc = ObsValue / employment,\n    nominal_prod_usd = nominal_prod_loc / ppp,\n    real_prod_usd = nominal_prod_usd / deflator\n    ) |&gt; \n  group_by(LOCATION) |&gt; \n  mutate(index = real_prod_usd / real_prod_usd[1] * 100) |&gt; \n  ungroup()\n  \np1 &lt;- ppp_method |&gt; \n  filter(LOCATION %in% c(\"USA\", \"JPN\")) |&gt; \n  mutate(LOCATION = factor(LOCATION, levels = c(\"USA\", \"JPN\"))) |&gt; \n  ggplot(aes(Time, real_prod_usd)) +\n  geom_line(aes(color = LOCATION)) +\n  labs(x = NULL, y = \"Real productivity per person\\n(thousand dollars, PPP, 2015 price)\",\n       color = \"Country\")\n\np2 &lt;- ppp_method |&gt; \n  filter(LOCATION %in% c(\"USA\", \"JPN\")) |&gt; \n  mutate(LOCATION = factor(LOCATION, levels = c(\"USA\", \"JPN\"))) |&gt; \n  ggplot(aes(Time, index)) +\n  geom_line(aes(color = LOCATION)) +\n  scale_y_continuous(limits = c(85, 125)) +\n  labs(x = NULL, y = \"Real productivity per person\\n(2005 = 100)\",\n       color = \"Country\")\n\n\n\n\nCode\nhours_worked_te &lt;- hours_worked |&gt; \n  select(COUNTRY, Time, hours_worked = ObsValue)\n\nnon_ppp_method &lt;- gdp |&gt; \n  filter(MEASURE == \"V\") |&gt; \n  left_join(employment, by = c(\"LOCATION\", \"Time\")) |&gt; \n  left_join(hours_worked_te, by = c(\"LOCATION\" = \"COUNTRY\", \"Time\")) |&gt; \n  mutate(\n    real_prod_loc = ObsValue / employment,\n    real_prod_loc_hr = real_prod_loc / hours_worked\n    ) |&gt; \n  group_by(LOCATION) |&gt; \n  mutate(\n    prod_per_person = real_prod_loc / real_prod_loc[1] * 100,\n    prod_per_hour = real_prod_loc_hr / real_prod_loc_hr[1] * 100\n    ) |&gt; \n  ungroup()\n\np3 &lt;- non_ppp_method |&gt; \n  filter(LOCATION %in% c(\"USA\", \"JPN\")) |&gt; \n  mutate(LOCATION = factor(LOCATION, levels = c(\"USA\", \"JPN\"))) |&gt; \n  ggplot(aes(Time, prod_per_person)) +\n  geom_line(aes(color = LOCATION)) +\n  geom_line(aes(y = index), color = \"gray80\",\n            data = ppp_method |&gt; filter(LOCATION == \"JPN\")) +\n  scale_y_continuous(limits = c(85, 125)) +\n  labs(x = NULL, y = \"Real productivity per person\\n(2005 = 100)\",\n       color = \"Country\")\n\np4 &lt;- non_ppp_method |&gt; \n  filter(LOCATION %in% c(\"USA\", \"JPN\")) |&gt; \n  mutate(LOCATION = factor(LOCATION, levels = c(\"USA\", \"JPN\"))) |&gt; \n  ggplot(aes(Time, prod_per_hour)) +\n  geom_line(aes(color = LOCATION)) +\n  scale_y_continuous(limits = c(85, 125)) +\n  labs(x = NULL, y = \"Real productivity per hour\\n(2005 = 100)\",\n       color = \"Country\")\n\n\nHe shows the chart which is not exactly same, but similar to the left chart below, and says the gap in labor productivity level between the US and Japan is widening. I have modified it to make the right chart so that 2005 = 100. He uses PPP method. I think it is very difficult or impossible to compare the productivity level, as Japan and the US produce very different products and services. It is only possible to compare productivity growth, then using PPP is unnecessary and inappropriate.\n\n\nCode\np1 + p2 + plot_layout(ncol = 2, guides = \"collect\") + plot_annotation(\n  title = \"PPP method: nominal GDP per employed person in JPY\\nconverted to USD by PPP, then deflated to real by US GDP deflator\",\n  caption = \"Source: OECD stat\"\n)\n\n\n\n\n\nFigure 1: Per-person productivity in 2015 dollars (PPP) and its index (2005 = 100)\n\n\n\n\nBelow is the estimates of labor productivity growth without using PPP. Growth gap narrows in the left below. If we look at productivity per hour instead of per person in the right below, the gap narrows even further.\n\n\nCode\np3 + p4 + plot_layout(ncol = 2, guides = \"collect\") + plot_annotation(\n  title = \"Non PPP method: real GDP per employed person or per hour in JPY \\nindexed at 2005 = 100\",\n  subtitle = \"Gray line in the left is JPN by PPP method, the same as above right\",\n  caption = \"Source: OECD stat\"\n)\n\n\n\n\n\nFigure 2: Per-person and per-hour productivity index (2005 = 100)"
  },
  {
    "objectID": "posts/2023-02-17-cross-country-productivity-analysis-is-orange-to-apple-comparison/index.html#productivity-comparison-among-g7-countries",
    "href": "posts/2023-02-17-cross-country-productivity-analysis-is-orange-to-apple-comparison/index.html#productivity-comparison-among-g7-countries",
    "title": "Cross-country productivity analysis is orange to apple comparison",
    "section": "Productivity comparison among G7 countries",
    "text": "Productivity comparison among G7 countries\nAlthough Japan looks like a loser in productivity per person in PPP dollars, it is not a loser in growth of productivity per hour.\n\n\nCode\np5 &lt;- ppp_method |&gt; \n  ggplot(aes(Time, real_prod_usd)) +\n  geom_line(aes(color = LOCATION)) +\n  gghighlight(LOCATION == \"JPN\", use_group_by = FALSE) +\n  labs(x = NULL, y = \"Real productivity per person\\n(thousand dollars, PPP, 2015 price)\",\n       color = \"Country\")\n\np6 &lt;- non_ppp_method |&gt; \n  ggplot(aes(Time, prod_per_person)) +\n  geom_line(aes(color = LOCATION)) +\n  gghighlight(LOCATION == \"JPN\", use_group_by = FALSE) +\n  scale_y_continuous(limits = c(85, 125)) +\n  labs(x = NULL, y = \"Real productivity per person (2005 = 100)\",\n       color = \"Country\")\n\np7 &lt;- non_ppp_method |&gt; \n  ggplot(aes(Time, prod_per_hour)) +\n  geom_line(aes(color = LOCATION)) +\n  gghighlight(LOCATION == \"JPN\", use_group_by = FALSE) +\n  scale_y_continuous(limits = c(85, 125)) +\n  labs(x = NULL, y = \"Real productivity per hour (2005 = 100)\",\n       color = \"Country\")\n\np5 + p6 + p7 + plot_layout(ncol = 3, guides = \"collect\") + plot_annotation(\n  title = \"Japan is not a loser in growth of productivity per hour\\namong G7 countries\",\n  caption = \"Source: OECD stat\"\n)\n\n\n\n\n\nFigure 3: Per-person productivity in 2015 dollars (PPP), per-person and per-hour productivity index (2005 = 100)"
  },
  {
    "objectID": "posts/2021-04-27-confidence-fairy-in-disguise/index.html",
    "href": "posts/2021-04-27-confidence-fairy-in-disguise/index.html",
    "title": "Confidence fairy in disguise",
    "section": "",
    "text": "Nikkei publishes guest essays named “Lecture on Economics” in its news paper. The guests are Hirohide Yamaguchi, an ex-central banker, and Hiroshi Yoshikawa, a widely respected economist and professor, and the theme is “Policy proposal for post-Covid-19” on April 26, 2021.\nThey say, “Consumption is structurally weak, because people doubt the sustainability of the public pension system, to which the government contributes by deficits, and try to save more to prepare for the collapse of the public pension system.” So, they propose, “Reduce the government deficits, and regain the confidence in the public pension system.”\nThey are not explicit about how to reduce the government deficits, but I guess, they are considering pension benefit reduction and tax increase. If so, their proposal is confidence fairy, the term Paul Krugman uses to critisize “expansionary austerity”. Do people save less, if they see pension benefit reduced? No, I don’t think so.\nI agree that the social security system, including the public pension system, should be reformed. People try to save more, as they are afraid of unexpectedly long old lives. I believe the social security system can be accommodated to provide life-long insurance to live with dignity.\nI don’ agree that we should reduce government deficits to make the public pension system more sustainable, and to promote more consumption. It is confidence fairy in disguise."
  },
  {
    "objectID": "posts/2022-02-08-update-city-competition-to-consume-in-2021/index.html",
    "href": "posts/2022-02-08-update-city-competition-to-consume-in-2021/index.html",
    "title": "Update: city competition to consume in 2021",
    "section": "",
    "text": "I have updated “City competition to consume in Japan”. This is the third annual update. The latest year is now 2021.\nShiny app is here."
  },
  {
    "objectID": "posts/2022-02-17-will-higher-wages-lead-to-higher-labor-productivity/index.html",
    "href": "posts/2022-02-17-will-higher-wages-lead-to-higher-labor-productivity/index.html",
    "title": "Will higher wages lead to higher labor productivity?",
    "section": "",
    "text": "Associate Professor Izumi Yokoyama at Hitotsubashi University published an article titled “Gov’t promotion for higher wages will have limited effects on productivity” (Japanese) in “Lecture on Economics” in Nikkei news paper on February 17, 2022.\nAlthough I agree to what the title says, I am surprised at her reasoning.\nShe considers whether higher wages promoted by the government will lead to higher labor productivity, both (a) under the completely competitive labor market model, and (b) under the efficiency wage theory model.\nIn case of (a), her answer is “yes”, as wages equal to marginal labor productivity. In case of (b), her answer is “limited”, as the opportunity costs of losing jobs for employees don’t increase, because they can find jobs from other employers which also raised wages following the government promotion.\nI would like to show my answer here. In case of (a), absolutely “no”, as wages are determined by the market, and the government promotion has no effects in the first place. She is wrong in thinking higher wages cause higher productivity, though in fact higher wages reflect higher productivity.\nIn case of (b), probably “no”. As the opportunity costs of losing jobs increase, employees will try to enhance productivity. However, all will not succeed, and employers will cut failed employees. So employment will be reduced. Although productivity per hours worked may increase a bit, productivity per labor force may even drop. She is wrong in forgetting the efficiency wage theory was invented to explain persistent involuntary unemployment.\nNear the end of the article, she says government promotion of wage increase is expected to stimulate the economy, which is still suffering from Covid-19. I think this is the only path where wage increase campaign may increase productivity in the short term."
  },
  {
    "objectID": "posts/2021-04-30-bounce-back-at-the-speed-of-potential-gdp-growth-rates/index.html",
    "href": "posts/2021-04-30-bounce-back-at-the-speed-of-potential-gdp-growth-rates/index.html",
    "title": "Bounce back at the speed of potential GDP growth rates?",
    "section": "",
    "text": "This is the third consecutive post on my complaints about the guest essays “Policy proposal for post-Covid-19” on “Lecture on Economics” in Nikkei news paper. The guest is Miho Takizawa, an economics professor, on April 28, 2021. Japanese article is here (subscription required).\nI don’t have any strong objections to her essay as a whole. She points out the need to enhance potential GDP, and proposes some policies on labor, capital and total factor productivity.\nThe problem is just one sentence in the introductory part. She writes, “It is calculated to take surprisingly long 7 years for real GDP to recover to the 2019 level, if it grows at 0.7 percent annually, which Cabinet Office estimates as potential GDP growth rate.”\nThis calculation comes from 4.8 percent, by which 2020 annual level dropped compared to 2019, divided by 0.7 percent. But, how about if we think the fourth quarter as FRB usually does, not annual. As 2020 Oct.-Dec. is 1.4 percent lower on year-over-year basis, it will take 2 years to recover to the 2019 level. Is this my complaint? No, this is a small issue.\nMy complaint is that it is meaningless to assume recovery speed at the potential GDP growth rate, as recovery starts from the lower-than-potential level, where we are not fully utilizing labor, capital and other factors under Covid-19 situation.\nI guess she would like to emphasize the importance of potential GDP growth rate, but this sentence is absurd. If I were an editor, I would have recommended her to delete this sentence."
  },
  {
    "objectID": "posts/2021-10-29-are-tokyo-olympics-paralympics-volunteers-satisfied/index.html",
    "href": "posts/2021-10-29-are-tokyo-olympics-paralympics-volunteers-satisfied/index.html",
    "title": "Are Tokyo Olympics-Paralympics volunteers satisfied?",
    "section": "",
    "text": "NHK News Watch 9 on October 29, 2021 surprised me by the last news (Japanese), which reports that more than 70 percent of volunteers of Tokyo Olympics-Paralympics feel their causes to join volunteers have been fulfilled. Survey is done by the Tokyo Organising Committee of the Olympic and Paralympic Games (TOCOG). 11,893 persons among all 70,000 volunteers have responded.\nResponse rate is 17 percent. I guess most unsatisfied volunteers have not responded. TOCOG may be OK with the survey results, which actually mean nothing. If TOCOG really wants to get meaningful results, it should not have tried complete census, instead should have selected around 200 random samples and tried to get high response rates.\nAnd NHK should not have reported the TOCOG survey uncritically."
  },
  {
    "objectID": "posts/2021-04-21-update-city-competition-to-consume-by-city-panel/index.html",
    "href": "posts/2021-04-21-update-city-competition-to-consume-by-city-panel/index.html",
    "title": "Update: City Competition to Consume: “by city” panel",
    "section": "",
    "text": "I have changed “by city” panel in City Competition to Consume Shiny app from a table to a plot.\nI make this change, because I would like to make it easier to find high rank items, which citizens in each city consume relatively more in Japan. Such high rank items may inspire citizens, and contribute to city revitalization, like dumplings do for Hamamatsu-city and Utsunomiya-city."
  },
  {
    "objectID": "posts/2020-06-14-let-the-presidents-speak/index.html",
    "href": "posts/2020-06-14-let-the-presidents-speak/index.html",
    "title": "Let the Presidents speak",
    "section": "",
    "text": "I added Let the presidents speak on economic matters to the GitHub repository of Economic Report of the President.\nThis is a text generation exercise using Python and tensorflow.\nI first tried docker like below, but failed probably due to the incompatibility issues of the versions of tensorflow, cuda and cudnn. I tried both tf2-gpu.2-2 and tf2-gpu.2-0 in vain.\ngcloud container images list \\\n  --repository=\"gcr.io/deeplearning-platform-release\"\n\ndocker run --gpus all -p 8080:8080 -v `pwd`:/home \\\n  gcr.io/deeplearning-platform-release/tf2-gpu.2-2\nSo I now use Google Colab. I may go back to docker, when I can find compatible version images.\nI input 523 sentences authored by Harry Truman from 3 files from 1947 to 1949, which I manually cleaned up to ensure that each line has one sentence. Fitting the model took nearly 4 hours. Then I started the text, “I have some proposals to the Congress”. The model continued:\n“presented 1947 that i have included in the people and the policy for a few days i have a month earlier resources in a rate of prices and wages which more permanently sustainable rates of the vast public debt and to check year improved services to sustained economic situation to deal with the situation points up generally i evaluate it should should i evaluate i deal show i evaluate wholesale control of our program among as of deflationary pressures of living through hospitals and to savings and credit wages prosperity to reduce of low incomes health or strikes soon as”\nMy ambition was to create some A. I. Presidents, like a Democrat President or a Republican President, and let them talk about health care, tax, trade, etc. However, the generated texts are not convincing.\nAnyway, I will continue to manually clean up text files from 1950 to 2020, and try again."
  },
  {
    "objectID": "posts/2019-04-25-us-tariffs-on-china/index.html",
    "href": "posts/2019-04-25-us-tariffs-on-china/index.html",
    "title": "US tariffs on China",
    "section": "",
    "text": "I would like to know the effects of the tariffs on US imports from China. So I have got data from Census Bureau U.S. International Trade Data, and made “us-tariffs-on-china” repo in my GitHub. Chinese shares rise just before the tariff effective dates, and decline thereafter, as I expected. I am somewhat surprised to know that the USTR has chosen lower-Chinese-share goods first to impose tariffs."
  },
  {
    "objectID": "posts/2019-08-06-who-replaces-china-in-us-imports/index.html",
    "href": "posts/2019-08-06-who-replaces-china-in-us-imports/index.html",
    "title": "Who replaces China in US imports?",
    "section": "",
    "text": "US imports from China are decreasing in 2019. If trade diversion is goin on, other countries are replacing China. In this study, I somewhat arbitrarily choose 4 candidate countries like Vietnam, Korea, Japan and Mexico, and check whether the US imports from these countries increase by HS 4 digit codes."
  },
  {
    "objectID": "posts/2021-04-07-update-world-economic-outlook-april-2021/index.html",
    "href": "posts/2021-04-07-update-world-economic-outlook-april-2021/index.html",
    "title": "Update: IMF World Economic Outlook Database, April 2021",
    "section": "",
    "text": "I have updated my Shiny app every half a year since April 2019. So this is the fifth iteration. And I believe I could make it more usable this time, as I made some improvements so that:\n\nYou can select multiple areas.\nYou can see the values by hovering over a chart.\nYou can compare the current forecast with the previous one.\nYou can download data as a csv file.\n\nUnder the hood, I reconstructed the app as a R package. I could do all of these, as I read the book “Mastering Shiny” by Hadley Wickham. Thank you, Hadley."
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "",
    "text": "Code\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#is-govt-debt-a-morale-issue",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#is-govt-debt-a-morale-issue",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "Is gov’t debt a morale issue?",
    "text": "Is gov’t debt a morale issue?\n“Lecture on Economics” in Nikkei news paper on May 3 to 5, 2021 was titled “Think about the burden for future generations.” Lectures are here, here and here (Japanese, subscription required). The authors think that lack of government morale causes government debt. They think politicians are not well disciplined, and are weak under the pressure from spend-demanding and tax-averse electorate.\nSo the first proposes a debt rollover restriction rule, to which I have strong objection. Don’t forget the U.S. debt ceiling crisis under the Obama administration and the Republican controlled House. The second proposes independent fiscal institutions, of which effectiveness I doubt. The third proposes Covid-19 measures should be financed by taxes, not by deficits, because deficits divert resources from productive capital accumulation. He may be right, if the deficits crowd out investment by causing higher interest rates. But now I observe persistent zero interest rates, and no crowding-out.\nSo I don’t think government debt is a morale issue."
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#is-govt-debt-a-burden-for-future-generations",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#is-govt-debt-a-burden-for-future-generations",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "Is gov’t debt a burden for future generations?",
    "text": "Is gov’t debt a burden for future generations?\nNikkei title is “Think about the burden for future generations.” Is government debt a burden for future generations in the first place?\nPaul Krugman says no. “Debt is Money We Owe to Ourselves.” (here) Dean Baker says no. “There is a distributional issue — Bill Gates’ children may own all the debt — but that is within generations, not between generations.” (here)\nSimon Wren-Lewis says yes, if we consider overlapping generations. “Government debt can be a burden on future generations.” (here)"
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#two-meanings-of-generation",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#two-meanings-of-generation",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "Two meanings of “generation”",
    "text": "Two meanings of “generation”\nWhich side is right? I think both sides are right. According to Oxford Languages via Google, “generation” meanings are:\n\nthe average period, generally considered to be about thirty years, in which children grow up, become adults, and have children of their own.\nall of the people born and living at about the same time, regarded collectively.\n\nPaul Krugman and Dean Baker are right if they use “generation” as 1, and Simon Wren-Lewis is right if he uses “generation” as 2.\nLet us call 1 as “Period” and 2 as “Generation,” then I can show Generation overlap as below. Every Generation lives in 2 Periods. For example, Generation 2 lives working in Period 1 and lives retired in Period 2.\n\n\n\nFigure 1: Period Generation Matrix"
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#a-tiny-model",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#a-tiny-model",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "A tiny model",
    "text": "A tiny model\nTo clarify my understanding, I make a tiny model to replicate above table. You can see my tiny model at tiny_model function in the Rmarkdown format of this post.\nImagine a one factor (labor), three sector (Generation 1 and 2, Government), and closed economy. There is no capital, no business sector, no international trade, and no foreigner. Ignore financial sector as an intermediary. And imagine all goods and services produced in a Period are perishable, and must be consumed in that Period, like foodstuff and entertainment, care and medicine services. There is no stock, and no investment. And imagine the only role of Government is to issue and pay back bonds, of which duration is one Period, 30 years. There is no defense spending, and no taxes. The only method for Generation to save is to buy bonds.\n\nConstant saving rate, with constant population and productivity\nIn Period 1, Generation 1 and Generation 2 lives, but only Generation 2 works. If the population in Generation 2 is 100 persons, and the productivity in Period 1 is 20 yen per person, 2000 yen worth goods and services are produced.\n\n\nCode\ntiny_model &lt;- function(population_growth, productivity_growth, saving_rate = NULL) {\n  by_generation &lt;- tibble(\n    Generation = 1:7,\n    population = 100 * c(1, cumprod(population_growth)),\n    reproduce_rate = c(population_growth, NA)\n  )\n  \n  by_period &lt;- tibble(\n    Period = 1:6,\n    pop_retired = by_generation$population[-7],\n    pop_working = by_generation$population[-1],\n    productivity = 20 * c(1, cumprod(productivity_growth))\n  )\n  \n  by_period &lt;- by_period %&gt;% \n    mutate(\n      pop_total = pop_retired + pop_working,\n      retired_ratio_pop = pop_retired / pop_total,\n      GDP = productivity * pop_working\n    )\n  \n  if (is.null(saving_rate)) {\n    saving_rate &lt;- by_period$retired_ratio_pop\n  }\n  \n  by_period &lt;- by_period %&gt;% \n    mutate(\n      consump_working = GDP * (1 - saving_rate),\n      consump_retired = GDP - consump_working,\n      percap_cons_wk = consump_working / pop_working,\n      percap_cons_re = consump_retired / pop_retired,\n      # real interest rate per year\n      annual_interest_rate = ((consump_retired / lag(consump_retired))^(1/30) - 1) * 100,\n      debt_GDP_ratio = consump_retired / GDP\n    )\n\n  by_generation &lt;- by_generation %&gt;% \n    bind_cols(\n      tibble(\n          consump_working = c(NA, by_period$consump_working[-11]),\n          consump_retired = c(by_period$consump_retired, NA)\n      )\n    )\n  \n  by_generation &lt;- by_generation %&gt;% \n    mutate(\n      consumption = consump_working + consump_retired,\n      income_from_work = c(NA, by_period$GDP),\n      income_from_interest = consumption - income_from_work,\n      percap_consump = consumption / population,\n      percap_income_from_work = income_from_work / population,\n      percap_income_from_interest = income_from_interest / population,\n      percap_cons_wk = c(NA, by_period$percap_cons_wk),\n      percap_cons_re = percap_consump - percap_cons_wk\n      )\n  \n  list(\n    by_period = by_period,\n    by_generation = by_generation\n  )\n}\n\n\nFrom Period 2 and on, let us assume population by Generation is constant 100 persons, population by Period is constant 200 persons, and productivity is constant 20 yen per person. And let us assume working Generation and retired Generation in each Period agree to share the produced so that each person can consume equally. As each working Generation consume half of what they produce, the saving rate is 0.5.\n\n\nCode\n# multiplier by Generation, 30 years, is constant 1 for Generation 2 to 7\npopulation_growth &lt;- rep(1, 6)\n\n# multiplier by Period, 30 years, is constant 1 for Period 2 to 6\nproductivity_growth &lt;- rep(1, 5) \n\nmodel1 &lt;- tiny_model(population_growth, productivity_growth)\n\nmodel1$by_period %&gt;% \n  select(Period, pop_total, pop_retired, pop_working, retired_ratio_pop) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\",\n      \"Population Total (persons)\",\n      \"Population Retired (persons)\",\n      \"Population Working (persons)\",\n      \"Ratio of Retired\"\n      )\n    )\n\n\n\n\nTable 1: Population by Period\n\n\n\n\n\n\n\n\n\nPeriod\nPopulation Total (persons)\nPopulation Retired (persons)\nPopulation Working (persons)\nRatio of Retired\n\n\n\n\n1\n200\n100\n100\n0.5\n\n\n2\n200\n100\n100\n0.5\n\n\n3\n200\n100\n100\n0.5\n\n\n4\n200\n100\n100\n0.5\n\n\n5\n200\n100\n100\n0.5\n\n\n6\n200\n100\n100\n0.5\n\n\n\n\n\n\n\n\nCode\nmodel1$by_period %&gt;% \n  select(Period, productivity, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Productivity (yen/person)\",\n      \"Consumption by Working (yen/person)\",\n      \"Consumption by Retired (yen/person)\"\n    )\n  )\n\n\n\n\nTable 2: Production and Consumption per person by Period\n\n\n\n\n\n\n\n\nPeriod\nProductivity (yen/person)\nConsumption by Working (yen/person)\nConsumption by Retired (yen/person)\n\n\n\n\n1\n20\n10\n10\n\n\n2\n20\n10\n10\n\n\n3\n20\n10\n10\n\n\n4\n20\n10\n10\n\n\n5\n20\n10\n10\n\n\n6\n20\n10\n10\n\n\n\n\n\n\n\n\nCode\nmodel1$by_period %&gt;% \n  select(Period, GDP:consump_retired, debt_GDP_ratio) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Consumption by Retired (yen)\",\n      \"Government debt to GDP ratio = Saving rate\"\n      )\n  )\n\n\n\n\nTable 3: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Working (yen)\nConsumption by Retired (yen)\nGovernment debt to GDP ratio = Saving rate\n\n\n\n\n1\n2000\n1000\n1000\n0.5\n\n\n2\n2000\n1000\n1000\n0.5\n\n\n3\n2000\n1000\n1000\n0.5\n\n\n4\n2000\n1000\n1000\n0.5\n\n\n5\n2000\n1000\n1000\n0.5\n\n\n6\n2000\n1000\n1000\n0.5\n\n\n\n\n\n\nEach Generation n produces 20 yen per person in Period n-1 , and consumes 10 yen in Period n-1 and 10 yen in Period n, 20 yen in total. Note that every yen value is in real, denoted in Period 1 price level yen.\n\n\nCode\nmodel1$by_generation %&gt;% \n  select(Generation, population, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \"Population (persons)\",\n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    )\n  )\n\n\n\n\nTable 4: Consumption per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nPopulation (persons)\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\n100\nNA\nNA\nNA\n\n\n2\n100\n20\n10\n10\n\n\n3\n100\n20\n10\n10\n\n\n4\n100\n20\n10\n10\n\n\n5\n100\n20\n10\n10\n\n\n6\n100\n20\n10\n10\n\n\n7\n100\nNA\n10\nNA\n\n\n\n\n\n\n\n\nUnfunded gift and its reversal\nNow imagine, in Period 2, Generation 2 and 3 agree to change sharing ratio from 50:50 to 60:40 by Generation 3 buying additional bonds and Government giving the received money to Generation 2. Generation 3’s saving rate changes from 0.5 to 0.6. Generation 3 may have been persuaded, as consumption in life will be unchanged 20 yen per person if the same custom continues, that is Generation 4 will save 0.6 in Period 3. Generation 2 can benefit from this deal, as they can consume 22 yen per person more than 20 yen they produce in life.\nAnd imagine, in Period 5, Generation 5 and 6 agree to abolish this custom for some reason. Generation 5 can consume only 18 yen per person in life. Consumption of 2 yen per person is transferred to Generation 2 from Generation 5, a future generation.\n\n\nCode\n# 0.5 in Period 1, 0.6 in Period 2 to 4, and 0.5 in Period 5 to 6\nsaving_rate &lt;- c(0.5, rep(0.6, 3), rep(0.5, 2)) \n\n\n\n\nCode\n# multiplier by Generation, 30 years, is constant 1 for Generation 2 to 7\npopulation_growth &lt;- rep(1, 6)\n\n# multiplier by Period, 30 years, is constant 1 for Period 2 to 6\nproductivity_growth &lt;- rep(1, 5) \n\nmodel2 &lt;- tiny_model(population_growth, productivity_growth, saving_rate)\n\n\n\n\nCode\nmodel2$by_period %&gt;% \n  select(Period, GDP:consump_retired, debt_GDP_ratio) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Consumption by Retired (yen)\",\n      \"Government debt to GDP ratio = Saving rate\"\n      )\n  )\n\n\n\n\nTable 5: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Working (yen)\nConsumption by Retired (yen)\nGovernment debt to GDP ratio = Saving rate\n\n\n\n\n1\n2000\n1000\n1000\n0.5\n\n\n2\n2000\n800\n1200\n0.6\n\n\n3\n2000\n800\n1200\n0.6\n\n\n4\n2000\n800\n1200\n0.6\n\n\n5\n2000\n1000\n1000\n0.5\n\n\n6\n2000\n1000\n1000\n0.5\n\n\n\n\n\n\n\n\nCode\nmodel2$by_generation %&gt;% \n  select(Generation, population, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \"Population (persons)\",\n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    )\n  )\n\n\n\n\nTable 6: Consumption per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nPopulation (persons)\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\n100\nNA\nNA\nNA\n\n\n2\n100\n22\n10\n12\n\n\n3\n100\n20\n8\n12\n\n\n4\n100\n20\n8\n12\n\n\n5\n100\n18\n8\n10\n\n\n6\n100\n20\n10\n10\n\n\n7\n100\nNA\n10\nNA\n\n\n\n\n\n\nBut is this Generation 5 worse-off caused by the burden of government debt on future Generations?\nNow, suppose Government suddenly discovers a new way to transfer buying power across Generation other than issuing additional bonds. The new way is tax and transfer payment, like pay-go based pension system. You may cry foul, claiming this should also be counted as government debt, though this is not bond balance. You may be right in accounting, but you can feel the difference between government debt and government promise in pension system is not solid but fluid.\nFrom this thought experiment, I would like to say the burden on future Generations is not government debt per se, but legacy social contract on how to share. Social contract made between Generation 2 and 3 becomes a legacy. Because of this legacy, Generation 3 and 4 in Period 4, and Generation 4 and 5 in Period 5 agree to share 60:40. But Generation 5 and 6 fail to keep this legacy in Period 6. This legacy turns out to be the burden on Generation 5. Generation 6 is now free from this burdensome legacy."
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#population-bonus-and-onus",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#population-bonus-and-onus",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "Population bonus and onus",
    "text": "Population bonus and onus\nIn above simulation, Generation 2 is better off and Generation 5 is worse off. Is this kind of situation rare? No. If we assume population increases and decreases, there happens population bonus and onus.\nBelow is a rough image of population changes in Japan. Generation 1 works in Period 0: 1880-1910, and Generation 7 works in Period 6: 2060-2090. In Period 4: 2000-2030, Generation 4 is retired and Generation 5 is working. Although I am in the middle of Generation 4 and 5 in reality, let us read below as if we are Generation 5.\nI assume no productivity growth. And I assume Generation n and Generation n-1 agree to share the produced by population ratio so that each person can consume equally in each Period. So government debt to GDP ratio, which is the same as the saving rate and the ratio of consumption by the retired to total consumption by definition in this model, is exactly same as population ratio of the retired in each Period.\n\n\nCode\n# multiplier by Generation, 30 years, is:\n# 1.3 for Generation 2 to 4, 0.8 for Generation 5, 0.65 for Generation 6 to 7\npopulation_growth &lt;- c(rep(1.3, 3), 0.8, rep(0.65, 2))\n\n# multiplier by Period, 30 years, is constant 1 for Period 2 to 6\nproductivity_growth &lt;- rep(1, 5) \n\nmodel3 &lt;- tiny_model(population_growth, productivity_growth)\n\n\n\n\nCode\nmodel3$by_generation %&gt;% \n  select(Generation, population, reproduce_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \"Population (persons)\",\n      \"Reproduce rate\"\n    ),\n    digits = c(rep(0, 2), 2)\n  )\n\n\n\n\nTable 7: Population by Generation\n\n\nGeneration\nPopulation (persons)\nReproduce rate\n\n\n\n\n1\n100\n1.30\n\n\n2\n130\n1.30\n\n\n3\n169\n1.30\n\n\n4\n220\n0.80\n\n\n5\n176\n0.65\n\n\n6\n114\n0.65\n\n\n7\n74\nNA\n\n\n\n\n\n\n\n\nCode\nmodel3$by_period %&gt;% \n  select(Period, pop_total, pop_retired, pop_working, retired_ratio_pop) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\",\n      \"Population Total (persons)\",\n      \"Population Retired (persons)\",\n      \"Population Working (persons)\",\n      \"Ratio of Retired\"\n      ),\n    digits = c(rep(0, 4), 2)\n    )\n\n\n\n\nTable 8: Population by Period\n\n\n\n\n\n\n\n\n\nPeriod\nPopulation Total (persons)\nPopulation Retired (persons)\nPopulation Working (persons)\nRatio of Retired\n\n\n\n\n1\n230\n100\n130\n0.43\n\n\n2\n299\n130\n169\n0.43\n\n\n3\n389\n169\n220\n0.43\n\n\n4\n395\n220\n176\n0.56\n\n\n5\n290\n176\n114\n0.61\n\n\n6\n189\n114\n74\n0.61\n\n\n\n\n\n\n\n\nCode\nmodel3$by_period %&gt;% \n  select(Period, GDP:consump_retired, debt_GDP_ratio, annual_interest_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Consumption by Retired (yen)\",\n      \"Government debt to GDP ratio = Saving rate\",\n      \"Interest rate (percent)\"\n      ),\n    digits = c(rep(0, 4), rep(2, 2))\n  )\n\n\n\n\nTable 9: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Working (yen)\nConsumption by Retired (yen)\nGovernment debt to GDP ratio = Saving rate\nInterest rate (percent)\n\n\n\n\n1\n2600\n1470\n1130\n0.43\nNA\n\n\n2\n3380\n1910\n1470\n0.43\n0.88\n\n\n3\n4394\n2484\n1910\n0.43\n0.88\n\n\n4\n3515\n1562\n1953\n0.56\n0.07\n\n\n5\n2285\n900\n1385\n0.61\n-1.14\n\n\n6\n1485\n585\n900\n0.61\n-1.43\n\n\n\n\n\n\nGeneration 2 worked in Period 1 and saved 1130 yen, and can consume 1470 yen in Period 2. How come? We can interpret this as Generation 2 earned interest income from saving, and the interest rate of bonds is 0.88 percent annually.\nGeneration 5 saved 1953 yen in Period 4, but can consume only 1385 in Period 5. We can interpret this as Generation 5 earned negative interest rate, -1.14 percent, in Period 5.\nAs the yen value is denoted in real terms, at Period 1 price level, interest rate is real interest rate. In this model, safe real interest rate is endogenous. Positive interest rate is a bonus, and negative one is an onus from population changes.\n\n\nCode\nmodel3$by_generation %&gt;% \n  select(Generation, population, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \"Population (persons)\",\n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    ),\n    digits = c(rep(0, 2), rep(1, 3))\n  )\n\n\n\n\nTable 10: Consumption per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nPopulation (persons)\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\n100\nNA\nNA\nNA\n\n\n2\n130\n22.6\n11.3\n11.3\n\n\n3\n169\n22.6\n11.3\n11.3\n\n\n4\n220\n20.2\n11.3\n8.9\n\n\n5\n176\n16.8\n8.9\n7.9\n\n\n6\n114\n15.8\n7.9\n7.9\n\n\n7\n74\nNA\n7.9\nNA\n\n\n\n\n\n\nEach Generation produces 20 yen per person. Generation 2 and 3 consumes more than 20 yen, Generation 4 consumes approximately 20 yen, and Generation 5 and 6 consumes less than 20 yen.\n\n\nCode\nmodel3$by_generation %&gt;% \n  select(Generation, percap_consump, percap_income_from_work, percap_income_from_interest) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \"Consumption in Total (yen/person)\",\n      \"Income in Working (yen/person)\",\n      \"Income in Retired (interest income) (yen/person)\"\n    ),\n    digits = c(0, rep(1, 3))\n\n  )\n\n\n\n\nTable 11: Consumption and Income per person by Generation\n\n\n\n\n\n\n\n\nGeneration\nConsumption in Total (yen/person)\nIncome in Working (yen/person)\nIncome in Retired (interest income) (yen/person)\n\n\n\n\n1\nNA\nNA\nNA\n\n\n2\n22.6\n20\n2.6\n\n\n3\n22.6\n20\n2.6\n\n\n4\n20.2\n20\n0.2\n\n\n5\n16.8\n20\n-3.2\n\n\n6\n15.8\n20\n-4.2\n\n\n7\nNA\n20\nNA\n\n\n\n\n\n\nWe, Generation 5, can consume 16.8 yen per person, less than 20 yen we produce. Why is interest income from holding bonds negative? Isn’t this unfair? In theory, this is because we chose to have fewer children, Generation 6, who produce and share in Period 5. But as we, Generation 5, outnumber Generation 6, we may fight politically and get larger share in Period 5. This is so called “Silver Democracy.” If we do so, government debt to GDP ratio jumps from current 0.61. And this social contract on how to share may become the burdensome legacy for future Generations."
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#add-productivity-growth-and-stagnation",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#add-productivity-growth-and-stagnation",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "Add productivity growth and stagnation",
    "text": "Add productivity growth and stagnation\n\n\nCode\n# Reproduce rate over Generation, 30 years:\npopulation_growth &lt;- c(rep(1.3, 3), 0.8, rep(0.65, 2))\n\n# Annual growth rates in percent from Period 2 to 6\nprod_gr_annual &lt;- c(2, 8, 1, 0, 0)\n\nproductivity_growth &lt;- ((prod_gr_annual + 100) / 100) ^ 30\n\n\nNext, I change the assumption of productivity from constant to growing by annual rate of 2, 8, 1, 0, 0 percent in Period 2 to 6 respectively.\nI assume Generation n and Generation n-1 agree to share the produced by population ratio so that each person can consume equally in each Period. No “Silver Democracy.”\n\n\nCode\nmodel4 &lt;- tiny_model(population_growth, productivity_growth)\n\nmodel4$by_period %&gt;% \n  select(Period, productivity, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Productivity (yen/person)\",\n      \"Consumption by Working (yen/person)\",\n      \"Consumption by Retired (yen/person)\"\n    ),\n    digits = c(rep(0, 4))\n  )\n\n\n\n\nTable 12: Production and Consumption per person by Period\n\n\n\n\n\n\n\n\nPeriod\nProductivity (yen/person)\nConsumption by Working (yen/person)\nConsumption by Retired (yen/person)\n\n\n\n\n1\n20\n11\n11\n\n\n2\n36\n20\n20\n\n\n3\n365\n206\n206\n\n\n4\n491\n218\n218\n\n\n5\n491\n194\n194\n\n\n6\n491\n194\n194\n\n\n\n\n\n\n\n\nCode\nmodel4$by_period %&gt;% \n  select(Period, GDP:consump_retired, debt_GDP_ratio, annual_interest_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Consumption by Retired (yen)\",\n      \"Government debt to GDP ratio = Saving rate\",\n      \"Interest rate (percent)\"\n      ),\n    digits = c(rep(0, 4), rep(2, 2))\n  )\n\n\n\n\nTable 13: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Working (yen)\nConsumption by Retired (yen)\nGovernment debt to GDP ratio = Saving rate\nInterest rate (percent)\n\n\n\n\n1\n2600\n1470\n1130\n0.43\nNA\n\n\n2\n6122\n3460\n2662\n0.43\n2.90\n\n\n3\n80090\n45268\n34822\n0.43\n8.95\n\n\n4\n86359\n38382\n47977\n0.56\n1.07\n\n\n5\n56134\n22113\n34020\n0.61\n-1.14\n\n\n6\n36487\n14374\n22113\n0.61\n-1.43\n\n\n\n\n\n\n\n\nCode\nmodel4$by_generation %&gt;% \n  select(Generation, population, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \"Population (persons)\",\n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    ),\n    digits = c(rep(0, 5))\n  )\n\n\n\n\nTable 14: Consumption per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nPopulation (persons)\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\n100\nNA\nNA\nNA\n\n\n2\n130\n32\n11\n20\n\n\n3\n169\n227\n20\n206\n\n\n4\n220\n424\n206\n218\n\n\n5\n176\n412\n218\n194\n\n\n6\n114\n387\n194\n194\n\n\n7\n74\nNA\n194\nNA\n\n\n\n\n\n\n\n\nCode\nmodel4$by_generation %&gt;% \n  select(Generation, percap_consump, percap_income_from_work, percap_income_from_interest) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \"Consumption in Total (yen/person)\",\n      \"Income in Working (yen/person)\",\n      \"Income in Retired (interest income) (yen/person)\"\n    ),\n    digits = c(rep(0, 4))\n\n  )\n\n\n\n\nTable 15: Consumption and Income per person by Generation\n\n\n\n\n\n\n\n\nGeneration\nConsumption in Total (yen/person)\nIncome in Working (yen/person)\nIncome in Retired (interest income) (yen/person)\n\n\n\n\n1\nNA\nNA\nNA\n\n\n2\n32\n20\n12\n\n\n3\n227\n36\n190\n\n\n4\n424\n365\n60\n\n\n5\n412\n491\n-79\n\n\n6\n387\n491\n-104\n\n\n7\nNA\n491\nNA\n\n\n\n\n\n\nShocking result for us, Generation 5! We consume 412 yen per person, which is less than 491 yen we produce, and less than 424 yen Generation 4 consumes. Generation 5 is the first generation to become poorer than preceding Generation.\nThis happens because I assume that productivity growth is zero in Period 5 when Generation 6 works, and that population reproduce rate by Generation 5 is less than 1."
  },
  {
    "objectID": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#multi-equilibrium-hypothesis-on-inflation",
    "href": "posts/2021-05-06-gov-t-debt-is-savings-of-the-workers-for-retirement/index.html#multi-equilibrium-hypothesis-on-inflation",
    "title": "Gov’t debt is savings of the workers for retirement",
    "section": "Multi-equilibrium hypothesis on inflation",
    "text": "Multi-equilibrium hypothesis on inflation\nInterest rate in Period 5, 2030-2060, is negative, -1.14 percent. That is the return by holding bonds for Generation 5 who live retired in Period 5. How can we get negative interest rate? The answer is inflation. Nominal interest rate can’t be much negative as long as paper money remains as an alternative way of saving. But real interest rate can be negative with inflation.\nThis simulation suggests that it is possible for Bank of Japan to achieve 2 percent inflation target before long, as interest rate in Period 5 can be interpreted as a return rate we get by buying bonds in 2015 and selling in 2045 on average. Inflation is 2 percent, nominal interest rate is 0.86, and real interest rate is -1.14 on average from 2015 to 2045.\nOf course, this is a simulation, not a prediction. But I can say that aging and decreasing population and stagnant productivity growth leads to inflation eventually in this model. Is this model, which assumes one factor no business sector closed economy, too unrealistic? In reality, there is business and foreign sector, investment, international trade and wage negotiation. Aging and decreasing population prompts businesses to reduce investment. Stagnant productivity growth prompts businesses to be tough in wage negotiations. Balassa-Samuelson effect works in reverse. Does aging and decreasing population and stagnant productivity growth lead to deflation, instead of inflation, in reality?\nI am not sure whether I can and should expand this model by adding factors and sectors to make it closer to reality. So I would like to propose my thinking as a hypothesis. I think there exists multi-equilibrium on inflation. Although prospect for Generation 6 population is close to certain, prospect for productivity growth is still uncertain. We are often told we will be replaced by AI in the work place. If it is true, it will be a huge jump in productivity. Abundant production capacity can satisfy all the demands. As long as we believe so, there is no inflation pressure. This is the first equilibrium. But if productivity growth statistics continues to show otherwise and to disappoint us, we Generation 5 will someday accept the idea that we can’t consume as much as we saved, and that we must be poorer than Generation 4. On that day, we rush to consume by trying to get more share of consumption from each other in Generation 5 and/or from Generation 6. As buying power exceeds production capacity, inflation pressure mounts, and inflation will come. This is the second equilibrium. I am not hinting at hyper-inflation. Modest inflation is enough.\nThank you for reading a long thought experiment."
  },
  {
    "objectID": "posts/2019-05-30-japan-international-trade/index.html",
    "href": "posts/2019-05-30-japan-international-trade/index.html",
    "title": "Japan international trade",
    "section": "",
    "text": "I have downloaded a lot of csv files from e-Stat, and created a Shiny app which shows Japan international trade situations.\nhttps://mitsuoxv.shinyapps.io/jp-trade/"
  },
  {
    "objectID": "posts/2020-10-27-correction-who-pays-tariffs/index.html",
    "href": "posts/2020-10-27-correction-who-pays-tariffs/index.html",
    "title": "Correction: who pays tariffs",
    "section": "",
    "text": "Yesterday I noticed my analysis on who pays tariffs in US imports from China is totally incompatible with the import price movement in total.\nToday I added correction to my analysis. I guess my mistake came from unit revision by Census bureau at the start of the year, which generated a lot of zero price indices.\nThis is my second major correction. My first one was about [China retaliation values] (https://mitsuoxv.rbind.io/2019/06/21/correction-china-hits-back-as-much-as-the-size-of-its-claim/), and I learned that Harmonized Tariff Schedule is not harmonized at some level.\nThis time I have learned unit in US trade data may be different over years. In added correction, I just removed zero values and zero price indices. This is tentative correction. I may have to find out how to keep unit consistency."
  },
  {
    "objectID": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html",
    "href": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html",
    "title": "Assist Prof Narita tests us by his mistakes",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(dagitty)\n\ntheme_set(theme_light())"
  },
  {
    "objectID": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#assist-prof-narita-did-a-meta-analysis-on-the-effectiveness-of-ebpm",
    "href": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#assist-prof-narita-did-a-meta-analysis-on-the-effectiveness-of-ebpm",
    "title": "Assist Prof Narita tests us by his mistakes",
    "section": "Assist Prof Narita did a meta-analysis on the effectiveness of EBPM",
    "text": "Assist Prof Narita did a meta-analysis on the effectiveness of EBPM\nAssistant Professor Narita of Yale University wrote an article in a book on EBPM (Evidence-Based Policy-Making) which was published in Japan in December 2022. In his article, he did a meta-analysis on the effectiveness of EBPM by checking whether RFI (Results First Initiative), which supported states in the U.S. from 2010 to 2023 by EBPM methods and is now concluded, really helped states reduce crimes. From his article, I quote two pages below:\n\n\n\nA part of meta-analysis\n\n\n“***” in the right table means p-value is less than 0.01. This table looks too good to be true to me. So I try to reproduce his meta-analysis."
  },
  {
    "objectID": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#this-is-not-a-natural-experiment-contrary-to-his-assertion",
    "href": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#this-is-not-a-natural-experiment-contrary-to-his-assertion",
    "title": "Assist Prof Narita tests us by his mistakes",
    "section": "This is not a natural experiment, contrary to his assertion",
    "text": "This is not a natural experiment, contrary to his assertion\nHe asserts this is a natural experiment, as some states joined RFI and others didn’t.\nIf joining states are selected at random by some accidents, it is a natural experiment. In this case states voluntarily joins RFI, so this is not a natural experiment. Z (states’ willingness to join RFI) is a confound between X (RFI support) and Y (an outcome) like below. Even if X is associated with Y, it may be caused by Z.\n\n\nCode\nrfi_dag &lt;- dagitty(\"dag{\n  X &lt;- Z -&gt; Y\n  X -&gt; Y\n}\")\n\ncoordinates(rfi_dag) &lt;- list(x = c(X = 0, Z = 1, Y = 2),\n                            y = c(X = 1, Z = 0, Y = 1))\n\nrethinking::drawdag(rfi_dag)\n\n\n\n\n\nFigure 1: DAG with a confound\n\n\n\n\nX: RFI support based on EBPM\nY: Outcome of crimes\nZ: Governor or State Congress\nFor now, however, I pretend this is a natural experiment, and move on."
  },
  {
    "objectID": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#which-states-joined-rfi-and-when",
    "href": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#which-states-joined-rfi-and-when",
    "title": "Assist Prof Narita tests us by his mistakes",
    "section": "Which states joined RFI, and when?",
    "text": "Which states joined RFI, and when?\nI get the info on which states joined RFI and when from this page. As there must be 27 states, I count Salt Lake County, Utah as Utah state. Although some California counties joined in 2013, I count California in 2016 when California state joined.\n\n\nCode\nstates_join &lt;- tribble(\n  ~state, ~year_join,\n  \"North Carolina\", \"December 2017\",\n  \"Alabama\", \"August 2017\",\n  \"Minnesota\", \"June 2015\",\n  \"California\", \"January 2016\",\n  \"Mississippi\", \"December 2012\",\n  \"Colorado\", \"summer 2014\",\n  \"New Mexico\", \"2011\",\n  \"Illinois\", \"fall of 2011\",\n  \"New York\", \"late 2011\",\n  \"Iowa\", \"May 2011\",\n  \"Alaska\", \"March 2015\",\n  \"Nevada\", \"August 2014\",\n  \"Oregon\", \"January 2012\",\n  \"Connecticut\", \"March 2011\",\n  \"Pennsylvania\", \"March 2017\",\n  \"Rhode Island\", \"March 2013\",\n  \"Delaware\", \"August 2015\",\n  \"Utah\", \"June 2017\",\n  \"Florida\", \"October 2015\",\n  \"Texas\", \"December 2011\",\n  \"Idaho\", \"February 2011\",\n  \"Vermont\", \"November 2011\",\n  \"Kansas\",  \"2011\",\n  \"West Virginia\", \"July 2014\",\n  \"Massachusetts\", \"March 2012\",\n  \"Wisconsin\", \"fall 2013 Several months later\",\n  \"Montana\", \"May 2017\"\n) |&gt; \n  mutate(year_join = parse_number(year_join)) |&gt; \n  arrange(state)\n\n\n\n\nCode\nstates_join |&gt; \n  mutate(state = state |&gt; \n           fct_reorder(year_join) |&gt; \n           fct_rev()) |&gt; \n  ggplot(aes(year_join, state)) +\n  geom_point() +\n  scale_x_continuous(breaks = 2011:2017) +\n  labs(x = NULL, y = NULL,\n       title = \"27 states joined RFI from 2011 to 2017\") +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\nFigure 2: 27 states joined RFI (Results First Initiative)"
  },
  {
    "objectID": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#replicate-the-quoted-figure",
    "href": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#replicate-the-quoted-figure",
    "title": "Assist Prof Narita tests us by his mistakes",
    "section": "Replicate the quoted figure",
    "text": "Replicate the quoted figure\nStatistically significant at 0.01 items in the quoted table above are all U.S. prison data, like prisoners, sentenced prisoners, custody population, admissions and releases. So, I have prepared those data in my GitHub repo. For simplicity, I use only prisoners here.\n\n\nCode\nprisoners &lt;- read_csv(\"https://raw.githubusercontent.com/mitsuoxv/us-prison/main/prisoners.csv\")\n\nprisoners_long &lt;- prisoners |&gt; \n  pivot_longer(-state, names_to = \"year\", values_to = \"prisoners\") |&gt; \n  mutate(year = as.numeric(year)) |&gt; \n  arrange(state, year)\n\n\nJudging from the quoted figure, I guess he regards 17 states which joined between 2011 and 2014 as treatment group, and the rest 33 states as control group. I replicate the quoted figure in the left below.\nI also plot both treatment and control groups in Y-axis including zero in the right below. I set 2012 as 0 in X-axis in the control group.\n\n\nCode\nstates_join_upto_2014 &lt;- states_join |&gt; \n  filter(year_join &lt;= 2014)\n\nprisoners_long2 &lt;- prisoners_long |&gt; \n  left_join(states_join_upto_2014, by = \"state\") |&gt; \n  mutate(\n    group = if_else(is.na(year_join), \"Control\", \"Treatment\"),\n    year_join = coalesce(year_join, 2012),\n    diff_year = year - year_join\n  )\n\nprisoners_long2 |&gt; \n  filter(group == \"Treatment\") |&gt; \n  filter(between(diff_year, -3, 3)) |&gt; \n  group_by(diff_year) |&gt; \n  summarize(prisoners = mean(prisoners)) |&gt; \n  ggplot(aes(diff_year, prisoners)) +\n  geom_line() +\n  geom_vline(xintercept = 0, lty = 2) +\n  scale_x_continuous(breaks = -3:3) +\n  labs(x = \"years before or after the joined year\",\n       title = \"Average number of prisoners in treatment group (17 states)\") +\n  theme(panel.grid.minor = element_blank())\n\nprisoners_long2 |&gt; \n  filter(between(diff_year, -3, 3)) |&gt; \n  group_by(group, diff_year) |&gt; \n  summarize(prisoners = mean(prisoners), .groups = \"drop\") |&gt; \n  ggplot(aes(diff_year, prisoners)) +\n  geom_line(aes(color = group)) +\n  geom_vline(xintercept = 0, lty = 2) +\n  scale_x_continuous(breaks = -3:3) +\n  expand_limits(y = 0) +\n  labs(x = \"years before or after the joined year\",\n       title = \"Average number of prisoners per state\") +\n  theme(panel.grid.minor = element_blank(),\n        legend.position = \"top\")\n\n\n\n\n\n\n\nFigure 3: Replica of the quoted figure\n\n\n\n\n\n\n\nFigure 4: Modified version of the replica"
  },
  {
    "objectID": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#replicate-the-row-of-prisoners-in-the-quoted-table",
    "href": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#replicate-the-row-of-prisoners-in-the-quoted-table",
    "title": "Assist Prof Narita tests us by his mistakes",
    "section": "Replicate the row of prisoners in the quoted table",
    "text": "Replicate the row of prisoners in the quoted table\nAs the quoted figure shows -3 to 3 years from the joined year of the states which joined from 2011 to 2014, I use data from 2008 to 2017, and set “rfi” 0 in the years upto the joined year and 1 in the years beyond the joined year. Alaska, Delaware, Florida and Minnesota which joined in 2015 get 1 in “rfi” in 2016 and 2017, and California which joined in 2016 gets 1 in “rfi” in 2017. So the treatment group is now 22 states, and the control group is 28 states.\n\n\nCode\ndat &lt;- prisoners_long |&gt; \n  left_join(states_join, by = \"state\") |&gt; \n  filter(between(year, 2008, 2017)) |&gt; \n  mutate(\n    year_join = coalesce(year_join, Inf),\n    rfi = if_else(year &gt; year_join, 1, 0),\n    state = factor(state),\n    year = factor(year)\n    ) |&gt; \n  select(!year_join)\n\n\nHe asserts he has used DiD (Difference-in-Difference) method to make the quoted table, writes standard errors are clustered by state with the two-way (state and year) fixed effect model equation in the footnote of the table.\nAs he refers to the 4th chapter in Primer for causal inference by Shota Yasui, he must have used miceadds::lm.cluster() to get clustered standard errors. So I also use miceadds::lm.cluster().\nThe table below comes from two-way (state and year) fixed effect model: DiD. Coefficient “rfi” estimate is -248, and p-value is 0.709. This does not look like the quoted table.\n\n\nCode\nlm_2fe_summary &lt;- miceadds::lm.cluster(formula = prisoners ~ state + year + rfi,\n                     data = dat, cluster = \"state\") |&gt; \n  summary()\n\n\n\n\nCode\nlm_2fe_summary[60, ] |&gt; \n  knitr::kable()\n\n\n\n\nTable 1: Coefficient “rfi” from two-way (state and year) fixed effect model that is DiD\n\n\n\nx\n\n\n\n\nEstimate\n-248.0280061\n\n\nStd. Error\n664.0861555\n\n\nt value\n-0.3734877\n\n\nPr(&gt;|t|)\n0.7087855\n\n\n\n\n\n\nSo I try the one-way (state) fixed effect model in the right table. Now, estimate is -1415, and p-value is 0.019. Although p-value is slightly larger than 0.01, this looks similar to the quoted table. The problem is this is not DiD. Negative estimate merely reflects downward trend in nearly all states.\n\n\nCode\nlm_1fe_summary &lt;- miceadds::lm.cluster(formula = prisoners ~ state + rfi,\n                     data = dat, cluster = \"state\") |&gt; \n  summary()\n\n\n\n\nCode\nlm_1fe_summary[51, ] |&gt; \n  knitr::kable()\n\n\n\n\nTable 2: Coefficient “rfi” from one-way (state) fixed effect model that is not DiD\n\n\n\nx\n\n\n\n\nEstimate\n-1415.3431579\n\n\nStd. Error\n602.4018194\n\n\nt value\n-2.3495001\n\n\nPr(&gt;|t|)\n0.0187986"
  },
  {
    "objectID": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#conclusion",
    "href": "posts/2023-06-10-assist-prof-narita-tests-us-by-his-mistakes/index.html#conclusion",
    "title": "Assist Prof Narita tests us by his mistakes",
    "section": "Conclusion",
    "text": "Conclusion\nWhile I try to reproduce his work, I find that he wrongly recognized the data came from a natural experiment, and that he failed to do DiD, probably due to a coding error. Is he so careless? Maybe. Or maybe not. I suspect he may have tested us. If we are easily deceived by statistical junks, EBPM can be harmful. After all, he titled his article as “Wish Death of EBPM!”\nThis is my second post to criticize Assist. Prof. Narita’s work. First one is here."
  },
  {
    "objectID": "posts/2021-04-09-shiny-app-and-environments/index.html",
    "href": "posts/2021-04-09-shiny-app-and-environments/index.html",
    "title": "Shiny app and environments",
    "section": "",
    "text": "I transformed my Shiny app, imfweo, into a R package. GitHub repo is here. In the process, I fell into trouble, as I didn’t understand the namespace issues. So I did some experiments, using the monthApp example in “Matering Shiny”, and reading the Chapter 7.4.3 Namespaces in “Advanced R”. Both books are written by Hadley Wickham. As always, thank you, Hadley. I write this post which shows my understanding as of today to help future me."
  },
  {
    "objectID": "posts/2021-04-09-shiny-app-and-environments/index.html#motivation",
    "href": "posts/2021-04-09-shiny-app-and-environments/index.html#motivation",
    "title": "Shiny app and environments",
    "section": "",
    "text": "I transformed my Shiny app, imfweo, into a R package. GitHub repo is here. In the process, I fell into trouble, as I didn’t understand the namespace issues. So I did some experiments, using the monthApp example in “Matering Shiny”, and reading the Chapter 7.4.3 Namespaces in “Advanced R”. Both books are written by Hadley Wickham. As always, thank you, Hadley. I write this post which shows my understanding as of today to help future me."
  },
  {
    "objectID": "posts/2021-04-09-shiny-app-and-environments/index.html#namespace-issues",
    "href": "posts/2021-04-09-shiny-app-and-environments/index.html#namespace-issues",
    "title": "Shiny app and environments",
    "section": "Namespace issues",
    "text": "Namespace issues\n“Where does a function find non-argument variables, like a function name and a data name?” I call this namespace issues."
  },
  {
    "objectID": "posts/2021-04-09-shiny-app-and-environments/index.html#experiments-using-the-monthapp-example-in-matering-shiny",
    "href": "posts/2021-04-09-shiny-app-and-environments/index.html#experiments-using-the-monthapp-example-in-matering-shiny",
    "title": "Shiny app and environments",
    "section": "Experiments using the monthApp example in “Matering Shiny”",
    "text": "Experiments using the monthApp example in “Matering Shiny”\n\nA single file: Ctl + Shift + Enter, it works fine, and Global Environment is empty.\nA single file: Ctl + Enter, eack line works fine, and Global Environment is filled with function names like birthstoneServer and a data name like stones\n\nThis experiment suggests that the usual way, Ctl + Shift + Enter in app.R, runs in a function execution environment, not in Global Environment. Let us call this environment monthApp execution environment, even if monthApp is not yet here. I guess the file which contains shinyApp(ui, server) is so special that it creates a function which encloses all the codes.\n\nA single file: Change stones to units, and Ctl + Shift + Enter, it still works.\n\nDon’t forget to restart R at each experiment. Note that units is a function name in Base Environment. As birthstoneServer function is defined in monthApp execution environment, it can find units there.\n\nModule files: Ctl + Shift + Enter, and you will see “Error: object ‘stones’ not found”\nModule files: Ctl + Enter, stones &lt;- vroom:: line, and create stones in Global Environment. And then, Ctl + Shift + Enter, it works fine.\nModule files: Change stones to units, Ctl + Shift + Enter, and you will see “Error: object of type ‘closure’ is not subsettable”.\nModule files: Then, create units in Global Environment, it works fine.\n\nLet us call the environment in which variables, such as birthstoneServer function, are defined, R directory environment: monthApp execution environment is its ephemeral child environment, and Global Environment is its parent environment. Look at the last figure in Chapter 7.4.3 Namespaces in “Advanced R”, and insert R directory environment left to Global Environment. As there is no namespace: R directory environment, birthstoneServer function searches stones or units only in the lower row of the figure. If stones or units is in Global Environment, it can find there. If not, it can’t find stones, or can find units as a function in Base Environment.\n\nModule files: Create a new file stones.R and move stones &lt;- vroom:: line there, and it works fine.\nModule files: Change stones to units, create a new file units.R and move units &lt;- vroom:: line there, and it works fine.\n\nIn this case, stones or units and birthstoneServer exist in the same R directory environment, so birthstoneServer can find stones or units there before searching Base Environment, or even Global Environment.\n\nA package: Leave stones &lt;- vroom:: line in monthApp: “Error: object ‘stones’ not found”\nA package: Leave stones &lt;- vroom:: line in monthApp: Then create stones in Global Environment, and it works fine.\nA package: Leave stones &lt;- vroom:: line in monthApp: Change stones to units, and “Error: object of type ‘closure’ is not subsettable”\nA package: Leave stones &lt;- vroom:: line in monthApp: Change stones to units, and create units in Global Environment. Still, “Error: object of type ‘closure’ is not subsettable”\n\nNow it is a package. Let us call it monthApp package. Insert package: monthApp right to Global Environment, and namespace: monthApp left to namespace: stats in the same last figure in Chapter 7.4.3 Namespaces in “Advanced R”. birthstoneServer function searches from the top left. If stones is in Global Environment, it finds there, and if not, it can’t find. Whether or not units is in Global Environment, it finds units as a function in namespace: base in the top right before searching Global Environment.\n\nA package: Take optional extra, and create data/stones.rda: It works fine.\nA package: Take optional extra, and create data/units.rda: “Error: object of type ‘closure’ is not subsettable”\n\nTaking optional extra to create a package dataset is to make sure stones or units is in Global Environment. So the results are the same as above in case stones or units exists in Global Environment."
  },
  {
    "objectID": "posts/2021-04-09-shiny-app-and-environments/index.html#for-best-practices",
    "href": "posts/2021-04-09-shiny-app-and-environments/index.html#for-best-practices",
    "title": "Shiny app and environments",
    "section": "For best practices",
    "text": "For best practices\nI don’t know what are the best practices at this moment. Joe Cheng recommends to preprocess out of Shiny what all Shiny users do in this Youtube lecture. As for imfweo package, I followed his recommendation, and created a lot of .rda files in data directory. units.rda happened to be there, and I faced “Error: object of type ‘closure’ is not subsettable”. As a solution, I first created a list, like weo$meta$units, and hoped weo doesn’t match any namespace before Global Environment. In the second thought, as I update data every half a year and can compare the current one with the previous one in rolling, I decided to pass every data variable as an argument. As result, I can be sure there will be no accidental match in namespaces, but the codes have become more difficult to read, as there are so many non-reactive arguments.\nI am not a developer but a practitioner. Environments are hard to understand. Future me, if you are confused, come back to this post."
  },
  {
    "objectID": "posts/2020-02-07-hamamatsu-city-defeated/index.html",
    "href": "posts/2020-02-07-hamamatsu-city-defeated/index.html",
    "title": "Hamamatsu-city defeated",
    "section": "",
    "text": "I have just done an annual update of “City competition to consume in Japan”. The latest year is now 2019.\nHamamatsu-city, the last year champion in consuming dumplings, was defeated by the rival Utsunomiya-city. It now ranks second.\nHamamatsu-city, 11 year in a row champion in consuming grilled eel, was badly defeated. I am surprised. Look at my shiny app. Select “level 5”, item “364 grilled eel” and year “2019”, and you will find “22130 Hamamatsu-city” is out of top 10. If you change year to any from “2008” to “2018”, you will see “22130 Hamamatsu-city” is the outstanding champion. (BTW, it was not in the list of cities in 2007.) What happened? I don’t know. It may be related to the fact that it is getting harder to catch baby eels, and that grilled eels are now expensive."
  },
  {
    "objectID": "posts/2021-08-02-money-pegged-to-the-dollar-is-prone-to-runs/index.html",
    "href": "posts/2021-08-02-money-pegged-to-the-dollar-is-prone-to-runs/index.html",
    "title": "Money pegged to the dollar is prone to runs",
    "section": "",
    "text": "I found two strange articles in Nikkei newspaper on August 2, 2021. One (Japanese) blames the floating exchange rate regime after 1971 for recurring currency crises, though it reports Lebanon abandoning the fixed exchange rate regime as an example of currency crises. The other (Japanese) tells the US Treasury’s move to regulate stablecoins is aiming to keep the dominant role of the dollar in the international payment system to keep national security. The US Treasury indeed tells it needs regulation because stablecoins pose “potential risks to end-users, the financial system, and national security”, but I think this “national security” is the concern on the collapse of the financial system, not on the possibility stablecoins replace the dollar in the international payment system.\nI briefly read “Currency crises” by Paul Krugman (1997) and “Taming Wildcat Stablecoins” by Gary Gordon and Jeffery Zhang (2021), and thought that both currency crises and stablecoins issues come from the same fact that money pegged to the dollar (greenbacks) or some other currency (central bank notes) is prone to runs.\n“Taming Wildcat Stablecoins” by Gary Gordon and Jeffery Zhang (2021) looks back into the history, and lists deposits, money market funds and stablecoins as money pegged to the dollar. Runs on bank deposits were solved by regulations, like deposit insurance. Authorities failed to regulate money market funds, and saved them on the runs arbitrarily as they were too big to fail. The paper suggests several policy choices for stablecoins, and one of them is “requiring stablecoins to be backed one-for-one with Treasuries or reserves at the central bank”. This choice is equivalent to the currency board for foreign currency pegged to the dollar, and its effectiveness depends on the perception that the requirement is indeed met, and will not be abandoned in the future. Argentina’s currency board collapsed in 2002, and Hong Kong’s currency board has survived so far."
  },
  {
    "objectID": "posts/2019-05-13-who-pays-tariffs/index.html",
    "href": "posts/2019-05-13-who-pays-tariffs/index.html",
    "title": "Who pays tariffs?",
    "section": "",
    "text": "On May 11, 2019, Japanese newspaper Nikkei reported that China pays most of the tariffs (Japanese).\nI have checked how US import price from China changed from 2018 Q2, just before the first tranche “34b” became effective, for each HTS 10 digit code item, and compared the changes by tariff schedule category. I think the numbers disagree with the Nikkei report.\nUpdate on 2019-05-15:\nMost cited studies on this issue are “The Impact of the 2018 Trade War on U.S. Prices and Welfare” by Mary Amiti, Stephen J. Redding, David Weinstein (March 2019) and “The Return to Protectionism” by Pablo D. Fajgelbaum, Pinelopi K. Goldberg, Patrick J. Kennedy, and Amit K. Khandelwal” (March 2019). Both studies say US firms and consumers pay most of the tariffs.\nThe Nikkei report cites the EconPol paper “Who is Paying for the Trade War with China?” by Benedikt Zoller-Rydzek and Gabriel Felbermayr (November 2018), which says “In this analysis we show that, contrary to public opinion, the greatest share of the tariff burden falls not on American consumers or firms, but on Chinese exporters.”"
  },
  {
    "objectID": "posts/2020-03-07-coronavirus-newly-confirmed-cases-by-each-area/index.html",
    "href": "posts/2020-03-07-coronavirus-newly-confirmed-cases-by-each-area/index.html",
    "title": "Coronavirus newly confirmed cases by each area",
    "section": "",
    "text": "I scratched numbers from the WHO situation reports, and created a shiny app to show the time-series movement of the newly confirmed cases by each area, as I would like to know whether coronavirus is being contained in Japan, or other areas.\nThe sites, like Coronavirus Situation Dashboard by WHO and Coronavirus Update by worldometer, utilize the WHO situation report numbers, but so far I could not find any API or csv files I can use. Scratching numbers from pdf files is a dirty work. I would like to update frequently, but I am not sure."
  },
  {
    "objectID": "posts/2022-03-09-overestimate-of-gasoline-price-control-effects-by-meti/index.html",
    "href": "posts/2022-03-09-overestimate-of-gasoline-price-control-effects-by-meti/index.html",
    "title": "Overestimate of gasoline price control effects by METI",
    "section": "",
    "text": "The Japanese government will increase its subsidy to gasoline wholesalers from 5 to 17.7 yen per liter on March 10, reports the Nikkei article of March 9, 2022. The article also reports that METI estimated the gasoline retail price was reduced by 6.1 yen, thanks to its 5 yen per liter subsidy on March 7.\nI have searched, and found that METI indeed published such estimates. METI transforms Dubai crude oil prices from dollar per barrel to yen per liter based on yen-dollar exchange rates, and estimates the subsidy effect by comparing the weekly average of Dubai crude oil price in yen from February 22 to 28 with the gasoline retail price in yen on March 7. So, METI assumes Dubai spot crude oil will be sent to Japan, converted into gasoline, and sold to consumers in 10 days. I think it is too short. Looking at spot prices and customs import prices of crude oil in this site, I guess it takes approximately one month for Dubai spot crude oil to be sent to Japan. If I am right, the costs for gasoline wholesalers didn’t increase on March 7 by as much as METI estimated, and 6.1 yen per liter price reduction was overestimated.\nI will revisit this issue, when February 2022 customs data are available, at my GitHub page."
  },
  {
    "objectID": "posts/2020-03-02-sentiment-analysis-of-the-economic-report-of-the-president/index.html",
    "href": "posts/2020-03-02-sentiment-analysis-of-the-economic-report-of-the-president/index.html",
    "title": "Sentiment analysis of the economic report of the president",
    "section": "",
    "text": "I tried sentiment analysis of the economic report of the president. I owe much to Len Kiefer, as I learned the techniques of sentiment analysis from his “Text Mining Fedspeak”, and the techniques to draw recession shaded areas from his “Plotting U.S. Macroeconomic Trends with FRED and R”.\nThe conclusion is not surprising. The sentiments of the presidents usually fall in or after the recession."
  },
  {
    "objectID": "posts/2021-06-16-strange-version-of-quoting-out-of-context-by-nhk/index.html",
    "href": "posts/2021-06-16-strange-version-of-quoting-out-of-context-by-nhk/index.html",
    "title": "Strange version of quoting out of context by NHK",
    "section": "",
    "text": "I was watching News Watch 9, an NHK nightly news program, on June 16, 2021. It told President Biden of the U.S. was about to meet President Putin of Russia, and it let us know there is some criticism in the U.S. that the meeting itself can be a reward to Russia.\nAnd then it quoted from Fox News opinion by Mike Pompeo, the former Secretary of State in the Trump Administration, “Biden has already signaled to Putin that he is timid and unprepared to confront the Russian challenge.” NHK didn’t mention his opinion was published on June 15, 2021.\nNext, NHK showed the White House press briefing. It quoted a question, “Can you respond to criticism from some Republicans that the administration is essentially rewarding Putin for bad behavior?” Actually the caption was shortened to “There is criticism that the meeting is rewarding Russia.” Next it quoted Press Secretary Jen Psaki replying, “It’s actually important to meet with leaders when we have a range of disagreements, as we do with Russian leaders.” “We regard it as a vital part of defending America’s interests.” NHK displayed “Last month” at the upper left corner of the screen only for two or three seconds to let us know this press briefing was held in May. I noticed this display, when I watched NHK plus App (registration required) repeatedly. Actually it was held on May 25, 2021.\nAs a brief viewer of the program, I thought Mike Pompeo criticized that the meeting is rewarding Putin, and the White House responded to his criticism. However, it can’t be so, as I found Mike Pompeo’s opinion was published on June 15, 2021, and the White House press briefing was held on May 25.\nSo I read Mike Pompeo’s opinion, and found he criticized Biden changing Trump’s course mainly in climate and energy policies. He didn’t criticize that the meeting is rewarding Putin. NHK quoted him out of context. NHK could have quoted Sen. Ben Sasse, the Nebraska Republican, saying “We’re rewarding Putin with a summit?”\nI think NHK should be ashamed of this quoting out of context."
  },
  {
    "objectID": "posts/2021-03-03-update-add-usa-map-to-covid-19-app/index.html",
    "href": "posts/2021-03-03-update-add-usa-map-to-covid-19-app/index.html",
    "title": "Update: add USA map to Covid-19 app",
    "section": "",
    "text": "I have added “in the United States (map)” panel to Covid-19 app. Click the arrow, located in the right below the slider bar, you can see how novel corona virus has spread in the United States in animation. Note the color denotes relative, not absolute, hotness, as the legend changes over time.\nIn January 2020, it landed from China in the West Coast, but failed to spread. However, in spring, it landed again, this time from Europe in the East Coast, especially New York, and spread to the Mid West, and then to the South and the West, such as Arizona. It turned to north, and arrived at North Dakota. And it spread again to the South and the West. Now, as of the end of February 2021, New York is again one of the hot states. I guess new variants have arrived from Europe, South Africa and Brazil, and native new variants have appeared. I hope vaccines will be effective enough to contain new variants.\nI was watching the United States situation in “USA, Covid-19 situation by state” using static maps, and wished to make animated maps. I happened to read some parts of “Mastering Shiny” by Hadley Wickham, and found it is fairly easy to add animate functionality to Shiny app. It is just to set animate = TRUE in sliderInput function. I first added animate functionality to my other Shiny app, “City competition to consume”.\nToday, I turned to Covid-19 app. At first, it worked fine locally, but failed in shinyapps.io. I struggled a while. Finally I added library(mapproj) to app.R, and somehow it worked. I guess library(maps) automatically loads mapproj in the local RStudio IDE, but it doesn’t in shinyapps.io."
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(lubridate)\n\ntheme_set(theme_light())\n\nlibrary(OECD)\nlibrary(countrycode)\n\nlibrary(janitor)\nlibrary(ggrepel)"
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#assertions-in-the-economic-and-fiscal-advisory-council-material",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#assertions-in-the-economic-and-fiscal-advisory-council-material",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "Assertions in the Economic and Fiscal Advisory Council material",
    "text": "Assertions in the Economic and Fiscal Advisory Council material\nThe headline of Asahi Shinbun article on April 27, 2023 (Japanese) caught my eye, which is “5 trillion increase in public expenditure for family is estimated to increase population by 0.9 to 1.8 million persons in 2060.” This article let me know the estimate on page 3 titled “Possible utilization of EBPM to analyze policy effects” in the Economic and Fiscal Advisory Council material presented by 4 private-sector members on April 26, 2023 (Japanese).\nIt shows the figure below, and warns us that correlation is not causality in the footnote. Title is “Correlation between public expenditure for family and fertility rate in OECD countries.” X-axis is percent ratio of public expenditure for family to GDP in 2017, and Y-axis is fertility rate in 2021. Red point is Japan. I find 34 points in the figure.\n\n\n\nFigure 1: Quoted figure titled correlation between public expenditure for family and fertility rate\n\n\nThen, they make a causal statement, “1 percent of GDP (5 trillion yen) increase in public expenditure for family leads to 0.05 to 0.1 increase in fertility rate. This estimate is based on 30 OECD countries data since 2010”.\nI have got confused. Do they think this figure, which does not show confidence interval, suggests correlation? And, even if it does, do they think they can morph correlation into causality by more samples from multiple years? So I have decided to get data from OECD.stat."
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#replicated-figure-with-some-tweaks",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#replicated-figure-with-some-tweaks",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "Replicated figure with some tweaks",
    "text": "Replicated figure with some tweaks\n\n\nCode\n# 38 countries\noecd_countries &lt;- c(\"ISR\", \"LUX\", \"NLD\", \"GRC\", \"ISL\", \"LVA\", \"SVN\", \"FRA\", \"POL\", \"TUR\", \"ESP\", \"BEL\", \"MEX\", \"IRL\", \"CHE\", \"FIN\", \"CHL\", \"CAN\", \"KOR\", \"NZL\", \"AUS\", \"HUN\", \"USA\", \"GBR\", \"AUT\", \"SWE\", \"DNK\", \"SVK\", \"CZE\", \"COL\", \"JPN\", \"NOR\",\"CRI\", \"LTU\", \"DEU\", \"EST\", \"PRT\", \"ITA\")\n\n# \"OAVG\" OECD average\nfamily &lt;- get_dataset(\n  \"FAMILY\",\n  filter = list(c(oecd_countries, \"OAVG\"), \"TOTAL\", c(\"FAM1\", \"FAM3\")),\n  start_time = 1990, end_time = 2021\n  ) |&gt; \n  clean_names() |&gt; \n  mutate(\n    obs_value = parse_number(obs_value),\n    time = parse_number(time)\n    )\n\n# \"OECD\" OECD average\nfamily_expenditure &lt;- get_dataset(\n  \"SOCX_AGG\",\n  filter = list(\"10\", \"5\", \"0\", \"0\", \"PCT_GDP\", c(oecd_countries, \"OECD\")),\n  start_time = 1980, end_time = 2021\n  ) |&gt; \n  clean_names() |&gt; \n  mutate(\n    obs_value = parse_number(obs_value),\n    time = parse_number(time)\n    )\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `obs_value = parse_number(obs_value)`.\nCaused by warning:\n! 129 parsing failures.\nrow col expected actual\n 42  -- a number    NaN\n 43  -- a number    NaN\n 44  -- a number    NaN\n 45  -- a number    NaN\n 47  -- a number    NaN\n... ... ........ ......\nSee problems(...) for more details.\n\n\n\n\nCode\navail_2021 &lt;- family |&gt; \n  filter(ind == \"FAM1\", time == 2021, !is.na(obs_value)) |&gt; \n  mutate(country = countrycode(cou, \"iso3c\", \"country.name\")) |&gt; \n  pull(country)\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `country = countrycode(cou, \"iso3c\", \"country.name\")`.\nCaused by warning:\n! Some values were not matched unambiguously: OAVG\n\n\nI find there are just 39 countries of which fertility rates of 2021 are available in OECD.stat.\n\n\nCode\navail_2021\n\n\n [1] \"Israel\"         \"Luxembourg\"     \"Netherlands\"    \"Greece\"        \n [5] \"Iceland\"        \"Latvia\"         \"Slovenia\"       \"France\"        \n [9] \"Poland\"         \"Turkey\"         \"Spain\"          \"Belgium\"       \n[13] \"Mexico\"         \"Ireland\"        \"Switzerland\"    \"Finland\"       \n[17] \"Chile\"          \"Canada\"         \"South Korea\"    \"New Zealand\"   \n[21] \"Australia\"      \"Hungary\"        \"United States\"  \"United Kingdom\"\n[25] \"Austria\"        \"Sweden\"         \"Denmark\"        \"Slovakia\"      \n[29] \"Czechia\"        \"Colombia\"       \"Japan\"          \"Norway\"        \n[33] \"Costa Rica\"     \"Lithuania\"      \"Germany\"        \"Estonia\"       \n[37] \"Portugal\"       \"Italy\"          NA              \n\n\nProbably they got 2021 data from other sources. I decide to change Y-axis from 2021 to 2020 to cover all 38 OECD countries data.\n\n\nCode\n# fertility rate vs public family expenditure; point\nfer_vs_exp &lt;- family |&gt; \n  filter(ind == \"FAM1\", time == 2020) |&gt; \n  select(cou, fertility = obs_value) |&gt; \n  mutate(cou = if_else(cou == \"OAVG\", \"OECD\", cou)) |&gt; \n  left_join(family_expenditure |&gt; \n              filter(time == 2017) |&gt; \n              select(cou = country, fam_exp = obs_value),\n            by = \"cou\") |&gt; \n  mutate(country = cou |&gt; \n           countrycode(\"iso3c\", \"country.name\") |&gt; \n           coalesce(\"OECD average\")\n         )\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `country = coalesce(countrycode(cou, \"iso3c\", \"country.name\"),\n  \"OECD average\")`.\nCaused by warning:\n! Some values were not matched unambiguously: OECD\n\n\nCode\nfer_vs_exp2 &lt;- fer_vs_exp |&gt;\n  filter(!cou %in% c(\"OECD\"))\n\nfer_vs_exp2 |&gt; \n  distinct(country) |&gt; \n  pull(country) # 38 countries\n\n\n [1] \"Israel\"         \"Luxembourg\"     \"Netherlands\"    \"Greece\"        \n [5] \"Iceland\"        \"Latvia\"         \"Slovenia\"       \"France\"        \n [9] \"Poland\"         \"Turkey\"         \"Spain\"          \"Belgium\"       \n[13] \"Mexico\"         \"Ireland\"        \"Switzerland\"    \"Finland\"       \n[17] \"Chile\"          \"Canada\"         \"South Korea\"    \"New Zealand\"   \n[21] \"Australia\"      \"Hungary\"        \"United States\"  \"United Kingdom\"\n[25] \"Austria\"        \"Sweden\"         \"Denmark\"        \"Slovakia\"      \n[29] \"Czechia\"        \"Colombia\"       \"Japan\"          \"Norway\"        \n[33] \"Costa Rica\"     \"Lithuania\"      \"Germany\"        \"Estonia\"       \n[37] \"Portugal\"       \"Italy\"         \n\n\nI plot the replicated chart below with confidence interval. It is uncertain whether the slope is positive or negative.\n\n\nCode\nfer_vs_exp2 |&gt; \n  ggplot(aes(fam_exp, fertility)) +\n  geom_point(aes(color = cou == \"JPN\"), show.legend = FALSE) +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(color = cou == \"JPN\", label = country)\n                  , show.legend = FALSE) +\n  scale_color_manual(values = c(\"gray50\", \"red\")) +\n  coord_cartesian(xlim = c(0, 4), ylim = c(0, 3)) +\n  labs(x = \"Ratio of public expenditure for family to GDP\\n(percent, 2017)\",\n       y = \"Fertility rate\\n(percent, 2020)\",\n       title = \"No clear correlation between public expenditure for family\\nand fertility rate in one year\",\n       caption = \"Source: OECD.stat\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 18 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n\nIt is difficult to say there is a positive or negative correlation.\n\n\nCode\nfer_exp_model &lt;- lm(fertility ~ fam_exp, data = fer_vs_exp2)\nsummary(fer_exp_model)\n\n\n\nCall:\nlm(formula = fertility ~ fam_exp, data = fer_vs_exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.68202 -0.13137 -0.01244  0.05674  1.33540 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.47932    0.13418  11.025  4.3e-13 ***\nfam_exp      0.03871    0.06036   0.641    0.525    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2946 on 36 degrees of freedom\nMultiple R-squared:  0.0113,    Adjusted R-squared:  -0.01617 \nF-statistic: 0.4113 on 1 and 36 DF,  p-value: 0.5254"
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#narrower-confidence-interval-from-multiple-years-data",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#narrower-confidence-interval-from-multiple-years-data",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "Narrower confidence interval from multiple years data?",
    "text": "Narrower confidence interval from multiple years data?\nI turn to multiple years data from 2010 to 2021 for fertility rate, and 2006 to 2017 for public expenditure for family, as I guess they assume 4 year ago public expenditure for family effects fertility rate this year. Confidence interval is now much narrower, as the sample size is larger.\n\n\nCode\nfamily_expenditure_4yr_ago &lt;- family_expenditure |&gt;\n  select(cou = country, time, fam_exp = obs_value) |&gt; \n  mutate(time = time + 4)\n\nfer_vs_exp_multi &lt;- family |&gt; \n  filter(ind == \"FAM1\") |&gt; \n  select(cou, time, fertility = obs_value) |&gt; \n  mutate(cou = if_else(cou == \"OAVG\", \"OECD\", cou)) |&gt; \n  left_join(family_expenditure_4yr_ago,\n            by = c(\"cou\", \"time\")) |&gt; \n  mutate(\n    country = if_else(cou == \"OECD\",\n                      \"OECD average\",\n                      countrycode(cou, \"iso3c\", \"country.name\"))\n    )\n\nfer_vs_exp_multi2 &lt;- fer_vs_exp_multi |&gt;\n  filter(cou != \"OECD\", time &gt;= 2010, time &lt;= 2021)\n\nfer_vs_exp_multi2 |&gt; \n  ggplot(aes(fam_exp, fertility)) +\n  geom_path(aes(color = country)) +\n  geom_smooth(method = \"lm\", formula = y ~ x) +\n  coord_cartesian(xlim = c(0, 4), ylim = c(0, 3)) +\n  labs(x = \"Ratio of public expenditure for family to GDP\\n(percent, 4 years ago)\",\n       y = \"Fertility rate\\n(percent, current year)\",\n       color = NULL,\n       title = \"Apparent positive correlation between public expenditure for family and\\nfertility rate from 2010-2021 data. Is it real?\",\n       subtitle = \"Each colored line is a country.\",\n       caption = \"Source: OECD.stat\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\nFigure 3: Apparent positive correlation in 2010-2021\n\n\n\n\n\n\nCode\nfer_exp_multi_model &lt;- lm(fertility ~ fam_exp, data = fer_vs_exp_multi2)\n\n\nThe slope is estimated as 0.047, which is close to their assertion of 0.05 to 0.1 based on 30 countries. P-value is less than 0.01.\n\n\nCode\nsummary(fer_exp_multi_model)\n\n\n\nCall:\nlm(formula = fertility ~ fam_exp, data = fer_vs_exp_multi2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.79849 -0.20412 -0.05127  0.12143  1.46186 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.55612    0.03751   41.48  &lt; 2e-16 ***\nfam_exp      0.04748    0.01649    2.88  0.00416 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3288 on 445 degrees of freedom\n  (9 observations deleted due to missingness)\nMultiple R-squared:  0.0183,    Adjusted R-squared:  0.0161 \nF-statistic: 8.296 on 1 and 445 DF,  p-value: 0.004164"
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#its-a-bad-idea-to-treat-cross-country-multiple-year-data-as-independent-points",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#its-a-bad-idea-to-treat-cross-country-multiple-year-data-as-independent-points",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "It’s a bad idea to treat cross-country multiple-year data as independent points",
    "text": "It’s a bad idea to treat cross-country multiple-year data as independent points\nShould I agree with them? Absolutely not. Each colored line does not show a positive slope. The positive slope of the fitted line comes mainly from cross-country differences. And there is no positive correlation between public spending for family and fertility rate either in Japan or OECD average in the figure below.\n\n\nCode\noecd_jpn &lt;- fer_vs_exp_multi |&gt; \n  filter(cou %in% c(\"OECD\", \"JPN\")) |&gt; \n  filter(!is.na(fam_exp), !is.na(fertility))\n\noecd_jpn |&gt; \n  ggplot(aes(fam_exp, fertility)) +\n  geom_path(aes(color = country)) +\n  geom_label_repel(aes(label = time),\n             data = oecd_jpn |&gt; \n               filter(time %in% c(1990, 2021))) +\n  coord_cartesian(xlim = c(0, 4), ylim = c(0, 3)) +\n  labs(x = \"Ratio of public expenditure for family to GDP\\n(percent, 4 years ago)\",\n       y = \"Fertility rate\\n(percent, current year)\",\n       color = NULL,\n       title = \"No positive correlation over years between public spending for family\\nand fertility rate either in Japan or OECD average\",\n       caption = \"Source: OECD.stat\") +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#causality-does-not-come-from-data",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#causality-does-not-come-from-data",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "Causality does not come from data",
    "text": "Causality does not come from data\nStill they can argue fertility rate would have fallen deeper without an increase in public expenditure for family. This counterfactual argument should be based on some assumed causal mechanism. Increasing the number of samples does not morph correlation into causality, anyway. Do not try to increase the number of samples in a weird way."
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#replicate-the-quoted-figure",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#replicate-the-quoted-figure",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "Replicate the quoted figure",
    "text": "Replicate the quoted figure\n\n\nCode\n# OECD 38 countries\noecd_countries &lt;- c(\"ISR\", \"LUX\", \"NLD\", \"GRC\", \"ISL\", \"LVA\", \"SVN\", \"FRA\", \"POL\", \"TUR\", \"ESP\", \"BEL\", \"MEX\", \"IRL\", \"CHE\", \"FIN\", \"CHL\", \"CAN\", \"KOR\", \"NZL\", \"AUS\", \"HUN\", \"USA\", \"GBR\", \"AUT\", \"SWE\", \"DNK\", \"SVK\", \"CZE\", \"COL\", \"JPN\", \"NOR\",\"CRI\", \"LTU\", \"DEU\", \"EST\", \"PRT\", \"ITA\")\n\n# \"OAVG\" OECD average\nfamily &lt;- get_dataset(\n  \"FAMILY\",\n  filter = list(c(oecd_countries, \"OAVG\"), \"TOTAL\", c(\"FAM1\", \"FAM3\")),\n  start_time = 1990, end_time = 2021\n  ) |&gt; \n  clean_names() |&gt; \n  mutate(\n    obs_value = parse_number(obs_value),\n    time = parse_number(time)\n    )\n\n# \"OECD\" OECD average\nfamily_expenditure &lt;- get_dataset(\n  \"SOCX_AGG\",\n  filter = list(\"10\", \"5\", \"0\", \"0\", \"PCT_GDP\", c(oecd_countries, \"OECD\")),\n  start_time = 1980, end_time = 2021\n  ) |&gt; \n  clean_names() |&gt; \n  mutate(\n    obs_value = if_else(obs_value == \"NaN\", NA, obs_value),\n    obs_value = parse_number(obs_value),\n    time = parse_number(time)\n    )\n\n# fertility rate vs public family expenditure; point\nfer_vs_exp &lt;- family |&gt; \n  filter(ind == \"FAM1\", time == 2021) |&gt; \n  select(cou, fertility = obs_value) |&gt; \n  mutate(cou = if_else(cou == \"OAVG\", \"OECD\", cou)) |&gt; \n  left_join(family_expenditure |&gt; \n              filter(time == 2017) |&gt; \n              select(cou = country, fam_exp = obs_value),\n            by = \"cou\") |&gt; \n  mutate(\n    country = if_else(cou == \"OECD\",\n                      \"OECD average\",\n                      countrycode(cou, \"iso3c\", \"country.name\"))\n  )\n\nfer_vs_exp2 &lt;- fer_vs_exp |&gt;\n  filter(cou != \"OECD\")\n\n\nI plot the replicated chart below with confidence interval. There are 38 points, as this chart includes all 38 OECD countries. It is uncertain whether the slope is positive or negative.\n\n\nCode\nfer_vs_exp2 |&gt; \n  ggplot(aes(fam_exp, fertility)) +\n  geom_point(aes(color = cou == \"JPN\"), show.legend = FALSE) +\n  geom_smooth(method = \"lm\", formula = y ~ x) +\n  geom_text_repel(aes(color = cou == \"JPN\", label = country),\n                  show.legend = FALSE) +\n  scale_color_manual(values = c(\"gray50\", \"red\")) +\n  coord_cartesian(xlim = c(0, 4), ylim = c(0, 3)) +\n  labs(x = \"Ratio of public expenditure for family to GDP\\n(percent, 2017)\",\n       y = \"Fertility rate\\n(percent, 2021)\",\n       title = \"No clear correlation between public expenditure for family\\nand fertility rate in one year\",\n       caption = \"Source: OECD.stat\")\n\n\n\n\n\nFigure 2: No clear correlation in one year\n\n\n\n\nIt is difficult to say there is a positive or negative correlation.\n\n\nCode\nfer_exp_model &lt;- lm(fertility ~ fam_exp, data = fer_vs_exp2)\nsummary(fer_exp_model)\n\n\n\nCall:\nlm(formula = fertility ~ fam_exp, data = fer_vs_exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70589 -0.13334 -0.02066  0.09695  1.41083 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.44241    0.14142  10.200 3.65e-12 ***\nfam_exp      0.06662    0.06362   1.047    0.302    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3104 on 36 degrees of freedom\nMultiple R-squared:  0.02956,   Adjusted R-squared:  0.002604 \nF-statistic: 1.097 on 1 and 36 DF,  p-value: 0.302"
  },
  {
    "objectID": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#its-a-bad-idea-to-treat-cross-country-multiple-year-data-as-independent-observations",
    "href": "posts/2023-04-27-will-higher-public-spending-for-family-lead-to-higher-fertility-rate/index.html#its-a-bad-idea-to-treat-cross-country-multiple-year-data-as-independent-observations",
    "title": "Will higher public spending for family lead to higher fertility rate?",
    "section": "It’s a bad idea to treat cross-country multiple-year data as independent observations",
    "text": "It’s a bad idea to treat cross-country multiple-year data as independent observations\nShould I agree with them? Absolutely not. Each colored line does not show a positive slope. The positive slope of the fitted line comes mainly from cross-country differences. And there is no positive correlation between public spending for family and fertility rate either in Japan or OECD average in the figure below.\n\n\nCode\noecd_jpn &lt;- fer_vs_exp_multi |&gt; \n  filter(cou %in% c(\"OECD\", \"JPN\")) |&gt; \n  filter(!is.na(fam_exp), !is.na(fertility))\n\noecd_jpn |&gt; \n  ggplot(aes(fam_exp, fertility)) +\n  geom_path(aes(color = country)) +\n  geom_label_repel(aes(label = time),\n             data = oecd_jpn |&gt; \n               filter(time %in% c(1990, 2021))) +\n  coord_cartesian(xlim = c(0, 4), ylim = c(0, 3)) +\n  labs(x = \"Ratio of public expenditure for family to GDP\\n(percent, 4 years ago)\",\n       y = \"Fertility rate\\n(percent, current year)\",\n       color = NULL,\n       title = \"No positive correlation over years between public spending for\\nfamily and fertility rate either in Japan or OECD average\",\n       caption = \"Source: OECD.stat\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigure 4: 1990-2021 in Japan and OECD average"
  },
  {
    "objectID": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html",
    "href": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html",
    "title": "Does repeated vaccination cause excess mortality?",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(lubridate)\n\nlibrary(ggrepel)\nlibrary(dagitty)\nlibrary(tsibble)\n\nlibrary(scales)\ntheme_set(theme_light())"
  },
  {
    "objectID": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#replication",
    "href": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#replication",
    "title": "Does repeated vaccination cause excess mortality?",
    "section": "Replication",
    "text": "Replication\nSeiji Kojima, Professor Emeritus of Nagoya University, suggests that the repeated vaccine shots, like the third or the fourth shots, may cause more excess mortality in the article of Shukan Shincho (December 22, 2022). He shows the chart like below, and asserts there is a correlation between additional shots in 2022 and excess deaths in the summer of 2022. The chart below is not the same with the chart in the article, but looks similar enough, I think.\n\n\nCode\nexcess_mortality_economist_estimates &lt;- read_csv(\"https://github.com/owid/covid-19-data/raw/master/public/data/excess_mortality/excess_mortality_economist_estimates.csv\")\n\nvaccinations &lt;- read_csv(\"https://github.com/owid/covid-19-data/raw/master/public/data/vaccinations/vaccinations.csv\")\n\n\n\n\nCode\nexcess_deaths_summer_2022 &lt;- excess_mortality_economist_estimates %&gt;% \n  filter(date &gt;= \"2022-08-01\", date &lt;= \"2022-10-24\") %&gt;% \n  group_by(country) %&gt;% \n  summarize(excess_deaths = (cumulative_estimated_daily_excess_deaths_per_100k[which.max(date)] - cumulative_estimated_daily_excess_deaths_per_100k[which.min(date)]) * 10) %&gt;% \n  ungroup()\n\nexcess_deaths_upto_spring_2022 &lt;- excess_mortality_economist_estimates %&gt;% \n  filter(date &lt;= \"2022-07-31\") %&gt;% \n  group_by(country) %&gt;% \n  summarize(excess_deaths = (cumulative_estimated_daily_excess_deaths_per_100k[which.max(date)] - cumulative_estimated_daily_excess_deaths_per_100k[which.min(date)]) * 10) %&gt;% \n  ungroup()\n\n\n\n\nCode\nshots_2022 &lt;- vaccinations %&gt;% \n  filter(date &gt;= \"2022-01-01\", date &lt;= \"2022-11-01\") %&gt;% \n  group_by(location) %&gt;% \n  summarize(shots = max(total_vaccinations_per_hundred, na.rm = TRUE) - min(total_vaccinations_per_hundred, na.rm = TRUE)) %&gt;% \n  ungroup()\n\nshots_upto_2021 &lt;- vaccinations %&gt;% \n  filter(date &lt;= \"2021-12-31\") %&gt;% \n  group_by(location) %&gt;% \n  summarize(shots = max(total_vaccinations_per_hundred, na.rm = TRUE) - min(total_vaccinations_per_hundred, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\n\n\nCode\npicked &lt;- c(\"Japan\", \"Taiwan\", \"Vietnam\", \"Germany\", \"Belgium\",\n            \"South Korea\", \"United Kingdom\", \"Spain\", \"Singapore\",\n            \"Albania\", \"Croatia\", \"Bosnia and Herzegovina\",\n            \"Pakistan\",\"Bulgaria\", \"Indonesia\", \"Jordan\")\n\nexcess_deaths_shots &lt;- excess_deaths_summer_2022 %&gt;% \n  filter(country != \"World\") %&gt;% \n  inner_join(shots_2022, by = c( \"country\" = \"location\")) %&gt;% \n  mutate(label = if_else(country %in% picked, country, NA))\n\nexcess_deaths_shots %&gt;% \n  filter(!is.na(label)) %&gt;% # cherry-picked 16 countries\n  ggplot(aes(shots, excess_deaths)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = label)) +\n  labs(x = \"Vaccine shots per 100 persons, from 2022-01-01 to 2022-11-01\",\n       y = \"Excess deaths per 1 million persons,\\nfrom 2022-08-01 to 2022-10-24\",\n       caption = \"Note: Excess deaths are estimated by the Economist\\nSource: Our World In Data\")\n\n\n\n\n\nFigure 1: Additional vaccine shots and excess deaths in 16 areas"
  },
  {
    "objectID": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#cherry-picking",
    "href": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#cherry-picking",
    "title": "Does repeated vaccination cause excess mortality?",
    "section": "Cherry picking?",
    "text": "Cherry picking?\nAlthough the chart above plots only 16 areas, there are 214 areas in the data. So, I plot all 214 areas in the chart below. Now, there is no apparent correlation between shots in 2022 and excess mortality in the summer of 2022.\n\n\nCode\nexcess_deaths_shots %&gt;% # 214 countries\n  mutate(cherrypicked = if_else(!is.na(label), \"Yes\", \"No\")) %&gt;% \n  ggplot(aes(shots, excess_deaths)) +\n  geom_point(aes(color = cherrypicked)) +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = country)) +\n  scale_color_manual(values = c(\"gray60\", \"red\")) +\n  labs(x = \"Vaccine shots per 100 persons, from 2022-01-01 to 2022-11-01\",\n       y = \"Excess deaths per 1 million persons,\\nfrom 2022-08-01 to 2022-10-24\",\n       caption = \"Note: Excess deaths are estimated by the Economist\\nSource: Our World In Data\",\n       color = \"Cherry-picked\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigure 2: Additional vaccine shots and excess deaths in 214 areas"
  },
  {
    "objectID": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#confound",
    "href": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#confound",
    "title": "Does repeated vaccination cause excess mortality?",
    "section": "Confound?",
    "text": "Confound?\nHe may have thought Bangladesh, Cuba, Nepal, etc. can’t be the repeated shots, and excluded them. However, even if there is some legitimate reasons to pick up his 16 areas, there is not necessarily a causal path from A (additional vaccine shots) to E (excess mortality in the summer of 2022). Below, I show S (vaccine shots up to the end of 2021) can be a confound.\nE: Excess mortality in the summer of 2022\nC: Cumulative extra mortality up to the spring of 2022\nS: Vaccine shots up to the end of 2021\nA: Additional vaccine shots in 2022\n\n\nCode\ndag_con &lt;- dagitty(\"dag{\n                  A &lt;- S -&gt; C -&gt; E\n                  }\")\ncoordinates(dag_con) &lt;- list(x = c(A = 0, S = 0, C = 1, E = 1),\n                               y = c(A = 1, S = 0, C = 0, E = 1))\nrethinking::drawdag(dag_con)\n\n\n\n\n\nFigure 3: From A to E, there is no causal path, but a backdoor path\n\n\n\n\nS -&gt; C: Eager shooters could reduce excess mortality up to the spring of 2022.\n\n\nCode\nexcess_deaths_shots_2021 &lt;- excess_deaths_upto_spring_2022 %&gt;% \n  filter(country != \"World\") %&gt;% \n  inner_join(shots_upto_2021, by = c( \"country\" = \"location\")) %&gt;% \n  mutate(label = if_else(country %in% picked, country, NA))\n\nexcess_deaths_shots_2021 %&gt;% \n  filter(!is.na(label)) %&gt;% # cherry-picked 16 countries\n  ggplot(aes(shots, excess_deaths)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = label)) +\n  scale_y_continuous(labels = comma) +\n  labs(x = \"Vaccine shots per 100 persons, up to 2021-12-31\",\n       y = \"Excess deaths per 1 million persons,\\nfrom 2020-01-01 to 2022-07-31\",\n       caption = \"Note: Excess deaths are estimated by the Economist\\nSource: Our World In Data\")\n\n\n\n\n\nFigure 4: Vaccine shots up to the end of 2021 and excess deaths up to July 2022\n\n\n\n\nC -&gt; E: So, the vulnerable people, who could survive up to the spring of 2022, remain vulnerable in the summer of 2022.\n\n\nCode\nexcess_deaths_shots %&gt;% \n  filter(!is.na(label)) %&gt;% \n  bind_cols(\n    excess_deaths_shots_2021 %&gt;% \n      filter(!is.na(label)) %&gt;% \n      select(excess_deaths_upto_spring_2022 = excess_deaths,\n             shots_upto_2021 = shots)\n  ) %&gt;% \n  select(-label) %&gt;% \n  ggplot(aes(excess_deaths_upto_spring_2022, excess_deaths)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = country)) +\n  scale_x_continuous(labels = comma) +\n  labs(x = \"From 2020-01-01 to 2022-07-31\",\n       y = \"From 2022-08-01 to 2022-10-24\",\n       title = \"Excess deaths per 1 million persons\",\n       caption = \"Note: Excess deaths are estimated by the Economist\\nSource: Our World In Data\")\n\n\n\n\n\nFigure 5: Excess deaths before and after July 2022\n\n\n\n\nS -&gt; A: Eager shooters tend to continue to shoot.\n\n\nCode\nshots_2022 %&gt;% \n  filter(location %in% picked) %&gt;% \n  bind_cols(\n    shots_upto_2021 %&gt;% \n  filter(location %in% picked) %&gt;% \n    select(-location, shots_upto_2021 = shots)\n  ) %&gt;% \n  ggplot(aes(shots_upto_2021, shots)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = location)) +\n  labs(x = \"Up to 2021-12-31\",\n       y = \"From 2022-01-01 to 2022-11-01\",\n       title = \"Vaccine shots per 100 persons\",\n       caption = \"Source: Our World In Data\")\n\n\n\n\n\nFigure 6: Vaccine shots before and after the end of 2021"
  },
  {
    "objectID": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#vaccine-shots-and-excess-deaths-in-japan",
    "href": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#vaccine-shots-and-excess-deaths-in-japan",
    "title": "Does repeated vaccination cause excess mortality?",
    "section": "Vaccine shots and excess deaths in Japan",
    "text": "Vaccine shots and excess deaths in Japan\n\n\nCode\nvaccine_jp &lt;- read_csv(\"https://data.vrs.digital.go.jp/vaccination/opendata/latest/summary_by_date.csv\")\n\nvaccine_jp_ratio &lt;- vaccine_jp %&gt;% \n  select(date:count_fifth_shot_general) %&gt;% \n  mutate(across(-date, ~ cumsum(.x) / 125918711)) %&gt;% \n  pivot_longer(-date, names_to = \"order\", values_to = \"shots\") %&gt;% \n  mutate(order = str_remove_all(order, \"count_|_shot|_general\")) %&gt;% \n  filter(shots != 0) %&gt;% \n  mutate(\n    order = factor(order,\n                        levels = c(\"first\", \"second\", \"third\", \"fourth\", \"fifth\"),\n                        labels = c(\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\"))\n    )\n\ncovid_deaths_jp &lt;- read_csv(\"https://covid19.mhlw.go.jp/public/opendata/deaths_cumulative_daily.csv\")%&gt;% \n  mutate(Date = as.Date(Date)) %&gt;% \n  select(date = Date, deaths = ALL)\n\neconomist_estimates_jp &lt;- excess_mortality_economist_estimates %&gt;% \n  filter(country == \"Japan\")\n\n\nShukan Shincho continues to suggest causation from repeated vaccine shots to excess deaths in 3 weeks in a row, by showing Professor Kojima’s line chart like below. Prof Kojima warns against repeated vaccine shots by suggesting there is a synchronized movement between 3rd vaccine shots and cumulative excess deaths from January to March 2022. However, his warning does not sound persuasive, because it assumes immediate effects of vaccine shots on deaths, and it depends on just 3 months data.\n\n\nCode\nvaccine_jp_ratio %&gt;% \n  filter(order == \"3rd\", date &gt;= \"2022-01-01\", date &lt; \"2022-04-01\") %&gt;% \n  ggplot(aes(date, shots)) +\n  geom_line() +\n  scale_y_continuous(labels = percent) +\n  labs(x = NULL, y = \"Cululative shots per population\",\n       color = \"Order of shots\",\n       title = \"3rd vaccine shots in Japan\",\n       caption = \"Source: Digital Agency\")\n\ncum_end_of_2021 &lt;- economist_estimates_jp %&gt;% \n  filter(date == \"2021-12-27\") %&gt;% \n  pull(cumulative_estimated_daily_excess_deaths)\n\neconomist_estimates_jp %&gt;% \n  filter(date &gt;= \"2022-01-01\", date &lt; \"2022-04-01\") %&gt;% \n  mutate(excess_deaths_2022 = cumulative_estimated_daily_excess_deaths - cum_end_of_2021) %&gt;% \n  ggplot(aes(date, excess_deaths_2022)) +\n  geom_line() +\n  scale_y_continuous(labels = comma) +\n  labs(x = NULL, y = \"Cumulative deaths since 2022\",\n       title = \"Excess deaths in Japan\",\n       caption = \"Source: The Economist\")\n\n\n\n\n\n\n\nFigure 7: 3rd vaccine shots in Japan\n\n\n\n\n\n\n\nFigure 8: Excess deaths in Japan\n\n\n\n\n\n\nWhen we broaden the time horizon, it is hard to notice synchronized movement between vaccine shots and cumulative excess deaths. Instead, we notice continuous excess deaths rise over Covid-19 deaths in 2022.\n\n\nCode\nvaccine_jp_ratio %&gt;% \n  ggplot(aes(date, shots)) +\n  geom_line(aes(color = order)) +\n  scale_y_continuous(labels = percent) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(x = NULL, y = \"Cululative shots per population\",\n       color = NULL,\n       title = \"Vaccine shots in Japan\",\n       caption = \"Source: Digital Agency\") +\n  theme(legend.position = \"bottom\")\n\neconomist_estimates_jp %&gt;% \n  ggplot(aes(date, cumulative_estimated_daily_excess_deaths)) +\n  geom_line() +\n  geom_line(aes(date, deaths), data = covid_deaths_jp, color = \"red\") +\n  geom_hline(yintercept = 0, color = \"gray50\") +\n  scale_y_continuous(labels = comma) +\n  labs(x = NULL, y = \"Cumulative deaths\",\n       title = \"Excess deaths (black) and\\nCovid-19 deaths (red) in Japan\",\n       caption = \"Source: The Economist and MHLW\")\n\n\n\n\n\n\n\nFigure 9: Vaccine shots in Japan\n\n\n\n\n\n\n\nFigure 10: Excess deaths and Covid-19 deaths in Japan"
  },
  {
    "objectID": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#two-estimates-of-excess-deaths-by-the-economist-and-by-world-mortality-dataset-wmd",
    "href": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#two-estimates-of-excess-deaths-by-the-economist-and-by-world-mortality-dataset-wmd",
    "title": "Does repeated vaccination cause excess mortality?",
    "section": "Two estimates of excess deaths by The Economist and by World Mortality Dataset (WMD)",
    "text": "Two estimates of excess deaths by The Economist and by World Mortality Dataset (WMD)\n\n\nCode\nexcess_mortality &lt;- read_csv(\"https://github.com/owid/covid-19-data/raw/master/public/data/excess_mortality/excess_mortality.csv\")\n\nexcess_mortality_jp &lt;- excess_mortality %&gt;% \n  filter(location == \"Japan\")\n\n\nThere are two estimates of excess deaths by The Economist and by World Mortality Dataset (WMD). So far I use the Economist, which estimates more excess deaths than WMD.\n\n\nCode\nbind_rows(\n  economist_estimates_jp %&gt;% \n  select(date, cum_excess = cumulative_estimated_daily_excess_deaths) %&gt;% \n  mutate(source = \"The Economist\"),\nexcess_mortality_jp %&gt;% \n  select(date, cum_excess = cum_excess_proj_all_ages) %&gt;% \n  mutate(source = \"WMD\")\n) %&gt;% \n  ggplot(aes(date, cum_excess)) +\n  geom_line(aes(color = source)) +\n  geom_hline(yintercept = 0, color = \"gray50\") +\n  scale_y_continuous(labels = comma) +\n  labs(x = NULL, y = \"Cumulative excess deaths\",\n       color = \"Source\",\n       title = \"The Economist estimates more excess deaths than WMD\",\n       caption = \"Source: Our World In Data\")\n\n\n\n\n\nFigure 11: Two estimates of excess deaths by the Economist and WMD"
  },
  {
    "objectID": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#excess-deaths-in-japan-are-based-on-not-age-adjusted-projection",
    "href": "posts/2022-12-16-does-repeated-vaccination-cause-excess-mortality/index.html#excess-deaths-in-japan-are-based-on-not-age-adjusted-projection",
    "title": "Does repeated vaccination cause excess mortality?",
    "section": "Excess deaths in Japan are based on not age-adjusted projection",
    "text": "Excess deaths in Japan are based on not age-adjusted projection\nExcess deaths are actual deaths minus projected deaths. It turns out projected deaths from 2020 are linear extrapolation from 2015-2019 deaths in World Mortality Dataset (WMD) which Our World In Data uses.\n\n“Before 20 September 2021, we calculated P-scores using a different estimate of expected deaths: the five-year average from 2015–2019. We made this change because using the five-year average has an important limitation — it does not account for year-to-year trends in mortality and thus can misestimate excess mortality. The WMD projection we now use, on the other hand, does not suffer from this limitation because it accounts for these year-to-year trends.”\n\nThe Economist claims it uses a model to estimate excess deaths. As its estimates are larger than WMD in Japan, it is likely that the Economist does not age-adjust normal deaths projection either.\nAs projection is not age-adjusted, it is more plausible that projection is too low than that actual deaths are too high in 2022.\n\n\nCode\nseasonality &lt;- excess_mortality_jp %&gt;% \n  filter(!is.na(average_deaths_2015_2019_all_ages)) %&gt;% \n  mutate(month = month(date)) %&gt;% \n  select(month, average_deaths_2015_2019_all_ages) %&gt;% \n  mutate(seasonality = average_deaths_2015_2019_all_ages - mean(average_deaths_2015_2019_all_ages)) %&gt;% \n  select(month, seasonality)\n\nactual_2015_2019 &lt;- excess_mortality_jp %&gt;% \n  filter(!is.na(deaths_2015_all_ages)) %&gt;% \n  select(date, deaths_2015_all_ages:deaths_2019_all_ages) %&gt;% \n  pivot_longer(-date, names_to = \"year\", values_to = \"actual\") %&gt;% \n  mutate(\n    month = month(date),\n    year = year %&gt;% \n      str_sub(8, 11) %&gt;% \n      as.integer()\n    ) %&gt;% \n  select(-date) %&gt;% \n  left_join(seasonality, by = \"month\") %&gt;% \n  mutate(\n    actual_sa = actual - seasonality,\n    date = make_yearmonth(year, month)\n    ) %&gt;% \n  select(-year, -month) %&gt;% \n  arrange(date)\n\nactual_since_2020 &lt;- excess_mortality_jp %&gt;% \n  filter(!is.na(deaths_since_2020_all_ages)) %&gt;% \n  select(date, actual = deaths_since_2020_all_ages) %&gt;% \n  mutate(month = month(date)) %&gt;% \n  left_join(seasonality, by = \"month\") %&gt;% \n  mutate(\n    actual_sa = actual - seasonality,\n    date = yearmonth(date)\n    ) %&gt;% \n  select(-month)\n\nprojected_since_2020 &lt;- excess_mortality_jp %&gt;% \n  filter(!is.na(projected_deaths_since_2020_all_ages)) %&gt;% \n  select(date, projected = projected_deaths_since_2020_all_ages) %&gt;% \n  mutate(month = month(date)) %&gt;% \n  left_join(seasonality, by = \"month\") %&gt;% \n  mutate(\n    projected_sa = projected - seasonality,\n    date = yearmonth(date)\n    ) %&gt;% \n  select(-month)\n\nbind_rows(actual_2015_2019, actual_since_2020) %&gt;% \n  ggplot(aes(date, actual_sa)) +\n  geom_line() +\n  geom_line(aes(date, projected_sa), data = projected_since_2020,\n            color = \"blue\", linewidth = 0.8) +\n  geom_smooth(method = \"lm\", data = actual_2015_2019, se = FALSE) +\n  scale_y_continuous(labels = comma) +\n  labs(x = NULL, y = \"Monthly deaths in Japan\\nseasonally adjusted\\nby using 2015-2019 average additively\",\n     title = \"Actual deaths surpass projection in 2022\",\n     subtitle = \"Black is actual, and blue is projection; linear extrapolation from 2015-2019\",\n     caption = \"Note: Excess deaths are estimated by WMD\\nSource: Our World In Data\")\n\n\n\n\n\nFigure 12: Actual deaths and projection by the Economist\n\n\n\n\nProjection by WMD is age-adjusted in below 35 locations. In other locations, including Japan, projection is not age-adjusted, and just linear extrapolation of total deaths in 2015-2019.\n\n\nCode\nexcess_mortality %&gt;% \n  filter(!is.na(p_scores_15_64)) %&gt;% \n  distinct(location) %&gt;% \n  pull(location)\n\n\n [1] \"Australia\"        \"Austria\"          \"Belgium\"          \"Bulgaria\"        \n [5] \"Canada\"           \"Chile\"            \"Croatia\"          \"Czechia\"         \n [9] \"Denmark\"          \"England & Wales\"  \"Estonia\"          \"Finland\"         \n[13] \"France\"           \"Germany\"          \"Greece\"           \"Hungary\"         \n[17] \"Iceland\"          \"Israel\"           \"Italy\"            \"Latvia\"          \n[21] \"Lithuania\"        \"Luxembourg\"       \"Netherlands\"      \"New Zealand\"     \n[25] \"Northern Ireland\" \"Norway\"           \"Poland\"           \"Portugal\"        \n[29] \"Scotland\"         \"Slovakia\"         \"Slovenia\"         \"South Korea\"     \n[33] \"Spain\"            \"Switzerland\"      \"United Kingdom\"   \"United States\"   \n\n\nThe oldest baby boomers in Japan were born in 1947, two years after the end of World War II. They were 70 years old in 2017, and 75 years old in 2022. And 75-79 person death rates are 1.66 times of 70-74 person in 2019, according to Ministry of Health, Labour and Welfare (Japanese, PDF). I don’t have enough data to make age-adjusted projection by myself, but I can safely say that not age-adjusted projection is too low."
  },
  {
    "objectID": "posts/2022-10-04-can-you-say-it-is-high-or-low-by-looking-at-one-time-data/index.html",
    "href": "posts/2022-10-04-can-you-say-it-is-high-or-low-by-looking-at-one-time-data/index.html",
    "title": "Can you say it is high or low by looking at one time data?",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\n\ntheme_set(theme_light())\nCode\nread_dat1 &lt;- function(url, sheet, year) {\n  # download\n  tf &lt;- tempfile(fileext = \".xls\")\n  \n  httr::GET(url, httr::write_disk(tf))\n  \n  # read\n  dat &lt;- read_excel(tf, sheet = sheet)\n  ratios &lt;- dat[5, 9] %&gt;% \n    as.numeric()\n  names(ratios) &lt;- year\n  \n  # return\n  ratios\n}\n\nread_dat2 &lt;- function(url, sheet1, sheet2, year) {\n  # download\n  tf &lt;- tempfile(fileext = \".xls\")\n  \n  httr::GET(url, httr::write_disk(tf))\n  \n  # read\n  dat1 &lt;- read_excel(tf, sheet = sheet1)\n  sales &lt;- as.numeric(dat1[4, 12]) * 100\n  \n  dat2 &lt;- read_excel(tf, sheet = sheet2)\n  costs &lt;- as.numeric(dat2[6, 6])\n  \n  ratios &lt;- costs / sales * 100\n  names(ratios) &lt;- year\n  \n  # return\n  ratios\n}\n\nread_dat3 &lt;- function(url, sheet1, r1, c1, sheet2, r2, c2, year) {\n  # download\n  tf &lt;- tempfile(fileext = \".xls\")\n  \n  httr::GET(url, httr::write_disk(tf))\n  \n  # read\n  dat1 &lt;- read_excel(tf, sheet = sheet1)\n  sales &lt;- as.numeric(dat1[r1, c1])\n  \n  dat2 &lt;- read_excel(tf, sheet = sheet2)\n  costs &lt;- parse_number(as.character(dat2[r2, c2]))\n  \n  ratios &lt;- costs / sales * 100\n  names(ratios) &lt;- year\n  \n  # return\n  ratios\n}\n\nread_dat4 &lt;- function(url, sheet1, r1, c1, sheet2, r2, c2, year) {\n  # download\n  tf &lt;- tempfile(fileext = \".xlsx\")\n  \n  httr::GET(url, httr::write_disk(tf))\n  \n  # read\n  dat1 &lt;- read_excel(tf, sheet = sheet1)\n  sales &lt;- as.numeric(dat1[r1, c1])\n  \n  dat2 &lt;- read_excel(tf, sheet = sheet2)\n  costs &lt;- parse_number(as.character(dat2[r2, c2]))\n  \n  ratios &lt;- costs / sales * 100\n  names(ratios) &lt;- year\n  \n  # return\n  ratios\n}\nCode\ndat &lt;- rep(NA_real_, 27)\n\ndat[1] &lt;- read_dat1(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031365960&fileKind=0\", 8, 1994)\n\ndat[2] &lt;- read_dat1(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031365902&fileKind=0\", 10, 1995)\n\ndat[3] &lt;- read_dat2(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031365900&fileKind=0\", 2, 11, 1996)\n\ndat[4] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031365898&fileKind=0\", 8, 4, 3, 11, 5, 6, 1997)\n\ndat[5] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335269&fileKind=0\", 16, 4, 3, 19, 6, 6, 1998)\n\ndat[6] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335267&fileKind=0\", 15, 4, 3, 18, 6, 6, 1999)\n\ndat[7] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335264&fileKind=0\", 16, 4, 3, 19, 6, 6, 2000)\n\ndat[8] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335251&fileKind=0\", 16, 4, 3, 19, 6, 6, 2001)\n\ndat[9] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335238&fileKind=0\", 6, 4, 3, 9, 6, 6, 2002)\n\ndat[10] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335227&fileKind=0\", 5, 4, 3, 8, 6, 6, 2003)\n\ndat[11] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335186&fileKind=0\", 6, 5, 6, 9, 6, 6, 2004)\n\ndat[12] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002335198&fileKind=0\", 5, 5, 3, 8, 6, 6, 2005)\n\ndat[13] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000002332496&fileKind=0\", 5, 4, 3, 8, 6, 6, 2006)\n\ndat[14] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000008797328&fileKind=0\", 5, 5, 3, 8, 6, 6, 2007)\n\ndat[15] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000008862770&fileKind=0\", 5, 4, 3, 8, 6, 6, 2008)\n\ndat[16] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000012448588&fileKind=0\", 5, 4, 3, 8, 6, 6, 2009)\n\ndat[17] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031364720&fileKind=0\", 5, 4, 3, 8, 6, 6, 2010)\n\ndat[18] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031364766&fileKind=0\", 5, 4, 3, 8, 6, 6, 2011)\n\ndat[19] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031364844&fileKind=0\", 5, 4, 3, 8, 6, 6, 2012)\n\ndat[20] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031364750&fileKind=0\", 5, 4, 3, 8, 6, 6, 2013)\n\ndat[21] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031435520&fileKind=0\", 5, 4, 3, 8, 6, 6, 2014)\n\ndat[22] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031626692&fileKind=0\", 5, 4, 3, 8, 6, 6, 2015)\n\ndat[23] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031735887&fileKind=0\", 5, 4, 3, 8, 6, 6, 2016)\n\ndat[24] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031841099&fileKind=0\", 5, 4, 3, 8, 6, 6, 2017)\n\ndat[25] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031974813&fileKind=0\", 5, 4, 3, 8, 6, 6, 2018)\n\ndat[26] &lt;- read_dat4(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000032116539&fileKind=0\", 5, 6, 4, 8, 7, 7, 2019)\n\ndat[27] &lt;- read_dat3(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000032210740&fileKind=0\", 5, 6, 4, 8, 7, 7, 2020)"
  },
  {
    "objectID": "posts/2022-10-04-can-you-say-it-is-high-or-low-by-looking-at-one-time-data/index.html#can-you-say-80-is-high-just-by-looking-at-fy-2020-data",
    "href": "posts/2022-10-04-can-you-say-it-is-high-or-low-by-looking-at-one-time-data/index.html#can-you-say-80-is-high-just-by-looking-at-fy-2020-data",
    "title": "Can you say it is high or low by looking at one time data?",
    "section": "Can you say 80% is high just by looking at FY 2020 data?",
    "text": "Can you say 80% is high just by looking at FY 2020 data?\nMr. Shunsuke Kobayashi, Chief Economist of Mizuho Securities, said that high cost of goods sold per sales ratio, 80 percent according to METI business activity survey, is the evidence that businesses could not transfer an increase in commodity and materials costs to sales price, in the evening NHK program “Close-up Gendai” on October 3.\nI was surprised that he says 80% is high. So I get METI business activity survey data from e-stat, and plot from fiscal year 1994 to 2020 as below. FY 2020 is the most recent one. As there is no upward trend, 80% in FY 2020 is not high compared to the past.\n\n\nCode\ntibble(\n  year = 1994:2020,\n  sales_cost_ratio = dat\n) %&gt;% \n  ggplot(aes(year, sales_cost_ratio)) +\n  geom_line() +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100 , 20), \n                     expand = c(0, 0)) +\n  labs(x = NULL, y = \"Cost of goods sold to sales ratios (%)\",\n       title = \"No upward trend in COGS to sales ratios up to FY 2020\",\n       caption = \"Source: METI business activity survey\")\n\n\n\n\n\nFigure 1: Cost of goods sold to sales ratios from 1994 to 2020\n\n\n\n\nHe may have considered 80% is high, when compared to some foreign countries. But this number, COGS to sales ratio in total, is not appropriate for cross-country comparison, because industrial structure, corporate structure and counting method matter. In a country where just one company produces and sells goods in a country, COGS to sales ratio in total will be very low. In another country where many divided companies transact each other, it will be higher. In addition, as COGS to sales ratios vary by industry as below, composition of industries effects total ratio.\n\n\nCode\nurl &lt;- \"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000032210740&fileKind=0\"\n\n# download\ntf &lt;- tempfile(fileext = \".xls\")\n\nhttr::GET(url, httr::write_disk(tf))\n\n\nCode\n# read\ndat1 &lt;- read_excel(tf, sheet = 5, skip = 5)\ndat2 &lt;- read_excel(tf, sheet = 8, skip = 6)\n\ndat_2020 &lt;- bind_cols(dat1[, c(1:2, 4)], dat2[, 7])\nnames(dat_2020) &lt;- c(\"code\", \"industry_j\", \"sales\", \"cogs\")\n\n\n\n\nCode\ndat_2020 %&gt;% \n  mutate(ratio = cogs / sales) %&gt;% \n  filter(code %in% c(\"000\", \"C\", \"E\", \"F\", \"G\", \"I1\", \"I2\", \"J1\")) %&gt;% \n  mutate(\n    industry_e = c(\"Total\", \"Mining\", \"Manifacturing\", \"Electric and gas\", \"Information and communication\", \"Wholesale\", \"Retail\", \"Credit card finance\"),\n    industry_e = fct_reorder(industry_e, ratio)\n    ) %&gt;% \n  ggplot(aes(ratio, industry_e)) +\n  geom_col() +\n  scale_x_continuous(labels = scales::percent,\n                     limits = c(0, 1),\n                     breaks = seq(0, 1, 0.2),\n                     expand = c(0, 0)) +\n  labs(y = NULL, x = \"Cost of goods sold to sales ratios in FY 2020 (%)\",\n       title = \"COGS to sales ratios vary by industry\",\n       caption = \"Source: METI business activity survey\")\n\n\n\n\n\nFigure 2: Cost of goods sold to sales ratios by industry in 2020"
  },
  {
    "objectID": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html",
    "href": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html",
    "title": "Central gov’t, not municipalities, has vaccine stocks",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(lubridate)\n\ntheme_set(theme_light())\nMy previous post was about the vaccine stock mystery. Central government says there must be 40M shots stocks, and FNN reports 40M shots stocks are 25M reserved for the second boost shots, 5M not-yet-reported shots, and 10M missing for unknown reasons. At that time, I thought at least 8M shots were not delivered to municipalities, if “Prospects for Pfizer vaccine supplies” by MHLW (Ministry of Health, Labour and Welfare) (japanese) is correct.\nAnd Nikkei reports Minister Kono says municipalities have 25M shots of vaccine stocks, which are equivalent to one week shots (Japanese) today (August 1, 2021). This is strange. One week shots are 1.2M per day times 7 days = 8.4M, far smaller than 25M.\nI checked shot loss from the last diluted vial in my previous post, and found the loss would be less than 1M shots per month. This alone can’t explain the mystery.\nIn this post, I check EU export approvals based on EU transparency and authorisation mechanism and “Prospects for Pfizer vaccine supplies” by MHLW (japanese), and would like to claim the missing vaccine stocks are exported from EU but not yet delivered to municipalities, thus are in the hands of the central government."
  },
  {
    "objectID": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#eu-export-approvals",
    "href": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#eu-export-approvals",
    "title": "Central gov’t, not municipalities, has vaccine stocks",
    "section": "EU export approvals",
    "text": "EU export approvals\nShots are in millions. EU approved 100M shots by “2021-06-30”. An officer of the Cabinet Office assumes 12M among 100M shots are distributed to doctors, and the rest 88M are distributed to residents in CNET Japan: Gov’t provides an IT system to support 1.2M shots per day. He also expects additional approvals by “2021-09-30” and “2021-12-31”.\n\n\nCode\nexport &lt;- tribble(\n  ~date, ~shots,\n  \"2021-03-24\", 5.4,\n  \"2021-04-30\", 52.3,\n  \"2021-06-30\", 100,\n  \"2021-09-30\", 170,\n  \"2021-12-31\", 190\n) %&gt;% \n  mutate(date = as.Date(date))"
  },
  {
    "objectID": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#domestic-delivery-to-doctors-and-residents",
    "href": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#domestic-delivery-to-doctors-and-residents",
    "title": "Central gov’t, not municipalities, has vaccine stocks",
    "section": "Domestic delivery to doctors and residents",
    "text": "Domestic delivery to doctors and residents\nData are from “Prospects for Pfizer vaccine supplies” by MHLW (japanese), which specifies delivery date as a week that starts on “date”. So all dates are Monday.\n\n\nCode\nfor_doctors_1 &lt;- tribble(\n  ~date, ~box,\n  \"2021-03-01\", 500,\n  \"2021-03-08\", 500,\n  \"2021-03-22\", 200,\n  \"2021-03-29\", 200,\n  \"2021-04-12\", 1200,\n  \"2021-04-19\", 1200,\n  \"2021-05-10\", 1000\n) %&gt;% \n  mutate(\n    date = as.Date(date)\n    )\n\nfor_doctors_2 &lt;- tribble(\n  ~date, ~box,\n  \"2021-03-22\", 500,\n  \"2021-03-29\", 500,\n  \"2021-04-12\", 200,\n  \"2021-04-19\", 200,\n  \"2021-05-03\", 1200,\n  \"2021-05-10\", 2200\n) %&gt;% \n  mutate(\n    date = as.Date(date)\n    )\n\nwday(for_doctors_1$date, label = TRUE)\n\n\n[1] Mon Mon Mon Mon Mon Mon Mon\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\nCode\nwday(for_doctors_2$date, label = TRUE)\n\n\n[1] Mon Mon Mon Mon Mon Mon\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\nAs the actual delivery date are not on Monday, I move them to Wednesday to reflect the average delivery date.\n\n\nCode\nfor_doctors_1 &lt;- for_doctors_1 %&gt;% \n  mutate(date = date + 2)\n\nfor_doctors_2 &lt;- for_doctors_2 %&gt;% \n  mutate(date = date + 2)\n\n\nAll dates are Monday as well in “for_residents”.\n\n\nCode\nfor_residents &lt;- tribble(\n  ~date, ~box,\n  \"2021-04-05\", 100,\n  \"2021-04-12\", 500,\n  \"2021-04-19\", 500,\n  \"2021-04-26\", 5741,\n  \"2021-05-10\", 16000,\n  \"2021-05-24\", 16000,\n  \"2021-06-07\", 13500,\n  \"2021-06-21\", 16000,\n  \"2021-07-05\", 11000,\n  \"2021-07-19\", 10000,\n  \"2021-08-02\", 10000,\n  \"2021-08-16\", 10000,\n  \"2021-08-30\", 10000,\n  \"2021-09-13\", 10000\n) %&gt;% \n  mutate(\n    date = as.Date(date)\n    )\n\nwday(for_residents$date, label = TRUE)\n\n\n [1] Mon Mon Mon Mon Mon Mon Mon Mon Mon Mon Mon Mon Mon Mon\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\nDelivery is weekly up to “2021-04-26”, and bi-weekly from “2021-05-10”. So I move weekly delivery date to Wednesday, and bi-weekly delivery date to the second week Monday.\n\n\nCode\nfor_residents &lt;- for_residents %&gt;% \n  mutate(date = if_else(date &lt;= \"2021-04-26\", date + 2, date + 7))\n\n\nThen I combine “for_doctors_1”, “for_doctors_2” and “for_residents”, and calculate cumulative delivered boxes.\n\n\nCode\ndate_frame &lt;- tibble(\n  date = seq(as.Date(\"2021-03-01\"), as.Date(\"2021-12-31\"), 1)\n)\n\ndeli_for_doctors_1 &lt;- date_frame %&gt;% \n  left_join(for_doctors_1, by = \"date\") %&gt;% \n  replace_na(list(box = 0)) %&gt;% \n  mutate(cum_box = cumsum(box))\n\ndeli_for_doctors_2 &lt;- date_frame %&gt;% \n  left_join(for_doctors_2, by = \"date\") %&gt;% \n  replace_na(list(box = 0)) %&gt;% \n  mutate(cum_box = cumsum(box))\n\ndeli_for_residents &lt;- date_frame %&gt;% \n  left_join(for_residents, by = \"date\") %&gt;% \n  replace_na(list(box = 0)) %&gt;% \n  mutate(cum_box = cumsum(box))\n\ndelivered &lt;- bind_rows(\n  deli_for_doctors_1 %&gt;% mutate(id = \"Doctors 1st shot\"),\n  deli_for_doctors_2 %&gt;% mutate(id = \"Doctors 2nd shot\"),\n  deli_for_residents %&gt;% mutate(id = \"Residents\")\n)"
  },
  {
    "objectID": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#chart",
    "href": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#chart",
    "title": "Central gov’t, not municipalities, has vaccine stocks",
    "section": "Chart",
    "text": "Chart\nI assume straight line between EU approvals. I also assume 195 vials per box and 6 shots per vial.\nMHLW has not yet scheduled domestic delivery from “2021-09-27” and beyond in its “Prospects for Pfizer vaccine supplies” (japanese).\n\n\nCode\ndelivered %&gt;% \n  mutate(shots = cum_box * 195 * 6 / 1e6) %&gt;% \n  mutate(id = fct_relevel(id, \"Residents\", \"Doctors 2nd shot\")) %&gt;% \n  ggplot(aes(date, shots)) +\n  geom_area(aes(fill = id)) +\n  geom_line(data = export) +\n  geom_vline(xintercept = as.Date(\"2021-06-30\"), lty = 3) +\n  labs(y = \"Cumulative shots (million)\", x = NULL, fill = \"Delivered to:\",\n       title = \"Pfizer vaccine supply and demand in Japan\",\n       subtitle = \"line: EU export approval, area: domestically distributed\")\n\n\n\n\n\nFigure 1: Pfizer vaccine supply and demand in Japan\n\n\n\n\nAs of June 30, EU approved 100M shots exports, and cumulative domestic delivery was 91.2M shots. So 8.8M shots were undelivered stocks.\n\n\nCode\ndelivered %&gt;% \n  mutate(shots = cum_box * 195 * 6 / 1e6) %&gt;% \n  filter(date == \"2021-06-30\") %&gt;% \n  summarize(shots = sum(shots)) %&gt;% \n  pull(shots) %&gt;% \n  round(1)\n\n\n[1] 91.2\n\n\nAs of July 31, EU approval is 100 + 70 / 3 = 123.3M, proportionally, assuming EU approves additional 70M by the end of September. Cumulative domestic delivery is 115.8M shots. 7.5M shots are undelivered stocks.\n\n\nCode\ndelivered %&gt;% \n  mutate(shots = cum_box * 195 * 6 / 1e6) %&gt;% \n  filter(date == \"2021-07-31\") %&gt;% \n  summarize(shots = sum(shots)) %&gt;% \n  pull(shots) %&gt;% \n  round(1)\n\n\n[1] 115.8"
  },
  {
    "objectID": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#conclusion",
    "href": "posts/2021-08-01-central-gov-t-not-municipalities-has-vaccine-stocks/index.html#conclusion",
    "title": "Central gov’t, not municipalities, has vaccine stocks",
    "section": "Conclusion",
    "text": "Conclusion\nI guess 10M missing shots for unknown reasons, which FNN reported (Japanese), are mainly due to the time lag between EU export approval and domestic delivery. If I am right, it is not municipalities but the central government who has stocks."
  },
  {
    "objectID": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html",
    "href": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html",
    "title": "How to finance war against Godzilla",
    "section": "",
    "text": "Code\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#a-tiny-model-before-expansion",
    "href": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#a-tiny-model-before-expansion",
    "title": "How to finance war against Godzilla",
    "section": "A tiny model before expansion",
    "text": "A tiny model before expansion\nI made a tiny model in the previous post, and showed that government debt can be a tool to bring about windfall and damage by transferring buying power from future Generations to the current one, and that windfall and damage can also be caused by population bonus and onus, and productivity growth and stagnation through interest income from holding bonds.\nAssumptions were:\n\nOur economy is a one factor (labor), three sector (Generation 1 and 2, Government), and closed economy. There is no capital, no business sector, no international trade, and no foreigner. Ignore financial sector as an intermediary.\nAll goods and services produced in a Period are perishable, and must be consumed in that Period, like foodstuff and entertainment, care and medicine services. There is no stock, and no investment.\nThe only role of Government is to issue and pay back bonds, of which duration is one Period, 30 years. There is no defense spending, and no taxes.\nThe only method for Generation to save is to buy bonds."
  },
  {
    "objectID": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#a-tiny-model-after-expansion",
    "href": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#a-tiny-model-after-expansion",
    "title": "How to finance war against Godzilla",
    "section": "A tiny model after expansion",
    "text": "A tiny model after expansion\nNow I would like to change 3. as below.\nThe roles of Government are:\n\nto issue and pay back bonds, of which duration is one Period, 30 years,\nto supply national defense service against the natural disasters, such as flood, earthquake and pandemic, (as I continue to assume no foreigner, there is no war against humans) and\nto collect tax.\n\nYou can see my tiny model after expansion at tiny_model2 function in the Rmarkdown format of this post.\n\n\nCode\ntiny_model2 &lt;- function(population_growth, productivity_growth, mobilize, tax_income_rate, tax_consumption_rate, saving_rate = NULL) {\n  by_generation &lt;- tibble(\n    Generation = 1:7,\n    population = 100 * c(1, cumprod(population_growth)),\n    reproduce_rate = c(population_growth, NA)\n  )\n  \n  by_period &lt;- tibble(\n    Period = 1:6,\n    pop_retired = by_generation$population[-7],\n    pop_working = by_generation$population[-1],\n    productivity = 20 * c(1, cumprod(productivity_growth)),\n    mobilize = mobilize,\n    tax_income_rate = tax_income_rate,\n    tax_consumption_rate = tax_consumption_rate\n  )\n  \n  by_period &lt;- by_period %&gt;% \n    mutate(\n      pop_total = pop_retired + pop_working,\n      retired_ratio_pop = pop_retired / pop_total,\n      GDP = productivity * pop_working,\n      gov_defense_layout = GDP * mobilize,\n      gov_defense_revenue = GDP * tax_income_rate + GDP * (1 - mobilize) * tax_consumption_rate,\n      gov_defense_balance = gov_defense_revenue - gov_defense_layout,\n      gov_defense_balance_cum = cumsum(gov_defense_balance)\n    )\n  \n  if (is.null(saving_rate)) {\n    by_period &lt;- by_period %&gt;% \n      mutate(saving_rate = retired_ratio_pop)\n  } else {\n    by_period &lt;- by_period %&gt;% \n      mutate(saving_rate = saving_rate)\n  }\n  \n  by_period &lt;- by_period %&gt;% \n    mutate(\n      disp_income = GDP - gov_defense_layout,\n      consump_retired = disp_income * saving_rate ,\n      consump_working = disp_income - consump_retired,\n      tax_working = GDP * tax_income_rate + consump_working * tax_consumption_rate,\n      tax_retired = consump_retired * tax_consumption_rate,\n      percap_cons_wk = consump_working / pop_working,\n      percap_cons_re = consump_retired / pop_retired,\n      bond_balance = consump_retired + tax_retired - gov_defense_balance,\n      income_from_interest = consump_retired + tax_retired - lag(bond_balance),\n      # real interest rate per year\n      annual_interest_rate = (((consump_retired + tax_retired) / (lag(bond_balance)))^(1/30) - 1) * 100,\n      debt_GDP_ratio = bond_balance / GDP,\n      after_tax_saving_rate = bond_balance / (GDP - tax_working)\n    )\n\n  by_generation &lt;- by_generation %&gt;% \n    bind_cols(\n      tibble(\n          consump_working = c(NA, by_period$consump_working[-11]),\n          tax_working = c(NA, by_period$tax_working[-11]),\n          consump_retired = c(by_period$consump_retired, NA),\n          tax_retired = c(by_period$tax_retired, NA),\n          income_from_work = c(NA, by_period$GDP),\n          income_from_interest = c(by_period$income_from_interest, NA)\n      )\n    )\n  \n  by_generation &lt;- by_generation %&gt;% \n    mutate(\n      consumption = consump_working + consump_retired,\n      tax = tax_working + tax_retired,\n      percap_consump = consumption / population,\n      percap_income_from_work = income_from_work / population,\n      percap_income_from_interest = income_from_interest / population,\n      percap_cons_wk = consump_working / population,\n      percap_cons_re = consump_retired / population,\n      percap_tax = tax / population\n      )\n  \n  list(\n    by_period = by_period,\n    by_generation = by_generation\n  )\n}\n\n\nBy expanding the model, I would like to check whether government debt, named war bond, is necessary to transfer buying power from peace time Generations to war-stricken Generations."
  },
  {
    "objectID": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#war-against-godzilla",
    "href": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#war-against-godzilla",
    "title": "How to finance war against Godzilla",
    "section": "War against Godzilla",
    "text": "War against Godzilla\nLet us regard the natural disasters as Godzilla.\nSuppose we know from a long history that Godzilla hits us irregularly, but on average once in every 3 Generation (90 years). We spend 10 percent of GDP to watch Godzilla in peace time Period, and spend 40 percent of GDP to fight against Godzilla in war time Period. How to fight? Imagine Government mobilizes additional 30 percent (plus peacetime 10 percent equals 40 percent in total) Working Generation, and makes them dancing and chanting “Godzilla, Ya!” without joy to calm down Godzilla. This works, and Godzilla goes away for a while. Otherwise, Godzilla will kill everybody, and no history will be written.\n\n\n\nFigure 1: Period Generation Matrix with defense spending"
  },
  {
    "objectID": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#simulations",
    "href": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#simulations",
    "title": "How to finance war against Godzilla",
    "section": "Simulations",
    "text": "Simulations\n\nAssume constant population and productivity through out this post\nNow suppose population is constant 100 persons in every Generation, and productivity is constant 20 yen per person. So GDP is constant 2000 yen.\n\n\nCode\n# multiplier by Generation, 30 years, is constant 1 for Generation 2 to 7\npopulation_growth &lt;- rep(1, 6)\n\n# multiplier by Period, 30 years, is constant 1 for Period 2 to 6\nproductivity_growth &lt;- rep(1, 5) \n\n# Godzilla hits Period 3 and 6\nmobilize &lt;- c(0.1, 0.1, 0.4, 0.1, 0.1, 0.4)\n\n\n\n\nCode\n# Income tax rates change accordingly\ntax_income_rate &lt;- mobilize\n\n# No consumption tax\ntax_consumption_rate &lt;- rep(0, 6)\n\nmodel1 &lt;- tiny_model2(population_growth, productivity_growth, mobilize, tax_income_rate, tax_consumption_rate)\n\nmodel1$by_period %&gt;% \n  select(Period, pop_total, pop_retired, pop_working, retired_ratio_pop) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\",\n      \"Population Total (persons)\",\n      \"Population Retired (persons)\",\n      \"Population Working (persons)\",\n      \"Ratio of Retired\"\n      )\n    )\n\n\n\n\nTable 1: Population by Period\n\n\n\n\n\n\n\n\n\nPeriod\nPopulation Total (persons)\nPopulation Retired (persons)\nPopulation Working (persons)\nRatio of Retired\n\n\n\n\n1\n200\n100\n100\n0.5\n\n\n2\n200\n100\n100\n0.5\n\n\n3\n200\n100\n100\n0.5\n\n\n4\n200\n100\n100\n0.5\n\n\n5\n200\n100\n100\n0.5\n\n\n6\n200\n100\n100\n0.5\n\n\n\n\n\n\n\n\nCase 1: Income tax rates move according to mobilization\nSuppose income tax rates are 10 percent in peace Period, and 40 percent in war Period. No bond issue to finance a war. And suppose Generation n and Generation n-1 agree to share the produced other than defense spending by population ratio so that each person can consume equally in each Period.\n\n\nCode\nmodel1$by_period %&gt;% \n  select(Period, mobilize, tax_income_rate, tax_consumption_rate, saving_rate, after_tax_saving_rate, debt_GDP_ratio, annual_interest_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Mobilize (share in working population)\",\n      \"Income tax rate\",\n      \"Consumption tax rate\",\n      \"After defense spending saving rate\",\n      \"After tax saving rate\",\n      \"Government debt to GDP ratio\",\n      \"Interest rate (percent)\"\n      ),\n    digits = c(0, rep(2, 7))\n  )\n\n\n\n\nTable 2: Rates and ratios by Period\n\n\n\n\n\n\n\n\n\n\n\n\nPeriod\nMobilize (share in working population)\nIncome tax rate\nConsumption tax rate\nAfter defense spending saving rate\nAfter tax saving rate\nGovernment debt to GDP ratio\nInterest rate (percent)\n\n\n\n\n1\n0.1\n0.1\n0\n0.5\n0.5\n0.45\nNA\n\n\n2\n0.1\n0.1\n0\n0.5\n0.5\n0.45\n0.00\n\n\n3\n0.4\n0.4\n0\n0.5\n0.5\n0.30\n-1.34\n\n\n4\n0.1\n0.1\n0\n0.5\n0.5\n0.45\n1.36\n\n\n5\n0.1\n0.1\n0\n0.5\n0.5\n0.45\n0.00\n\n\n6\n0.4\n0.4\n0\n0.5\n0.5\n0.30\n-1.34\n\n\n\n\n\n\nBe reminded that the yen values are in Period 1 price level, and that interest rate is determined by the social contract among Generations how to share the produced. Generation 3 works and earns 2000 yen, pays tax 200 yen, consumes 900 yen and saves 900 yen by buying bonds from Government in Period 2. Generation 3 is paid back 900 yen plus some interest by Government in retired in Period 3, but the buying power of received money decreases to 600 yen due to inflation immediately after the news of Godzilla hit. That means real interest is negative 300 yen, negative 3 yen per person, annual real interest rate is -1.34 percent.\n\n\nCode\nmodel1$by_period %&gt;% \n  select(Period, GDP, consump_retired, consump_working, gov_defense_layout) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Retired = Saving by Working (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Defense spending (yen)\"\n    )\n  )\n\n\n\n\nTable 3: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Retired = Saving by Working (yen)\nConsumption by Working (yen)\nDefense spending (yen)\n\n\n\n\n1\n2000\n900\n900\n200\n\n\n2\n2000\n900\n900\n200\n\n\n3\n2000\n600\n600\n800\n\n\n4\n2000\n900\n900\n200\n\n\n5\n2000\n900\n900\n200\n\n\n6\n2000\n600\n600\n800\n\n\n\n\n\n\nWhile Generation 2 and 5 who are lucky enough not to be hit by Godzilla consume 18 yen per person, other Generations who are hit by Godzilla either in working or in retired consume 15 yen per person.\n\n\nCode\nmodel1$by_generation %&gt;% \n  select(Generation, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    )\n  )\n\n\n\n\nTable 4: Consumption per person by Generation\n\n\n\n\n\n\n\n\nGeneration\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\nNA\nNA\n9\n\n\n2\n18\n9\n9\n\n\n3\n15\n9\n6\n\n\n4\n15\n6\n9\n\n\n5\n18\n9\n9\n\n\n6\n15\n9\n6\n\n\n7\nNA\n6\nNA\n\n\n\n\n\n\n\n\nCode\nmodel1$by_generation %&gt;% \n  select(Generation, percap_income_from_work, percap_income_from_interest, percap_consump, percap_tax) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Income in Working (yen/person)\",\n      \"Income in Retired (interest income) (yen/person)\",\n      \"Consumption in Total (yen/person)\",\n      \"Tax payment = Defense spending (yen/person)\"\n    ),\n    digits = c(0, rep(1, 4))\n  )\n\n\n\n\nTable 5: Income, Consumption and Tax per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nIncome in Working (yen/person)\nIncome in Retired (interest income) (yen/person)\nConsumption in Total (yen/person)\nTax payment = Defense spending (yen/person)\n\n\n\n\n1\nNA\nNA\nNA\nNA\n\n\n2\n20\n0\n18\n2\n\n\n3\n20\n-3\n15\n2\n\n\n4\n20\n3\n15\n8\n\n\n5\n20\n0\n18\n2\n\n\n6\n20\n-3\n15\n2\n\n\n7\n20\nNA\nNA\nNA\n\n\n\n\n\n\n\n\nCase 2: Consumption tax rates move according to mobilization\nIs there any change, if we tax not on income but on consumption?\nNote that consumption tax rate is 1/10 in this model as well as in Japan, when we pay 11 yen in total, 1 yen for consumption tax and 10 yen for consumption.\nNow note that interest rate and interest income changes to zero in any Period and Generation.\n\n\nCode\n# No income tax\ntax_income_rate &lt;- rep(0, 6)\n\n# Consumption tax rates change accordingly\ntax_consumption_rate &lt;- c(1/9, 1/9, 4/6, 1/9, 1/9, 4/6)\n\nmodel2 &lt;- tiny_model2(population_growth, productivity_growth, mobilize, tax_income_rate, tax_consumption_rate)\n\nmodel2$by_period %&gt;% \n  select(Period, mobilize, tax_income_rate, tax_consumption_rate, saving_rate, after_tax_saving_rate, debt_GDP_ratio, annual_interest_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Mobilize (share in working population)\",\n      \"Income tax rate\",\n      \"Consumption tax rate\",\n      \"After defense spending saving rate\",\n      \"After tax saving rate\",\n      \"Government debt to GDP ratio\",\n      \"Interest rate (percent)\"\n      ),\n    digits = c(0, rep(2, 7))\n  )\n\n\n\n\nTable 6: Rates and ratios by Period\n\n\n\n\n\n\n\n\n\n\n\n\nPeriod\nMobilize (share in working population)\nIncome tax rate\nConsumption tax rate\nAfter defense spending saving rate\nAfter tax saving rate\nGovernment debt to GDP ratio\nInterest rate (percent)\n\n\n\n\n1\n0.1\n0\n0.11\n0.5\n0.53\n0.5\nNA\n\n\n2\n0.1\n0\n0.11\n0.5\n0.53\n0.5\n0\n\n\n3\n0.4\n0\n0.67\n0.5\n0.62\n0.5\n0\n\n\n4\n0.1\n0\n0.11\n0.5\n0.53\n0.5\n0\n\n\n5\n0.1\n0\n0.11\n0.5\n0.53\n0.5\n0\n\n\n6\n0.4\n0\n0.67\n0.5\n0.62\n0.5\n0\n\n\n\n\n\n\n\n\nCode\nmodel2$by_period %&gt;% \n  select(Period, GDP, consump_retired, consump_working, gov_defense_layout) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Retired = Saving by Working (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Defense spending (yen)\"\n    )\n  )\n\n\n\n\nTable 7: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Retired = Saving by Working (yen)\nConsumption by Working (yen)\nDefense spending (yen)\n\n\n\n\n1\n2000\n900\n900\n200\n\n\n2\n2000\n900\n900\n200\n\n\n3\n2000\n600\n600\n800\n\n\n4\n2000\n900\n900\n200\n\n\n5\n2000\n900\n900\n200\n\n\n6\n2000\n600\n600\n800\n\n\n\n\n\n\n\n\nCode\nmodel2$by_generation %&gt;% \n  select(Generation, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    )\n  )\n\n\n\n\nTable 8: Consumption per person by Generation\n\n\n\n\n\n\n\n\nGeneration\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\nNA\nNA\n9\n\n\n2\n18\n9\n9\n\n\n3\n15\n9\n6\n\n\n4\n15\n6\n9\n\n\n5\n18\n9\n9\n\n\n6\n15\n9\n6\n\n\n7\nNA\n6\nNA\n\n\n\n\n\n\n\n\nCode\nmodel2$by_generation %&gt;% \n  select(Generation, percap_income_from_work, percap_income_from_interest, percap_consump, percap_tax) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Income in Working (yen/person)\",\n      \"Income in Retired (interest income) (yen/person)\",\n      \"Consumption in Total (yen/person)\",\n      \"Tax payment = Defense spending (yen/person)\"\n    ),\n    digits = c(0, rep(1, 4))\n  )\n\n\n\n\nTable 9: Income, Consumption and Tax per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nIncome in Working (yen/person)\nIncome in Retired (interest income) (yen/person)\nConsumption in Total (yen/person)\nTax payment = Defense spending (yen/person)\n\n\n\n\n1\nNA\nNA\nNA\nNA\n\n\n2\n20\n0\n18\n2\n\n\n3\n20\n0\n15\n5\n\n\n4\n20\n0\n15\n5\n\n\n5\n20\n0\n18\n2\n\n\n6\n20\n0\n15\n5\n\n\n7\n20\nNA\nNA\nNA\n\n\n\n\n\n\nHowever, there is no change in consumption whether we tax income or consumption. The buying power of Generation 3, who is paid back 900 yen plus some interest by Government in retired in Period 3, is reduced to 600 yen by inflation in Case 1, and is reduced to the same 600 yen by higher consumption tax rate in Case 2.\n\n\nCase 3: Change sharing rule from 50:50 in each Period to expected 50:50 in life for each Generation\nAs long as I assume Generation n and n-1 agrees to share 50:50 the produced other than defense spending so that each Generation can consume equally in each Period, lucky Generation 2 and 5 can consume 18 yen per person in total, and unlucky other Generations consume 15 yen.\nLet us change the assumption about Godzilla hits from irregular once in 3 Period on average to regular every 3 Period. Under this assumption, we can know Period 3 and 6 are war time Periods in advance. Then lucky Generations and unlucky Generations may agree to share\n\n50:50 for Retired and Working in war time Period (both Retired and Working are war-stricken),\n55.56:44.44 next Period (Retired is war-stricken, and Working is not) and\n44.44:55.56 next next Period (Retired is not war-stricken, and Working will be war-stricken next Period).\n\nNo income tax. Consumption tax rates are same as Case 2.\n\n\nCode\n# saving rate to make equal consumption in life of each Generation\nsaving_rate &lt;- c(10/18, 8/18, 6/12, 10/18, 8/18, 6/12)\n\n# No income tax\ntax_income_rate &lt;- rep(0, 6)\n\n# Consumption tax rates change accordingly\ntax_consumption_rate &lt;- c(1/9, 1/9, 4/6, 1/9, 1/9, 4/6)\n\nmodel3 &lt;- tiny_model2(population_growth, productivity_growth, mobilize, tax_income_rate, tax_consumption_rate, saving_rate)\n\nmodel3$by_period %&gt;% \n  select(Period, mobilize, tax_income_rate, tax_consumption_rate, saving_rate, after_tax_saving_rate, debt_GDP_ratio, annual_interest_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Mobilize (share in working population)\",\n      \"Income tax rate\",\n      \"Consumption tax rate\",\n      \"After defense spending saving rate\",\n      \"After tax saving rate\",\n      \"Government debt to GDP ratio\",\n      \"Interest rate (percent)\"\n      ),\n    digits = c(0, rep(2, 7))\n  )\n\n\n\n\nTable 10: Rates and ratios by Period\n\n\n\n\n\n\n\n\n\n\n\n\nPeriod\nMobilize (share in working population)\nIncome tax rate\nConsumption tax rate\nAfter defense spending saving rate\nAfter tax saving rate\nGovernment debt to GDP ratio\nInterest rate (percent)\n\n\n\n\n1\n0.1\n0\n0.11\n0.56\n0.58\n0.56\nNA\n\n\n2\n0.1\n0\n0.11\n0.44\n0.47\n0.44\n-0.74\n\n\n3\n0.4\n0\n0.67\n0.50\n0.62\n0.50\n0.39\n\n\n4\n0.1\n0\n0.11\n0.56\n0.58\n0.56\n0.35\n\n\n5\n0.1\n0\n0.11\n0.44\n0.47\n0.44\n-0.74\n\n\n6\n0.4\n0\n0.67\n0.50\n0.62\n0.50\n0.39\n\n\n\n\n\n\n\n\nCode\nmodel3$by_period %&gt;% \n  select(Period, GDP, consump_retired, consump_working, gov_defense_layout) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Retired = Saving by Working (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Defense spending (yen)\"\n    )\n  )\n\n\n\n\nTable 11: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Retired = Saving by Working (yen)\nConsumption by Working (yen)\nDefense spending (yen)\n\n\n\n\n1\n2000\n1000\n800\n200\n\n\n2\n2000\n800\n1000\n200\n\n\n3\n2000\n600\n600\n800\n\n\n4\n2000\n1000\n800\n200\n\n\n5\n2000\n800\n1000\n200\n\n\n6\n2000\n600\n600\n800\n\n\n\n\n\n\n\n\nCode\nmodel3$by_generation %&gt;% \n  select(Generation, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    )\n  )\n\n\n\n\nTable 12: Consumption per person by Generation\n\n\n\n\n\n\n\n\nGeneration\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\nNA\nNA\n10\n\n\n2\n16\n8\n8\n\n\n3\n16\n10\n6\n\n\n4\n16\n6\n10\n\n\n5\n16\n8\n8\n\n\n6\n16\n10\n6\n\n\n7\nNA\n6\nNA\n\n\n\n\n\n\n\n\nCode\nmodel3$by_generation %&gt;% \n  select(Generation, percap_income_from_work, percap_income_from_interest, percap_consump, percap_tax) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Income in Working (yen/person)\",\n      \"Income in Retired (interest income) (yen/person)\",\n      \"Consumption in Total (yen/person)\",\n      \"Tax payment = Defense spending (yen/person)\"\n    ),\n    digits = c(0, rep(1, 4))\n  )\n\n\n\n\nTable 13: Income, Consumption and Tax per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nIncome in Working (yen/person)\nIncome in Retired (interest income) (yen/person)\nConsumption in Total (yen/person)\nTax payment = Defense spending (yen/person)\n\n\n\n\n1\nNA\nNA\nNA\nNA\n\n\n2\n20\n-2.2\n16\n1.8\n\n\n3\n20\n1.1\n16\n5.1\n\n\n4\n20\n1.1\n16\n5.1\n\n\n5\n20\n-2.2\n16\n1.8\n\n\n6\n20\n1.1\n16\n5.1\n\n\n7\n20\nNA\nNA\nNA\n\n\n\n\n\n\nConsumption in total is 16 yen per person for every Generation. Inter-Generation equity is achieved!\n\n\nCase 4: Set consumption tax rate constant at 4/16, and issue war bond in war time Period\nAs production is 20 yen per person and consumption in total is 16 yen per person, let us set consumption tax rate at 4/16 in every Period. This means Government issue war bond in war time Period, pays back some parts and roll over other parts in peace time Period.\n\n\nCode\n# saving rate to make equal consumption in life of each Generation\nsaving_rate &lt;- c(10/18, 8/18, 6/12, 10/18, 8/18, 6/12)\n\n# No income tax\ntax_income_rate &lt;- rep(0, 6)\n\n# Constant consumption tax rates over Periods\ntax_consumption_rate &lt;- rep(4/16, 6)\n\nmodel4 &lt;- tiny_model2(population_growth, productivity_growth, mobilize, tax_income_rate, tax_consumption_rate, saving_rate)\n\nmodel4$by_period %&gt;% \n  select(Period, mobilize, tax_income_rate, tax_consumption_rate, saving_rate, after_tax_saving_rate, debt_GDP_ratio, annual_interest_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Mobilize (share in working population)\",\n      \"Income tax rate\",\n      \"Consumption tax rate\",\n      \"After defense spending saving rate\",\n      \"After tax saving rate\",\n      \"Government debt to GDP ratio\",\n      \"Interest rate (percent)\"\n      ),\n    digits = c(0, rep(2, 7))\n  )\n\n\n\n\nTable 14: Rates and ratios by Period\n\n\n\n\n\n\n\n\n\n\n\n\nPeriod\nMobilize (share in working population)\nIncome tax rate\nConsumption tax rate\nAfter defense spending saving rate\nAfter tax saving rate\nGovernment debt to GDP ratio\nInterest rate (percent)\n\n\n\n\n1\n0.1\n0\n0.25\n0.56\n0.56\n0.50\nNA\n\n\n2\n0.1\n0\n0.25\n0.44\n0.43\n0.38\n0\n\n\n3\n0.4\n0\n0.25\n0.50\n0.68\n0.62\n0\n\n\n4\n0.1\n0\n0.25\n0.56\n0.56\n0.50\n0\n\n\n5\n0.1\n0\n0.25\n0.44\n0.43\n0.38\n0\n\n\n6\n0.4\n0\n0.25\n0.50\n0.68\n0.62\n0\n\n\n\n\n\n\n\n\nCode\nmodel4$by_period %&gt;% \n  select(Period, GDP, consump_retired, consump_working, gov_defense_layout) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Retired (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Defense spending (yen)\"\n    ),\n    digits = rep(0, 5)\n  )\n\n\n\n\nTable 15: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Retired (yen)\nConsumption by Working (yen)\nDefense spending (yen)\n\n\n\n\n1\n2000\n1000\n800\n200\n\n\n2\n2000\n800\n1000\n200\n\n\n3\n2000\n600\n600\n800\n\n\n4\n2000\n1000\n800\n200\n\n\n5\n2000\n800\n1000\n200\n\n\n6\n2000\n600\n600\n800\n\n\n\n\n\n\n\n\nCode\nmodel4$by_period %&gt;% \n  select(Period, gov_defense_layout, gov_defense_revenue,\n         gov_defense_balance, gov_defense_balance_cum) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Defense spending (yen)\",\n      \"Tax revenue (yen)\",\n      \"Fiscal balance (yen)\",\n      \"Cumulative fiscal balance (yen)\"\n    ),\n    digits = rep(0, 5)\n  )\n\n\n\n\nTable 16: Defense spending and tax revenue by Period\n\n\n\n\n\n\n\n\n\nPeriod\nDefense spending (yen)\nTax revenue (yen)\nFiscal balance (yen)\nCumulative fiscal balance (yen)\n\n\n\n\n1\n200\n450\n250\n250\n\n\n2\n200\n450\n250\n500\n\n\n3\n800\n300\n-500\n0\n\n\n4\n200\n450\n250\n250\n\n\n5\n200\n450\n250\n500\n\n\n6\n800\n300\n-500\n0\n\n\n\n\n\n\n\n\nCode\nmodel4$by_generation %&gt;% \n  select(Generation, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    ),\n    digits = rep(0, 4)\n  )\n\n\n\n\nTable 17: Consumption per person by Generation\n\n\n\n\n\n\n\n\nGeneration\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\nNA\nNA\n10\n\n\n2\n16\n8\n8\n\n\n3\n16\n10\n6\n\n\n4\n16\n6\n10\n\n\n5\n16\n8\n8\n\n\n6\n16\n10\n6\n\n\n7\nNA\n6\nNA\n\n\n\n\n\n\n\n\nCode\nmodel4$by_generation %&gt;% \n  select(Generation, percap_income_from_work, percap_income_from_interest, percap_consump, percap_tax) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Income in Working (yen/person)\",\n      \"Income in Retired (interest income) (yen/person)\",\n      \"Consumption in Total (yen/person)\",\n      \"Tax payment (yen/person)\"\n    ),\n    digits = c(0, rep(1, 4))\n  )\n\n\n\n\nTable 18: Income, Consumption and Tax per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nIncome in Working (yen/person)\nIncome in Retired (interest income) (yen/person)\nConsumption in Total (yen/person)\nTax payment (yen/person)\n\n\n\n\n1\nNA\nNA\nNA\nNA\n\n\n2\n20\n0\n16\n4\n\n\n3\n20\n0\n16\n4\n\n\n4\n20\n0\n16\n4\n\n\n5\n20\n0\n16\n4\n\n\n6\n20\n0\n16\n4\n\n\n7\n20\nNA\nNA\nNA\n\n\n\n\n\n\nConsumption is not changed, but interest income is changed to zero. War bond replaces interest income’s role of transferring buying power across Generations.\n\n\nCase 5: Godzilla comes back sooner than expected\nNow let us change back the assumption about Godzilla hits from regular every 3 Period to irregular once in 3 Period on average. We can say consumption in total is expected to be equal for every Generation, but may turn out to be different.\nSo far we supposed Period 3 and 6 are war time Periods. Let us suppose Period 3 and 4 are war time Periods instead.\n\n\nCode\n# war time in Period 3 and 4\nmobilize &lt;- c(0.1, 0.1, 0.4, 0.4, 0.1, 0.1)\n\n# Constant consumption tax rates over Periods\ntax_consumption_rate &lt;- rep(4/16, 6)\n\n# No income tax\ntax_income_rate &lt;- rep(0, 6)\n\n# saving rate to make equal consumption in life of each Generation\nsaving_rate &lt;- c(10/18, 8/18, 6/12, 10/12, 14/18, 12/18)\n\nmodel5 &lt;- tiny_model2(population_growth, productivity_growth, mobilize, tax_income_rate, tax_consumption_rate, saving_rate)\n\nmodel5$by_period %&gt;% \n  select(Period, mobilize, tax_income_rate, tax_consumption_rate, saving_rate, after_tax_saving_rate, debt_GDP_ratio, annual_interest_rate) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Mobilize (share in working population)\",\n      \"Income tax rate\",\n      \"Consumption tax rate\",\n      \"After defense spending saving rate\",\n      \"After tax saving rate\",\n      \"Government debt to GDP ratio\",\n      \"Interest rate (percent)\"\n      ),\n    digits = c(0, rep(2, 7))\n  )\n\n\n\n\nTable 19: Rates and ratios by Period\n\n\n\n\n\n\n\n\n\n\n\n\nPeriod\nMobilize (share in working population)\nIncome tax rate\nConsumption tax rate\nAfter defense spending saving rate\nAfter tax saving rate\nGovernment debt to GDP ratio\nInterest rate (percent)\n\n\n\n\n1\n0.1\n0\n0.25\n0.56\n0.56\n0.50\nNA\n\n\n2\n0.1\n0\n0.25\n0.44\n0.43\n0.38\n0\n\n\n3\n0.4\n0\n0.25\n0.50\n0.68\n0.62\n0\n\n\n4\n0.4\n0\n0.25\n0.83\n0.90\n0.88\n0\n\n\n5\n0.1\n0\n0.25\n0.78\n0.79\n0.75\n0\n\n\n6\n0.1\n0\n0.25\n0.67\n0.68\n0.62\n0\n\n\n\n\n\n\n\n\nCode\nmodel5$by_period %&gt;% \n  select(Period, GDP, consump_retired, consump_working, gov_defense_layout) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"GDP (yen)\",\n      \"Consumption by Retired (yen)\",\n      \"Consumption by Working (yen)\",\n      \"Defense spending (yen)\"\n    ),\n    digits = rep(0, 5)\n  )\n\n\n\n\nTable 20: Production and Consumption by Period\n\n\n\n\n\n\n\n\n\nPeriod\nGDP (yen)\nConsumption by Retired (yen)\nConsumption by Working (yen)\nDefense spending (yen)\n\n\n\n\n1\n2000\n1000\n800\n200\n\n\n2\n2000\n800\n1000\n200\n\n\n3\n2000\n600\n600\n800\n\n\n4\n2000\n1000\n200\n800\n\n\n5\n2000\n1400\n400\n200\n\n\n6\n2000\n1200\n600\n200\n\n\n\n\n\n\n\n\nCode\nmodel5$by_period %&gt;% \n  select(Period, gov_defense_layout, gov_defense_revenue,\n         gov_defense_balance, gov_defense_balance_cum) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Period\", \"Defense spending (yen)\",\n      \"Tax revenue (yen)\",\n      \"Fiscal balance (yen)\",\n      \"Cumulative fiscal balance (yen)\"\n    ),\n    digits = rep(0, 5)\n  )\n\n\n\n\nTable 21: Defense spending and tax revenue by Period\n\n\n\n\n\n\n\n\n\nPeriod\nDefense spending (yen)\nTax revenue (yen)\nFiscal balance (yen)\nCumulative fiscal balance (yen)\n\n\n\n\n1\n200\n450\n250\n250\n\n\n2\n200\n450\n250\n500\n\n\n3\n800\n300\n-500\n0\n\n\n4\n800\n300\n-500\n-500\n\n\n5\n200\n450\n250\n-250\n\n\n6\n200\n450\n250\n0\n\n\n\n\n\n\n\n\nCode\nmodel5$by_generation %&gt;% \n  select(Generation, percap_consump, percap_cons_wk, percap_cons_re) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Consumption in Total (yen/person)\",\n      \"Consumption in Working (yen/person)\",\n      \"Consumption in Retired (yen/person)\"\n    ),\n    digits = rep(0, 4)\n  )\n\n\n\n\nTable 22: Consumption per person by Generation\n\n\n\n\n\n\n\n\nGeneration\nConsumption in Total (yen/person)\nConsumption in Working (yen/person)\nConsumption in Retired (yen/person)\n\n\n\n\n1\nNA\nNA\n10\n\n\n2\n16\n8\n8\n\n\n3\n16\n10\n6\n\n\n4\n16\n6\n10\n\n\n5\n16\n2\n14\n\n\n6\n16\n4\n12\n\n\n7\nNA\n6\nNA\n\n\n\n\n\n\n\n\nCode\nmodel5$by_generation %&gt;% \n  select(Generation, percap_income_from_work, percap_income_from_interest, percap_consump, percap_tax) %&gt;% \n  knitr::kable(\n    col.names = c(\n      \"Generation\", \n      \"Income in Working (yen/person)\",\n      \"Income in Retired (interest income) (yen/person)\",\n      \"Consumption in Total (yen/person)\",\n      \"Tax payment (yen/person)\"\n    ),\n    digits = c(0, rep(1, 4))\n  )\n\n\n\n\nTable 23: Income, Consumption and Tax per person by Generation\n\n\n\n\n\n\n\n\n\nGeneration\nIncome in Working (yen/person)\nIncome in Retired (interest income) (yen/person)\nConsumption in Total (yen/person)\nTax payment (yen/person)\n\n\n\n\n1\nNA\nNA\nNA\nNA\n\n\n2\n20\n0\n16\n4\n\n\n3\n20\n0\n16\n4\n\n\n4\n20\n0\n16\n4\n\n\n5\n20\n0\n16\n4\n\n\n6\n20\n0\n16\n4\n\n\n7\n20\nNA\nNA\nNA\n\n\n\n\n\n\nWe can keep consumption in total to be equal for every Generation, if Generation 4 and beyond are confident Godzilla does not hit more than once in 3 Periods on average, and agree to new share rule, though Generation 5 working in Period 4 the second consecutive war time Period may not be able to endure only 2 yen per person consumption. Additional war bonds can’t help Generation 5 in Period 4, as total consumption is constrained to 6 yen per person on average. If Generation 5 can’t endure 2 yen per person consumption in Period 4, and is afraid Godzilla may come back in Period 5, this share rule will collapse in Period 4."
  },
  {
    "objectID": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#it-is-inter-generation-equity-stupid",
    "href": "posts/2021-05-13-how-to-finance-war-against-godzilla/index.html#it-is-inter-generation-equity-stupid",
    "title": "How to finance war against Godzilla",
    "section": "It is inter-Generation equity, stupid",
    "text": "It is inter-Generation equity, stupid\nFrom above simulations, what can I say?\n\nWar bond is not essential to spread war burdens across Generations. Even if war bond is not issued, interest income from holding bonds play the role of spreading burdens across Generations.\nThat said, war bond is an orderly manner to spread war burdens intra-Generation. While tax hike hurts the poor, war bond collects money from the rich.\nAgreed share rule between Retired and Working Generations is essential to achieve inter-Generation equity.\n\nThe reason why I expand the model, and to check the role of war bond is because I read briefly the book “Look deep into the fiscal crisis” (Japanese), written by Kazumasa Oguro, a former Ministry of Finance officer, now a economics professor and a famous fiscal soundness advocate, and published by a subsidiary of NHK.\nHe explains government debt situation by comparing to household debt. I feel uneasy, because government debt creates mostly both bond holders’ credit and Government’s debt in house (a country), while household debt creates, well, only debt in house.\nHe also teaches us a history lesson that Japanese Government Bond defaulted after Japan lost the World War II, when government debt, including war bonds, reached 200 percent of GDP. I suspect the cause of default is not high debt ratio to GDP but the government regime change brought by losing war and being occupied. The man in the high castle may have not seen Japanese Government Bond default.\nAlthough there are many other things I disagree with him on, like the effects of quantitative easing by the Bank of Japan and the necessity to raise consumption tax rates before BOJ achieves 2 percent inflation target, I think he may or may not be right about pension system and inter-Generation equity issues.\nTo fiscal soundness advocates like him, I would like to say, “The issue is not fiscal soundness. It is inter-Generation equity, stupid.”"
  },
  {
    "objectID": "posts/2020-10-28-my-first-pull-request-imfr/index.html",
    "href": "posts/2020-10-28-my-first-pull-request-imfr/index.html",
    "title": "My first pull request: imfr",
    "section": "",
    "text": "I changed code to work under imfr Version 2."
  },
  {
    "objectID": "posts/2020-10-28-my-first-pull-request-imfr/index.html#my-first-pull-request",
    "href": "posts/2020-10-28-my-first-pull-request-imfr/index.html#my-first-pull-request",
    "title": "My first pull request: imfr",
    "section": "My first pull request",
    "text": "My first pull request\nPackage ‘imfr’ is the first package which merged my very small pull request. Thank you, creator Christopher Gandrud. I would like to show a usage example below.\n\n\nCode\nlibrary(tidyverse)\nlibrary(imfr)\n\ntheme_set(theme_light())"
  },
  {
    "objectID": "posts/2020-10-28-my-first-pull-request-imfr/index.html#look-for-database-id",
    "href": "posts/2020-10-28-my-first-pull-request-imfr/index.html#look-for-database-id",
    "title": "My first pull request: imfr",
    "section": "Look for database ID",
    "text": "Look for database ID\nPackage ‘imfr’ provides some functions to help us explore IMF database. First, I use ‘imf_databases’ function to get database IDs.\n\n\nCode\nimf_app_name(\"mitsuoxv\")\n\ndatabases &lt;- imf_databases()\n\n\nThere are 323 databases. I get a dataframe with 2 columns, ‘database_id’ and ‘description’.\n\n\nCode\nhead(databases)\n\n\n  database_id\n1 BOP_2017M06\n2  BOP_2020M3\n3 BOP_2017M11\n4  DOT_2020Q1\n5  GFSMAB2016\n6 BOP_2019M12\n                                                                       description\n1                                              Balance of Payments (BOP), 2017 M06\n2                                              Balance of Payments (BOP), 2020 M03\n3                                              Balance of Payments (BOP), 2017 M11\n4                                    Direction of Trade Statistics (DOTS), 2020 Q1\n5 Government Finance Statistics Yearbook (GFSY 2016), Main Aggregates and Balances\n6                                              Balance of Payments (BOP), 2019 M12\n\n\nI transform ‘description’ into all lower characters, in order to make search easier.\n\n\nCode\ndatabases &lt;- databases |&gt; \n  mutate(description = str_to_lower(description))\n\n\nAs I am interested in debt issues, I search ‘debt’ in ‘description’. I get ‘database_id’ HPDD, of which ‘description’ is historical public debt.\n\n\nCode\ndatabases |&gt; \n  filter(str_detect(description, \"debt\"))\n\n\n  database_id                   description\n1        HPDD historical public debt (hpdd)"
  },
  {
    "objectID": "posts/2020-10-28-my-first-pull-request-imfr/index.html#retrieve-parameters-of-a-database",
    "href": "posts/2020-10-28-my-first-pull-request-imfr/index.html#retrieve-parameters-of-a-database",
    "title": "My first pull request: imfr",
    "section": "Retrieve parameters of a database",
    "text": "Retrieve parameters of a database\nI use ‘imf_parameters’ function to retrieve the parameters of the database whose id is HPDD.\n\n\nCode\nparams &lt;- imf_parameters(\"HPDD\")\n\nstr(params)\n\n\nList of 3\n $ freq     :'data.frame':  3 obs. of  2 variables:\n  ..$ input_code : chr [1:3] \"A\" \"M\" \"Q\"\n  ..$ description: chr [1:3] \"Annual\" \"Monthly\" \"Quarterly\"\n $ ref_area :'data.frame':  199 obs. of  2 variables:\n  ..$ input_code : chr [1:199] \"AF\" \"AL\" \"DZ\" \"AO\" ...\n  ..$ description: chr [1:199] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n $ indicator:'data.frame':  1 obs. of  2 variables:\n  ..$ input_code : chr \"GGXWDG_GDP\"\n  ..$ description: chr \"Debt to GDP Ratio\"\n\n\nThere are 3 lists of code and description:\n\nfrequency,\ngeographical areas (code: two-letter country codes defined in ISO 3166-1), and\nindicator. Here, I get only one indicator GGXWDG_GDP, which describes Debt to GDP Ratio."
  },
  {
    "objectID": "posts/2020-10-28-my-first-pull-request-imfr/index.html#download-data",
    "href": "posts/2020-10-28-my-first-pull-request-imfr/index.html#download-data",
    "title": "My first pull request: imfr",
    "section": "Download data",
    "text": "Download data\nNow I am ready to download data. I use ‘imf_dataset’ function. I specify HPDD as ‘database_id’, select ‘freq’, ‘ref_area’ and ‘indicator’ from the parameters, and set ‘start_year’ and ‘end_year’.\n\n\nCode\ndebt_gdp_ratio &lt;- imf_dataset(\n  database_id = \"HPDD\",\n  freq = \"A\",\n  ref_area = params$ref_area$input_code,\n  indicator = \"GGXWDG_GDP\",\n  start_year = 1700, end_year = 2020\n)\n\n\nI change ‘year’ from character to integer, and add ‘country’ by utilizing the 2nd list.\n\n\nCode\ndebt_gdp_ratio &lt;- debt_gdp_ratio |&gt; \n  as_tibble() |&gt; \n  mutate(across(date:value, as.numeric)) |&gt; \n  select(date:ref_area) |&gt; \n  left_join(params$ref_area, by = c(\"ref_area\"=\"input_code\")) |&gt; \n  rename(country = description)\n\nhead(debt_gdp_ratio)\n\n\n# A tibble: 6 × 5\n   date value freq  ref_area country\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  \n1  1994  85.2 A     AL       Albania\n2  1995  75.0 A     AL       Albania\n3  1996  76.7 A     AL       Albania\n4  1997  81.9 A     AL       Albania\n5  1998  71.9 A     AL       Albania\n6  1999  63.9 A     AL       Albania\n\n\nSome countries have data as old as 1800. They are U.K., U.S. and Sweden. Most recent year is 2015.\n\n\nCode\nrange(debt_gdp_ratio$date)\n\n\n[1] 1800 2015\n\n\n\n\nCode\ndebt_gdp_ratio |&gt;  \n  filter(date == 1800)\n\n\n# A tibble: 3 × 5\n   date value freq  ref_area country       \n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         \n1  1800  34.3 A     SE       Sweden        \n2  1800 177.  A     GB       United Kingdom\n3  1800  18.1 A     US       United States \n\n\n191 countries have some data."
  },
  {
    "objectID": "posts/2020-10-28-my-first-pull-request-imfr/index.html#a-chart-and-some-thoughts",
    "href": "posts/2020-10-28-my-first-pull-request-imfr/index.html#a-chart-and-some-thoughts",
    "title": "My first pull request: imfr",
    "section": "A chart and some thoughts",
    "text": "A chart and some thoughts\nI use countrycode.org to get two-letter code of the select countries, and draw a chart.\nDebt to GDP ratio rises in the war, and, if you win, it decreases thanks to growth and inflation. If you lose, it decreases thanks to some defaults and very high inflation. Some people in the losing side lose their financial wealth, but most misery does not come from debt, but from physical devastation.\nRecently it rises due to secular stagnation, in which monetary policy is constrained by zero lower bound of nominal interest rates, and full employment can be achieved only by bubble or expansionary fiscal policy.\n\n\nCode\ndebt_gdp_ratio %&gt;% \n  filter(ref_area %in% c(\"US\", \"GB\", \"JP\", \"ZW\")) %&gt;% \n  ggplot(aes(date, value, color = fct_reorder2(country, date, value))) +\n  geom_line(linewidth = 1) +\n  labs(x = NULL, y = \"Debt to GDP Ratio\",\n       color = \"counry\")\n\n\n\n\n\nFigure 1: Debt to GDP Ratio in Japan, the US, the UK and Zimbabwe\n\n\n\n\nDebt to GDP ratio reflects the government capacity to borrow, the household and the enterprise capacity to save, and the financial sector capacity to mediate. It melts, if nominal GDP growth rates are higher than nominal interest rates.\nIf Japan falls into deflation, nominal GDP growth rates are negative, and nominal interest rates are zero due to lower bound. This leads to ballooning debt to GDP ratios. Austerity is not the solution, as it leads to deeper deflation and under-employment. Coordinating and rebalancing the monetary and fiscal policies is the solution, which can make inflation expectation positive and well anchored."
  },
  {
    "objectID": "posts/2019-04-25-my-first-post/index.html",
    "href": "posts/2019-04-25-my-first-post/index.html",
    "title": "My first post",
    "section": "",
    "text": "Hello, world. This is a web site of a would-be data scientist, named Mitsuo Shiota. I began to self-learn R one and half years ago in order to get the assigned job done. In that job, I had to deal with massive data. I gave up Excel, and picked up R. Fortunately I encountered an excellent book, “R for Data Science” by Garrett Grolemund and Hadley Wickham, so my journey for data science began.\nIn this web site, I will mainly do some economic analyses by using R and tidyverse."
  },
  {
    "objectID": "posts/2019-04-25-chinese-retaliation-is-half-the-size-of-their-claim/index.html",
    "href": "posts/2019-04-25-chinese-retaliation-is-half-the-size-of-their-claim/index.html",
    "title": "Chinese retaliation is half the size of their claim",
    "section": "",
    "text": "After I confirmed each tariff list of USTR really covers 34, 16 and 200 billion dollars imports from China, I have turned to Chinese claims that their retaliation tariff list covers 3, 34, 16 and 60 billion dollar imports from the US. As China imports from the US are the US exports to China, I can use the same Census Bureau U.S. International Trade Data to confirm their claims.\nAnd my calculation suggests that the Chinese hit-backs are half the size of their claims . My guess is that they calculated the size based on HTS 6 digit codes, while they actually impose tariffs based on both 6 and 8 digit codes."
  },
  {
    "objectID": "posts/2019-04-25-city-competition-to-consume-more-dumplings/index.html",
    "href": "posts/2019-04-25-city-competition-to-consume-more-dumplings/index.html",
    "title": "City competition to consume more dumplings",
    "section": "",
    "text": "This is a pilot project to utilize estatapi package by yutannihilation and e-Stat.\nI have downloaded data of Family Income and Expenditure Survey by the Statistics Bureau, Ministry of Internal Affairs and Communications, and analyzed which city, among 52 cities in Japan, consumed most dumplings per household from 2007 to 2018. Then I have turned to find specialty goods which some cities have persistently consumed most. I have also ranked cities in their consumption in 2018 by each item (499 items in total), and looked at the ranks distribution by each city, which may have been affected by price level differences."
  },
  {
    "objectID": "posts/2019-05-15-update-china-retaliation-even-if-less-than-claimed-hurt-us-exports/index.html",
    "href": "posts/2019-05-15-update-china-retaliation-even-if-less-than-claimed-hurt-us-exports/index.html",
    "title": "Update: China retaliation, even if less than claimed, hurt US exports",
    "section": "",
    "text": "I added some findings to “China-hits-back”. I am now less sure, but still keep my guess that China calculated the retaliation size based on HS 6 digit codes, while they actually impose tariffs based on both 6 and 8 digit codes. And I added a chart to show US exports are hurt, more on retaliated items, less on non-retaliated items."
  },
  {
    "objectID": "posts/2019-06-12-update-ustr-grants-product-exclusions-periodically/index.html",
    "href": "posts/2019-06-12-update-ustr-grants-product-exclusions-periodically/index.html",
    "title": "Update: USTR grants product exclusions periodically",
    "section": "",
    "text": "I have updated US tariffs on China.\nAs I have found USTR grants product exclusions from tariffs in the USTR page, I have added the new category “excl” which are granted to be excluded by USTR. If I calculate based on HTS 10 digit codes, granted exclusions amount to 9.8 among tariff-imposed 34 billion dollars imports so far.\nAs Chinese shares in the products which are not imposed tariffs are as high as those of “excl”, I expect that USTR will receive massive product exclusion requests, if they impose tariffs on them."
  },
  {
    "objectID": "posts/2019-06-18-update-china-retaliation-values-caluculated-from-china-data-not-from-the-us-data/index.html",
    "href": "posts/2019-06-18-update-china-retaliation-values-caluculated-from-china-data-not-from-the-us-data/index.html",
    "title": "Update: China retaliation values caluculated from China data, not from the US data",
    "section": "",
    "text": "I have added a new page to US tariffs on China repo.\nWhen I played with the US customs data, I guessed that Chinese calculated the retaliation values based on HS 6 digit codes, while they actually impose tariffs based on HS 8 digit codes. Later I have learned that HS codes are not so harmonized, and that HS codes can be different between the US and China. I have felt uneasy about my guess. So I have looked for the China customs data. In this new page, I have got the HS 6 digit data reported by China from UN Comtrade, and found that China data also support my guess.\nCORRECTION as of ‘2019-06-24’: As I forgot to change text2df function, I continued to omit 0s in the right of tariff imposed HS 8 digit codes in “China-hits-back2.Rmd”. As a result, some HS 6 digit codes failed to match, and I calculated import values as smaller than actual. After correction, I have found that China data do NOT support my guess."
  },
  {
    "objectID": "posts/2019-09-09-december-15-tariffs-target-imports-which-china-has-more-than-75-percent-shares/index.html",
    "href": "posts/2019-09-09-december-15-tariffs-target-imports-which-china-has-more-than-75-percent-shares/index.html",
    "title": "December 15 tariffs target imports which China has more than 75 percent shares",
    "section": "",
    "text": "I have added the new tariff schedules “300b_a” (effective 10 percent on September 1, 2019, and 15 percent after October 1, 2019) and “300b_c” (will be effective 15 percent on December 15, 2019) to my study Chinese shares in US imports by tariff schedule.\nAccording to my caluculation, US imports from China in 2018 (CIF base) are 110.4 billion dollars for “300b_a”, and 160.6 billion dollars for “300b_c”. Combined 271.0 billion dollars is 0.90 ratio to claimed 300 billion dollars.\nI was surprised to see the Chinese shares in “300b_c”, which includes smart phones and notebook PCs, are higher than 75 percent, and much much higer than other tariff schedules. However, I should not have been surprised, because USTR states they separate “300b_a” and “300b_c” by 75 percent share criteria in this page.\nSo far, USTR granted product exclusion worth of 16.8 billion dollars. Excluded products tend to have higher Chinese shares, say around 20 percent, but much less than 75 percent. USTR will receive massive product exclusion requests, if 15 percent tariffs are imposed on “300b_c” on December 15, 2019."
  },
  {
    "objectID": "posts/2020-04-15-imf-world-economic-outlook-database-april-2020/index.html",
    "href": "posts/2020-04-15-imf-world-economic-outlook-database-april-2020/index.html",
    "title": "IMF World Economic Outlook Database, April 2020",
    "section": "",
    "text": "I updated my shiny app, based on the newly released IMF World Economic Outlook Database. I first thought there must be some coding errors, as the forecast extended only to 2021, not 2024 of the previous version. However, it turned out IMF decided to forecast just up to 2021, due to the high level of uncertainty. “Concepts” you can choose are also limited.\nI hope this uncertainty surrounding our lives will subside soon."
  },
  {
    "objectID": "posts/2020-05-11-herfindahl-hirschman-index-of-world-export-by-product/index.html",
    "href": "posts/2020-05-11-herfindahl-hirschman-index-of-world-export-by-product/index.html",
    "title": "Herfindahl-Hirschman Index of world export by product",
    "section": "",
    "text": "I calculated Herfindahl-Hirschman Index of world export by product by using WTO Data. According to this page, HHI is a commonly accepted measure of concentration. I calculated the shares of each exporting economy, square them, and sum up for each product. If one economy dominates 100 percent of the world export, then HHI is 10000, which is maximum.\nI have found China’s rise in manufactured goods exports contributed to de-concentration up to 2005, and contributed to concentration thereafter. China’s rise is partially driven by international division of labor by process. Smart phones and note PCs are mostly assembled in China, and exported from China, but their main components come from South Korea, Taiwan, Japan and others."
  },
  {
    "objectID": "posts/2020-05-26-covid-19-in-the-united-states/index.html",
    "href": "posts/2020-05-26-covid-19-in-the-united-states/index.html",
    "title": "Covid-19 in the United States",
    "section": "",
    "text": "I added “In the United States” page to my shiny app on Covid-19, using USAFacts data. I also added “USA, Covid-19 situation by state” to Covid repository in GitHub.\nThe epicenter of Covid-19 has moved from China to Europe, and now to Americas. I am worrying that too vigorous “reopen economy” movements in the United States may trigger the second big wave of infections in autumn."
  },
  {
    "objectID": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html",
    "href": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html",
    "title": "I built a PC, installed Pop!_OS, and am running RStudio",
    "section": "",
    "text": "I have been using my company PC, a Panasonic note PC (Intel Core i5-7200U), to build and maintain this site. When I retire early next year, I have to return it to the company. I have to prepare a new one."
  },
  {
    "objectID": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#why-need-a-new-pc",
    "href": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#why-need-a-new-pc",
    "title": "I built a PC, installed Pop!_OS, and am running RStudio",
    "section": "",
    "text": "I have been using my company PC, a Panasonic note PC (Intel Core i5-7200U), to build and maintain this site. When I retire early next year, I have to return it to the company. I have to prepare a new one."
  },
  {
    "objectID": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#why-not-buy",
    "href": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#why-not-buy",
    "title": "I built a PC, installed Pop!_OS, and am running RStudio",
    "section": "Why not buy?",
    "text": "Why not buy?\nAt home, I am a long time Apple user (Mac SE, PowerBook 145B, iMac DV, iBook G4, iPad, iPad Retina, iPad Pro 12.9 inch). The natural choice is a Mac. However, no Mac is equipped with Nvidia GPU. I am planning to play with tensorflow for deep learning, and tensorflow practically requires Nvidia GPU. Mac is out.\nI usually copy the codes in the book, run them and experiment to learn coding. I have found most books on data science assume the readers use Unix-like OS. When I use a Windows PC, I have to change some parts in the codes, and it is annoying. Shift-JIS character code of Japanese version of Windows is also annoying. Windows is out.\nI considered to buy a used note PC with Nvidia GPU, and then to replace OS from Windows to Linux. I looked around used note PCs, but failed to find a resonably priced one. Used PCs tend to have less performance per cost than new PCs in Japan. Used PC is out.\nShould I buy a new note PC with Nvidia GPU, like DELL XPS 15, and replace OS? I am afraid I will fail to install Linux on a new PC, as it usually takes some time for Linux to support new chips. New PC is out.\nEventually I decided to build a PC from parts which Linux is likely to have supported."
  },
  {
    "objectID": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#build-a-pc",
    "href": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#build-a-pc",
    "title": "I built a PC, installed Pop!_OS, and am running RStudio",
    "section": "Build a PC",
    "text": "Build a PC\nIf I can transfer the work of maintaining this site from my company PC to my new home PC, it is a success. How probable is it? Will I successfully build a functional PC: prior probability 0.9. Will I successfully install a functional OS: probability 0.8. Will I run RStudio smoothly: probability 0.7. In total, as 0.9 x 0.8 x 0.7 equals 0.5, this project is a half/half bet. I can’t bet much money on this risky project. So I decided to go for a budget PC. But how much budget?\nThe Japanese government happens to be distributing one hundred thousand JPY to every resident. I just yesterday received an application form by mail. One hundred thousand JPY is 843 USD, if I exclude 10 percent consumption tax and exchange at 107.80 JPY/USD.\nThe parts I chose are below. I purchased all at Amazon. As I use my 49 inch Sony 4K TV, a monitor is not included. The total amounf of 829 USD is under the budget of 843 USD.\n\n\nTable 1: Parts I purchased\n\n\n#\nParts\nVendor\nPrice (USD)\n\n\n\n\n1\nCPU: Ryzen 5 1600 AF\nAMD\n94\n\n\n2\nMother board: B450M Pro\nAsrock\n69\n\n\n3\nDRAM: 16GBx2\nSkhynix\n135\n\n\n4\nSSD: 500GB, M.2 NVMe\nMicron\n77\n\n\n5\nGraphic card: GeForce RTX 2060\nKuroutoshikou\n307\n\n\n6\nCase: Q300L\nCooler Master\n46\n\n\n7\nFuns: 120mmx3\nNovonest\n9\n\n\n8\nPSU: 80Plus Bronze, 550W\nKuroutoshikou\n51\n\n\n9\nWireless keyboard and mouse\nElecom\n25\n\n\n10\nHDMI cable\nAmazon\n9\n\n\n11\nUSB memory\nToshiba\n4\n\n\n12\nBall grip driver\nVessel\n3\n\n\n-\nTotal\n-\n829\n\n\n\n\nPaul’s Hardware says Ryzen 5 1600 AF is a buy, if sold under 100 USD. Hardware Unboxed selects Asrock B450M Pro as the best B450 Micro ATX mother board. I followed their recommendations.\nThe hardest work in building a PC was to connect cables between the mother board and the PC case. I had to remove the graphic card to do so. That was the most dangerous moment. I nearly broke the mother board and/or the graphic card, as I didn’t know there is a lock mechanism in PCIe x16 slot. I should have connected cables, before I insert the graphic card into PCIe x16 slot, in the first place. Somehow I found how to unlock PCIe x16 slot, and could safely remove the graphic card. It took six hours for me to build a PC. When I restart and hit F2 button timely, I could enter UEFI settings. So far, so good."
  },
  {
    "objectID": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#install-pop_os",
    "href": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#install-pop_os",
    "title": "I built a PC, installed Pop!_OS, and am running RStudio",
    "section": "Install Pop!_OS",
    "text": "Install Pop!_OS\nUbuntu 20.04 LTS is just released, and Ubuntu-based System 76 Pop!_OS 20.04 is now available. Which distro should I choose? Jay in LearnLinux.tv is a fan of Pop!_OS, reviews Pop!_OS 20.04 positively, but has not yet confirmed its stability. In the pre-reseach, I have found Pop!_OS 20.04 has more polished user interface, and is easier to install Nvidia driver. So I chose Pop!_OS 20.04.\n\nMake a bootable USB memory\nAs connection to USB memory is disabled in my company PC for security reason, the only machine I can use is my old iBook G4, of which browser is TenFourFox. I downloaded an ISO file, Nvidia version, from System 76. Then, I followed the instructions in a seemingly promising page of how-to (Japanese).\n\nInsert the USB memory to iBook G4\nIn the Terminal, type $ diskutil list, and confirm the USB memory is recognized as /dev/disk1\n$ diskutil unmountDisk /dev/disk1\n$ cd ~/Downloads\n$ sudo dd if=pop-os_20.04_amd64_nvidia_6.iso of=/dev/disk1 bs=1m\nWhen the writing is finished, pull out the USB memory\n\n\n\nBoot from a USB memory\nI inserted the USB memory to my new PC, restart, hit F2 button, and entered UEFI settings. In the Boot section, I selected the USB memory as Boot option priority. In the Exit section, I saved changes and exit. Reboot, and voila! Pop!_OS started.\n\n\nInstall Pop!_OS\nIt was pretty easy to install. I just followed the installer. Although I selected “Japanese” in keyboard layout, I selected “English” in language, as searching in English hits more helpful pages than in Japanese. Pop!_OS 20.04 is working. So far, so good."
  },
  {
    "objectID": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#install-git-and-set-up-ssh-connection-with-github",
    "href": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#install-git-and-set-up-ssh-connection-with-github",
    "title": "I built a PC, installed Pop!_OS, and am running RStudio",
    "section": "Install Git, and set up SSH connection with GitHub",
    "text": "Install Git, and set up SSH connection with GitHub\nLooking at Linux Terminal Basics, I typed in the Terminal.\n$ sudo apt update\n$ sudo apt full-upgrade\nTaking some advice in this page (Japanese), I installed git and curl.\n$ sudo apt install git curl\nAnd I generated a new SSH key, and added it to the ssh-agent and to my GitHub account, basically following the instructions in the GitHub help page."
  },
  {
    "objectID": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#install-r-and-rstudio",
    "href": "posts/2020-05-30-i-built-a-pc-installed-pop-os-and-am-running-rstudio/index.html#install-r-and-rstudio",
    "title": "I built a PC, installed Pop!_OS, and am running RStudio",
    "section": "Install R and RStudio",
    "text": "Install R and RStudio\nAs I found “How to install RStudio on Ubuntu 20.04 Focal Fossa Linux” in linuxconfig.org, I followed the instructions.\nBut I failed to install “tidyverse”. I apt install nearly all modules in this shell script. Then I could install “tidyverse”.\nRStudio Version 1.3.959 sometimes hangs in my environment. Nothing appears in the panels, and the menu does not respond. “How to force quit an hanging application in Pop OS” helped me. I pushed alt+f2, and xkill.\nThis is a known issue, and 1.3-patch will come, according to this page. I added the line below to .bashrc as a workaround. Now I type rstudio in the Terminal to start RStudio.\nexport RSTUDIO_CHROMIUM_ARGUMENTS=\"--disable-seccomp-filter-sandbox\"\nStill, “Failed to load module appmenu-gtk-module” message appeared in the Terminal. So I apt install modules below, following this page.\n$ sudo apt install appmenu-gtk2-module appmenu-gtk3-module\nThere always is a small issue. After I installed maps library, I was asked to install mapproj library.\nAs a whole, it looks OK now.\nYesterday and today, I successfully updated my covid repository and my related shiny app from my new PC. And this is the first post from my new PC. So far, so good.\nI hope this machine will serve me long and well.\nPS I replaced Ryzen 5 1600 AF with Ryzen 5 5600 in May 2022."
  },
  {
    "objectID": "posts/2020-07-26-update-let-president-reagan-speak/index.html",
    "href": "posts/2020-07-26-update-let-president-reagan-speak/index.html",
    "title": "Update: let President Reagan speak",
    "section": "",
    "text": "In June 2020, OpenAI released GPT-3, a new text generator. Its reputation is very high. However, I can’t try it, because its size with 175 billion parameters is huge, and I can’t access OpenAI API.\nSo I looked around for information about an old one, GPT-2. I found gpt-2-simple module by Max Woolf, and decided to try it."
  },
  {
    "objectID": "posts/2020-07-26-update-let-president-reagan-speak/index.html#openais-gpt-2-model",
    "href": "posts/2020-07-26-update-let-president-reagan-speak/index.html#openais-gpt-2-model",
    "title": "Update: let President Reagan speak",
    "section": "",
    "text": "In June 2020, OpenAI released GPT-3, a new text generator. Its reputation is very high. However, I can’t try it, because its size with 175 billion parameters is huge, and I can’t access OpenAI API.\nSo I looked around for information about an old one, GPT-2. I found gpt-2-simple module by Max Woolf, and decided to try it."
  },
  {
    "objectID": "posts/2020-07-26-update-let-president-reagan-speak/index.html#i-use-reports-from-1982-to-1989-by-president-reagan",
    "href": "posts/2020-07-26-update-let-president-reagan-speak/index.html#i-use-reports-from-1982-to-1989-by-president-reagan",
    "title": "Update: let President Reagan speak",
    "section": "I use reports from 1982 to 1989 by President Reagan",
    "text": "I use reports from 1982 to 1989 by President Reagan\nI combined reports from 1982 to 1989 into reagan.txt."
  },
  {
    "objectID": "posts/2020-07-26-update-let-president-reagan-speak/index.html#i-tried-docker-but-failed-due-to-resourceexhaustederror",
    "href": "posts/2020-07-26-update-let-president-reagan-speak/index.html#i-tried-docker-but-failed-due-to-resourceexhaustederror",
    "title": "Update: let President Reagan speak",
    "section": "I tried docker, but failed due to ResourceExhaustedError",
    "text": "I tried docker, but failed due to ResourceExhaustedError\nAs gpt-2-simple module requires tensorflow 1.14 or 15, I create docker like below.\ndocker run -u $(id -u):$(id -g) \\\n  --gpus all -it -p 8888:8888 -v `pwd`:/tf/notebooks \\\n  tensorflow/tensorflow:1.15.2-gpu-py3-jupyter\nI tried the smallest model, “124M”, in gpt-2-try-and-error.ipynb, but failed due to ResourceExhaustedError. Probably my machine’s GPU VRAM 6GB is not enough."
  },
  {
    "objectID": "posts/2020-07-26-update-let-president-reagan-speak/index.html#i-tried-google-colab-and-got-an-annoying-result",
    "href": "posts/2020-07-26-update-let-president-reagan-speak/index.html#i-tried-google-colab-and-got-an-annoying-result",
    "title": "Update: let President Reagan speak",
    "section": "I tried Google Colab, and got an annoying result",
    "text": "I tried Google Colab, and got an annoying result\nIn the previous post, my trial in Google Colab failed due to time out. In the retrospect, I may have forgotten to enable GPU by Edit &gt; Notebook settings. This time I enabled GPU. It took about one and half hour to finetune the model. The result is gpt_2_colab.ipynb.\nI seeded the text, “I have some proposals to the Congress.” The finetuned model continued:\n“One way or the other, we will pursue the issues that matter most to us—jobs, growth, and economic opportunity—that will lead to sustained economic growth and to free trade and international economic cooperation.”\nAfter that, it copied the lines from #240 to #284 of the input texts, reagan.txt, I used for finetuning. Is it overfitting? I don’t know."
  },
  {
    "objectID": "posts/2020-08-18-update-i-ve-found-a-csv-file-in-who-dashboard/index.html",
    "href": "posts/2020-08-18-update-i-ve-found-a-csv-file-in-who-dashboard/index.html",
    "title": "Update: I have found a csv file in WHO Dashboard",
    "section": "",
    "text": "This morning, as I do every morning, I opened WHO stuation report page, and found no new daily report. It looks like WHO have changed its situation report publish frequency from daily to weekly. Do I have to change my update frequency of README.md, and shiny app also to weekly?\nFortunately, by following the link to WHO COVID-19 Dashboard on the same page, I could find a csv file of daily data, which I have long hoped for. I can download it from Data Table tab. Its URL is https://covid19.who.int/WHO-COVID-19-global-data.csv.\nI don’t know when it became available. Anyway, the days of scratching numbers from pdf files are over. Thank you, WHO."
  },
  {
    "objectID": "posts/2020-08-27-update-add-japan-prefecture-map-to-jp-household/index.html",
    "href": "posts/2020-08-27-update-add-japan-prefecture-map-to-jp-household/index.html",
    "title": "Update: add Japan prefecture map to jp-household",
    "section": "",
    "text": "I have added Japan prefecture map to “jp-household” and my Shiny app “City competition to consume”. To make the capital city represent each prefecture, I drop 5 non-capital cities.\nI use shape data from NipponMap package, and refer to “13.19 Creating a Map from a Shapefile” in “R Graphics Cookbook, 2nd edition” by Winston Chang.\nThis kind of visualization helps us understand which region tends to consume more or less of certain items. For example, go to my Shiny app, select item level 5, and select item 282 納豆　(fermented soybeans). You can see the western region consumes less, and the eastern region consumes more in 2019. Select different year between 2007 and 2019, you will see this pattern is pretty consistent.\nI am now wondering if and how I can quantify this consistency by each item."
  },
  {
    "objectID": "posts/2020-10-14-update-imf-world-economic-outlook-database-october-2020/index.html",
    "href": "posts/2020-10-14-update-imf-world-economic-outlook-database-october-2020/index.html",
    "title": "Update: IMF World Economic Outlook Database, October 2020",
    "section": "",
    "text": "I updated my shiny app.\nForecast period has extended from 2021 in April version to 2025. And “Concepts” are not limited.\nIMF changed the format of the download page. The link to SDMX Data is not .zip file, but .ashx file. As I don’t know how to handle .ashx file in R script, I have decided to download files in a browser.\nIMF also changed the formats in search pages, like “By Countries”. I prefer the former format, but will try to be accustomed to the new format."
  },
  {
    "objectID": "posts/2021-02-05-hamamatsu-city-came-back/index.html",
    "href": "posts/2021-02-05-hamamatsu-city-came-back/index.html",
    "title": "Hamamatsu-city came back",
    "section": "",
    "text": "I have just done an annual update of “City competition to consume in Japan”. This is the second annual update. The latest year is now 2020.\nHamamatsu-city lost the top position both in consuming dumplings and grilled eel in 2019. It came back to the top in both in 2020. Congratulations, Hamamatsu-city!\nIf you can read Japanese, try my shiny app. For example, select item level 5, select “282 納豆”, and you can see how divided Japan is."
  },
  {
    "objectID": "posts/2021-03-05-update-2021-economic-report-of-the-president/index.html",
    "href": "posts/2021-03-05-update-2021-economic-report-of-the-president/index.html",
    "title": "Update: 2021 Economic Report of the President",
    "section": "",
    "text": "I have updated “Tf-idf analysis” and “Sentiment analysis” of the Economic Report of the President, by adding the 2021 report.\nTf-idf analysis shows that the economic aspects in the last 4 years, from 2017 to 2020 under Trump Presidency, can be characterized by “cyber”, “ai”, “opioids” and “covid”.\nSentiment analysis shows that sentiment is worsening under the recession which began in February 2020."
  },
  {
    "objectID": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html",
    "href": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html",
    "title": "Don’t be afraid of negative real interest rates by inflation",
    "section": "",
    "text": "I read some parts of the book “Look deep into the fiscal crisis” (Japanese) more closely, and I’ve got what separates the author, Prof. Kazumasa Oguro, and me. That is whether negative real interest rates by inflation is intolerable or not.\nI would like to show his position and mine in the context of the model I created in the last two posts (here and here)."
  },
  {
    "objectID": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#model-assumptions",
    "href": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#model-assumptions",
    "title": "Don’t be afraid of negative real interest rates by inflation",
    "section": "Model assumptions",
    "text": "Model assumptions\nI repeat the assumptions of the model below.\n\nOur economy is a one factor (labor), three sector (Generation n (retired) and n+1 (working), Government) in Period n (30 years), and closed economy. There is no capital, no business sector, no international trade, and no foreigner. Ignore financial sector as an intermediary.\nAll goods and services produced in a Period are perishable, and must be consumed in that Period, like foodstuff and entertainment, care and medicine services. There is no stock, and no investment.\nThe only method for Generation n+1 (working) to save is to buy bonds.\nThe roles of Government are:\n\n\nto issue and pay back bonds, of which duration is one Period, 30 years,\nto supply national defense service against the natural disasters, such as flood, earthquake and pandemic, (as I assume no foreigner, there is no war against humans) and\nto collect tax."
  },
  {
    "objectID": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#what-i-have-learned-from-model-simulations-in-the-last-two-posts-here-and-here.",
    "href": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#what-i-have-learned-from-model-simulations-in-the-last-two-posts-here-and-here.",
    "title": "Don’t be afraid of negative real interest rates by inflation",
    "section": "What I have learned from model simulations in the last two posts (here and here).",
    "text": "What I have learned from model simulations in the last two posts (here and here).\nNote that the values in the model are not nominal, but real, and denominated in Period 1 price level yen.\n\nWhen retired and working Generations agree how to share the produced other than defense spending (Government consumption), interest income of retired Generation and thus interest rates of holding bonds are determined endogenously in the model. Reversely, interest rates determine how to share buying power between retired and working Generations.\nPositive interest rates in the model can come not just from holding bonds but from tax and transfer, like an expansion of pay-go based pension system and an end of war-time tax. GDP growth through working population increase and productivity growth can contribute to positive interest rates.\nNegative interest rates can come not just from holding bonds but from tax and transfer, like a shrinkage of pay-go based pension system and an introduction of war-time tax. GDP decline through working population decrease and productivity stagnation can contribute to negative interest rates. Debt default and hyperinflation can also contribute to negative interest rates.\n\nOK, I am ready to present his position and mine in the context of my model below. If I misrepresent his position, it is my fault."
  },
  {
    "objectID": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#prof.-kazumasa-oguros-position",
    "href": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#prof.-kazumasa-oguros-position",
    "title": "Don’t be afraid of negative real interest rates by inflation",
    "section": "Prof. Kazumasa Oguro’s position",
    "text": "Prof. Kazumasa Oguro’s position\n\nNegative interest rates mean that Government fails to pay back fully what it received 30 years ago in real terms, i.e. buying power terms. We should call this situation fiscal collapse. Debt default, hyperinflation and any other type of negative interest rates is intolerable.\nThe U.K. employed “financial repression” to make interest rates artificially low by regulation and to make them less than inflation after the World War II (Government debt to GDP ratio in the U.K. in my past post). This should be regarded as fiscal collapse.\nAs GDP other than defense spending, i.e. the pie to share, is likely to shrink in the next Period 5 (2030-60, according to my previous post), Generation 5, who is working in the current Period 4 (2000-30) and will be retired in the next Period 5, must save less to avoid negative interest rates in next Period 5. It is equivalent to say that Generation 4, who is retired now, must consume less in the current Period 4 and/or Government have less deficits. So, tax Generation 4 and reduce Government deficits, now.\nThe Abe administration’s decision to postpone the consumption tax increase scheduled in October, 2015 was a big mistake. It made fiscal collapse more likely.\nThe reasons why Government does not accept my proposal to tax Generation 4 now are:\nGovernment is too optimistic about GDP in the next Period 5 (2030-60). So we need independent fiscal institutions to present unbiased long term economic forecasts.\nGeneration 4 outnumbers Generation 5, and exerts political power to avoid tax increases. So “Silver Democracy” is an obstacle."
  },
  {
    "objectID": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#my-position",
    "href": "posts/2021-05-19-don-t-be-afraid-of-negative-real-interest-rates-by-inflation/index.html#my-position",
    "title": "Don’t be afraid of negative real interest rates by inflation",
    "section": "My position",
    "text": "My position\n\nWhile debt default and hyperinflation is intolerable, negative real interest rates by inflation is tolerable, when we consider the costs. As positive real interest rates are the norm under increasing GDP, negative real interest rates are the norm under decreasing GDP.\nAs for the U.K. experience after the World War II, I regard it as a success.\nWe should think inter Generation equity from the viewpoint of not avoiding any type of negative real interest rates, but fair share in each Period and fair distribution of income in life by Generation.\nThere are lucky and unlucky Generations, as population bonus and onus, productivity growth and stagnation, and war against Godzilla brings about both windfall and undue pains. So what I mean by “fair” is not quantitatively definitive in advance but politically decided afterwards.\nAlthough I agree that GDP is likely to shrink in the next Period 5 (2030-60), it is far from certain. Even if independent fiscal institutions can present unbiased long term economic forecasts, forecasts are always with a lot of uncertainties, especially when the time span is 30 years. The reason why Government does not accept his proposal to tax Generation 4 now is probably not because of Generation 4’s greed and “Silver Democracy” but because of this uncertainty.\nA rigid rule to make “expected” buying power equal among Generations can result in a very unequal “actual” buying power distribution, and can be a burdensome legacy for future Generations.\nThe Abe administration’s decision to raise the consumption tax rate from 5 to 8 percent in April, 2014 was a big mistake. We should avoid austerity, when the resources are not fully utilized. This is a business cycle stabilization issue whose time span is less than 5 years. Due to this mistake, inflation momentum from high pressure economy was lost, and the Bank of Japan still fails to achieve its inflation target of 2 percent, which is foremost important to get negative real interest rates in an orderly manner.\nEmbrace negative real interest rates by inflation. To get that, create high pressure economy through expansionary fiscal and monetary policies, so that the Bank of Japan can achieve its inflation target.\n\nFULL DISCLOSURE: I retired at the end of February this year."
  },
  {
    "objectID": "posts/2021-07-17-do-some-municipalities-have-superfluous-stocks-of-pfizer-vaccines/index.html",
    "href": "posts/2021-07-17-do-some-municipalities-have-superfluous-stocks-of-pfizer-vaccines/index.html",
    "title": "Do some municipalities have superfluous stocks of Pfizer vaccines?",
    "section": "",
    "text": "Reference materials in this post are all in Japanese:\n\nFNN Prime Online: Missing 40M shots vaccines\nCNET Japan: Gov’t provides an IT system to support 1.2M shots per day\nMinistry of Health, Labour and Welfare: Prospects for Pfizer vaccine supplies\nPfizer: Handling manual of Pfizer vaccine\n\nThe central government says that it distributed 88 million shots vaccines to municipalities by the end of June, the reported shots are 48M shots, so there are 40M shots stocks, and some municipalities must have superfluous stocks.\nMunicipalities say they don’t have any superfluous stocks, and some of them stopped taking reservations for shots.\nFNN reports that 40M shots stocks are 25M reserved for the second boost shots, 5M not-yet-reported shots, and 10M missing for unknown reasons.\nAccording to “Prospects for Pfizer vaccine supplies” by Ministry of Health, Labour and Welfare, MHLW planned to distribute 68,341 boxes to municipalities. One box contains 195 vials. One vials contain 5 or 6 shots, according to the injector type.\n68,341 boxes can be 67M - 80M shots, but can’t reach 88M shots. At least 8M shots were not delivered to municipalities, if “Prospects for Pfizer vaccine supplies” by MHLW is correct.\nMHLW distributes 21,600 boxes in July, and the officer of the Cabinet Office says the government distributes 25M shots in July. 21,600 boxes can be 21M - 25M shots. Looks like the officer assumes 6 shots per vial. Is this assumption practical?\nAccording to Pfizer manual, after the vial is diluted, it must be shot in 6 hours. At the end of the day, each center or clinic will try to exhaust the last diluted vial, but it will fail to do so at some probability.\nImagine that the expected shot loss from the last diluted vial is 0.2 shots (four cases of 1 shot unused, three cases of 2 shots unused, two case of 3 shots unused and one case of 4 shots unused out of 100 last diluted vials).\nAnd imagine the only one center tries to do 1.2M shots per day (37M shots per month) in July. Then the number of the last diluted vial is one per day, and the expected shot loss is 0.2 shots per day (6.2 shots per month).\nInstead, imagine 55 thousand clinics are scheduled to do 1.2M shots per day (37M shots per month) in July, as the officer says. Then the number of the last diluted vial is 55K per day, and the expected shot loss is 55K * 0.2 = 11K shots per day (341K shots per month).\nThus, some of missing vaccines may be due to shot losses at the last diluted vial.\nMore centralized regime leads to less shot losses. The decentralized regime may have facilitated 65 years or older people to get shots at nearby clinics. However, the centralized regime may be more desirable now, as younger generations get shots.\nI am scheduled to get the first shot of Pfizer vaccine at the municipal center on August 2."
  },
  {
    "objectID": "posts/2021-07-26-nhk-is-trapped-in-bothsideism-on-us-politics/index.html",
    "href": "posts/2021-07-26-nhk-is-trapped-in-bothsideism-on-us-politics/index.html",
    "title": "NHK is trapped in bothsideism on US politics",
    "section": "",
    "text": "Although I think most of NHK news are reliable, I sometimes find some odd news. Such recent odd news on US economy and politics are:\n\n“Hiring is hard in the US, as unemployment benefit in American Rescue Plan is too generous” in “Catch! World Top News” on June 24, 2021 (Japanese)\n“Half a year after Biden inauguration” in “News Watch 9” on July 20, 2021 (Japanese)\n“Republicans, who consider fiscal discipline is important, oppose to raising debt ceiling” in NHK news at 2pm on July 26, 2021\n\nThe first news is odd, as CNBC had reported “Cutting off unemployment benefits early is not pushing people to find work, data suggests” on June 23. CNBC recently added “States cutting unemployment benefits didn’t get people back to work, study finds” on July 22.\nThe second news showed Trump claiming election fraud at Fulton county in Georgia at his rally, and then it reported that 17 Republican-led state legislatures changed voting entitlement more strict, claiming their purpose was to prevent such election frauds. The program continued to show protests by minorities and Democrats against voter suppression. But it failed to report Trump’s election fraud claim is unsubstantiated.\nThe third news sounds like a joke, as Republicans didn’t care of deficits, when they passed Tax Cuts and Jobs Act of 2017 using reconciliation procedures. And “Federal Surplus or Deficit [-] as Percent of Gross Domestic Product” clearly shows the Republicans since Reagan tend to increase deficits.\nI guess NHK is trapped in bothsideism. NHK says that it shall try to be fair and balanced on political issues, and to report opinions from both sides on its FAQ page (Japanese). So NHK reports what Republicans say as a fact, even if it is an ideology, a pretense, or a white lie. NHK should not report facts from both sides, as there is no alternative fact."
  },
  {
    "objectID": "posts/2021-08-31-nobel-laureate-dr-omura-is-misinformed/index.html",
    "href": "posts/2021-08-31-nobel-laureate-dr-omura-is-misinformed/index.html",
    "title": "Nobel laureate Dr Omura is misinformed",
    "section": "",
    "text": "I read an interview (Japanese) with Dr Satoshi Omura, who helped development of ivermectin and was awarded the Nobel Prize in Physiology or Medicine in 2015, in the weekly magazine, Sunday Mainichi, published on July 25 and August 1, 2021, and found a few points where his recognition is or may be wrong.\n\nHe wrongly recognizes Michael Capuzzo is a New York Times star reporter. He is not. He is a New York Times best-selling author.\nHe wrongly recognizes the Indian Bar Association, which served a legal notice to Chief Scientist at WHO, is comparable with Japan Federation of Bar Associations (Japanese). Bar Council of India and the Bar Association of India, both located in New Dehli, are, but the Indian Bar Association is not. It is a private bar association located in Mumbai.\nHe recognizes Michael Capuzzo writes “As WHO receives donations from big pharmaceutical companies, it should be regarded not as a public but as a private organization.” I could not find this sentence in this article of his, though I could find the phrase “the FDA (the budget of which, as it happens, is 75 percent funded by big pharmaceutical companies).” Michael Capuzzo may have written this sentence in his other writings. If so, is he right? According to the article by World Economic Forum, the share of the private sector entities in WHO funding in 2018 is 2 percent. It is difficult to regard WHO as a private organization.\n\nDespite above, Dr Omura has not lost his mind as a scientist. He states, “I am not demanding ivermectin be hastily approved for Covid-19 treatment in Japan. I will wait for the outcome of the clinical test I helped to start. The truth shall prevail.”"
  },
  {
    "objectID": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html",
    "href": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html",
    "title": "Another kind of immaculate inflation doctrine",
    "section": "",
    "text": "Prof Masaya Sakuragawa at Keio university published an anticle titled “The Bank of Japan should abandon zero interest policy, and normalize monetary policy” (Japanese) in “Lecture on Economics” in Nikkei news paper on September 9, 2021.\nHis two main proposals are:\n\nThe Bank of Japan should declare it will aim to raise interest rates to 1 percent, and promise it will never go back to zero interest rates except for emergencies.\nThe Japan Government should make efforts to sell yen-denominated Japanese Government Bonds to foreign central banks by internationalizing the yen.\n\nAnd he writes, “Once we reduce real interest rates to negative 1 percent, we can reach 2 percent inflation target.”\nMy intuition tells me his proposals are impractical, and even if they are practical, he is wrong.\nAs for practicality, interest rates that affect the economy are not overnight rates, but the long term rates, like 10 year government bond yields. The market will not believe the Bank of Japan will never go back to zero interest rates, so the long-term rates will not rise to 1 percent.\nNow forget about practicality, and suppose the long-term rates will indeed rise to 1 percent. Then how is he wrong? It took me two days and brief reading of his books to find out his way of thinking and how he is wrong.\nHis thinking is based on the bubble theory by a French economist Jean Tirole, according to his book published in 2009 (Japanese). He writes, “A bubble exists when there is a difference between a market price and a fundamental value of the asset”, “Paper money is a bubble because it is evaluated in the market more than its fundamental value as of paper” and “Government bond is not a bubble as long as it will not roll over”. I am confused about the definition of “bubble.” So I would like to use my words, not his words, and avoid the word “bubble.”"
  },
  {
    "objectID": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#prof-sakuragawas-policy-proposals",
    "href": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#prof-sakuragawas-policy-proposals",
    "title": "Another kind of immaculate inflation doctrine",
    "section": "",
    "text": "Prof Masaya Sakuragawa at Keio university published an anticle titled “The Bank of Japan should abandon zero interest policy, and normalize monetary policy” (Japanese) in “Lecture on Economics” in Nikkei news paper on September 9, 2021.\nHis two main proposals are:\n\nThe Bank of Japan should declare it will aim to raise interest rates to 1 percent, and promise it will never go back to zero interest rates except for emergencies.\nThe Japan Government should make efforts to sell yen-denominated Japanese Government Bonds to foreign central banks by internationalizing the yen.\n\nAnd he writes, “Once we reduce real interest rates to negative 1 percent, we can reach 2 percent inflation target.”\nMy intuition tells me his proposals are impractical, and even if they are practical, he is wrong.\nAs for practicality, interest rates that affect the economy are not overnight rates, but the long term rates, like 10 year government bond yields. The market will not believe the Bank of Japan will never go back to zero interest rates, so the long-term rates will not rise to 1 percent.\nNow forget about practicality, and suppose the long-term rates will indeed rise to 1 percent. Then how is he wrong? It took me two days and brief reading of his books to find out his way of thinking and how he is wrong.\nHis thinking is based on the bubble theory by a French economist Jean Tirole, according to his book published in 2009 (Japanese). He writes, “A bubble exists when there is a difference between a market price and a fundamental value of the asset”, “Paper money is a bubble because it is evaluated in the market more than its fundamental value as of paper” and “Government bond is not a bubble as long as it will not roll over”. I am confused about the definition of “bubble.” So I would like to use my words, not his words, and avoid the word “bubble.”"
  },
  {
    "objectID": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#loanable-funds-market-alone-does-not-determine-the-real-interest-rate",
    "href": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#loanable-funds-market-alone-does-not-determine-the-real-interest-rate",
    "title": "Another kind of immaculate inflation doctrine",
    "section": "Loanable funds market alone does not determine the real interest rate",
    "text": "Loanable funds market alone does not determine the real interest rate\nLoanable funds market diagram’s x-axis is loan amounts and y-axis is real interest rates. Supply curve is upward slope to the right, and demand curve is downward slope as usual. The cross point, an equilibrium, determines the loan amount and the real interest rate.\nIn my understanding, he thinks his two proposals will shift supply curve to the right. His proposal #1 will induce savers to move their paper money holdings, which earn zero interests, to bank deposits, which earn some positive interests. His proposal #2 will allow banks to move their government bond holdings to loans. The supply curve will shift to the right, and the equilibrium will move to more loan amount and reduced real interest rate. He thinks that’s it.\nAlthough I doubt his proposals’ effects on the supply curve, it is not the main problem. The main problem is that he thinks the real interest rate is determined in the loanable funds market alone.\nNo, it is not yet determined. Loanable funds market is not the end of the story, but only the start. One diagram of lonable funds market is drawn for a given real GDP level. When we draw diagrams for possible real GDP levels, we get many equilibrium sets of real interest rates and real GDP levels. When we draw IS-LM (investment-saving and liquidity demand-money supply) diagram, of which x-axis is real GDP level and y-axis is real interest rates, it becomes IS curve, which is downward slope. The real interest rate and real GDP level is determined at the cross point of IS curve and LM curve. If you are confused, refer to Paul Krugman’s article in May 2009.\nFor simplicity, I would like to use monetary policy based on Taylor rule to explain LM curve. Suppose inflation expectation is anchored at zero percent. The lower bound of nominal interest rates is now 1 percent, not zero, due to his proposal #1. Then the lower bound of real interest rates is 1 percent. Even if IS curve shifts a bit to the right thanks to his proposals, considering this upward shift of LM curve thanks to his proposal #1, and the position of the starting cross point which is far left of the kink of LM curve, the cross point will stay on the lower bound of LM curve. As a result, real interest rate will not decrease to negative 1 percent as he asserts, instead will increase to 1 percent."
  },
  {
    "objectID": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#inflation-comes-not-from-fischer-equation-but-from-high-pressure-economy",
    "href": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#inflation-comes-not-from-fischer-equation-but-from-high-pressure-economy",
    "title": "Another kind of immaculate inflation doctrine",
    "section": "Inflation comes not from Fischer equation, but from high pressure economy",
    "text": "Inflation comes not from Fischer equation, but from high pressure economy\nIn the above paragraph, I use Fischer equation to calculate real interest rates given nominal interest rates and inflation expectation. Prof Sakuragawa uses it to predict inflation from his (wrong) predictions of nominal and real interest rates.\nPredicting inflation without explaining what changes people’s behavior is called “immaculate inflation”. One example is predicting inflation when the central bank increases monetary base (quantitative easing) in the liquidity trap, just based on the quantity theory of money. Paul Krugman, who coined the phrase “immaculate inflation” by mimicking “immaculate transfer” coined by John Williamson, pointed out another example in his article in March 2018.\nWhen Prof Sakuragawa writes, “Once we reduce real interest rates to negative 1 percent, we can reach 2 percent inflation target”, it is another example of “immaculate inflation” by predicting inflation just based on Fishcer equation."
  },
  {
    "objectID": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#prof-sakuragawa-is-trying-to-create-custom-made-economics-for-japan",
    "href": "posts/2021-09-11-another-kind-of-immaculate-inflation-doctrine/index.html#prof-sakuragawa-is-trying-to-create-custom-made-economics-for-japan",
    "title": "Another kind of immaculate inflation doctrine",
    "section": "Prof Sakuragawa is trying to create custom-made economics for Japan",
    "text": "Prof Sakuragawa is trying to create custom-made economics for Japan\nProf Sakuragawa published a book titled “Japan can revive by internationalizing the yen” (Japanese) in 2011. In the afterword, he writes “Japan can never revive by believing and adopting economics imported from America. The idea of internationalizing the yen will never come from America. We have to create our own custom-made economics to revive Japan economy.”\nHe is trying to create custom-made economics for Japan economy. I admire him, as I am just a believer of economics imported from America. He may sometimes fall in some pit holes in the way. I hope he is courageous enough to admit his mistakes, and will go on.\nP.S. He won the Nikkei / Economic Book Culture Award (Japanese) for his new book, “Economic Theory of bubbles” (Japanese) on November 3, 2021."
  },
  {
    "objectID": "posts/2021-09-30-lost-in-translation/index.html",
    "href": "posts/2021-09-30-lost-in-translation/index.html",
    "title": "Lost in translation",
    "section": "",
    "text": "I watched NHK News 7 in the evening on September 30, 2021.\nNews host (in Japanese): Today, one month has passed since the U.S. withdrawal from Afghanistan. TV screen (in English, volume is so small, it is difficult to hear): President Biden says, “The United States ended 20 years of war in Afghanistan — the longest war in American history.” News host (in Japanese): President Biden said, “Withdrawal was the right, wise and best decision.” But General Milley, Joint Chiefs Chair, said in his testimony to the Congress, TV screen (in English): “The war was a strategic failure.” TV caption (in Japanese): “Was a strategic failure.” News host (in Japanese): And he showed his strong alarm on terrorist attacks.\nIf you watch in Japanese and don’t hear English, you get the impression that President Biden defended his decision one month later, and that General Milley said “President Biden’s decision was a strategic failure.”\nI searched President Biden’s sayings, and I found them in his speech on August 31, 2021. So he said them at the withdrawal, not one month later.\nGeneral Milley did not say “President Biden’s decision was a strategic failure.” He said, “The war was a strategic failure.” According to the New York Times:\n\nAsked whether Mr. Biden’s decision to withdraw caused what General Milley had described as a “strategic failure,” the general took a longer view.\n“This is a 20-year war,” General Milley said. “It wasn’t lost in the last 20 days or even 20 months for that matter. There is a cumulative effect from a series of decisions that go way back.”\n\nI understand NHK has to make news compact, and easier to swallow. But NHK has gone too far this time, believing viewers don’t hear English."
  },
  {
    "objectID": "posts/2021-10-13-update-imf-world-economic-outlook-database-october-2021/index.html",
    "href": "posts/2021-10-13-update-imf-world-economic-outlook-database-october-2021/index.html",
    "title": "Update: IMF World Economic Outlook Database, October 2021",
    "section": "",
    "text": "As IMF updated its World Economic Outlook Database on October 12, 2021, I updated my Shiny app accordingly. This is the sixth iteration since I created this Shiny app in April 2019."
  },
  {
    "objectID": "posts/2021-11-06-are-subsidies-for-domestic-semiconductor-fabs-effective-for-economic-security/index.html",
    "href": "posts/2021-11-06-are-subsidies-for-domestic-semiconductor-fabs-effective-for-economic-security/index.html",
    "title": "Are subsidies for domestic semiconductor fabs effective for economic security?",
    "section": "",
    "text": "NHK revealed the draft of the measures to expand domestic semiconductor production capacity by the Japanese Government (Japanese) on November 6, 2021.\nThis post is not a complaint to NHK, but a complaint to the Kishida Administration.\nI am basically skeptical about subsidizing domestic semiconductor productions.\n\nThe current semiconductor shortages are mainly driven by demands, as consumers buy more goods, which contain some semiconductors, and less services under the constraints of Covid-19. When our lives come back to some normality, consumers will buy more services and less goods. Semiconductor shortages may be short lived.\nFabs are designed for specific semiconductor products to gain the maximum economies of scale. So one finished electronic device must contain semiconductors from more than a dozen fabs. When any one fab among them is in trouble, other fabs can’t supplant immediately, so the supply chain will inevitably be constrained for a while. To help build one or two domestic fabs does not count much.\nSubsidies for domestic semiconductor production may violate WTO subsidy rules.\n\nHowever, what astonished me most was the proposed condition. In the draft NHK revealed, the Japanese Government shall give subsidies as much as half of the building costs to fab builders, on the condition that they respond to the Japanese Government’s request to increase productions under semiconductor shortages. If the condition is violated, the Japanese Government shall request pay-back of subsides.\nSemiconductor fabs are highly capital intensive, so are usually working at full capacity. More likely so, under semiconductor shortages. Can they increase production at the Government request? No, I don’t think so. I guess this draft is written by people who don’t understand the semiconductor business."
  },
  {
    "objectID": "posts/2021-11-11-does-gasoline-explain-the-inflation-difference-between-us-and-euro/index.html",
    "href": "posts/2021-11-11-does-gasoline-explain-the-inflation-difference-between-us-and-euro/index.html",
    "title": "Does gasoline explain the inflation difference between US and Euro?",
    "section": "",
    "text": "I read the tweet by Paul Krugman on the inflation difference between US and Euro. Why is the US inflation is now 2 percent higher than Euro? He thinks the difference can be explained by gasoline.\nSo I have done a rough calculation. To my surprise, my calculation does not support his claim. Excluding gasoline does not shrink the difference. My choice of “gasoline” might not be appropriate, or my use of the fixed component share might be a problem. I will wait for validation by someone.\nP.S. Paul Krugman’s blog post on November 12, 2021 seems to have validated my calculation."
  },
  {
    "objectID": "posts/2021-11-17-is-a-subsidy-to-gasoline-wholesaler-effective/index.html",
    "href": "posts/2021-11-17-is-a-subsidy-to-gasoline-wholesaler-effective/index.html",
    "title": "Is a subsidy to gasoline wholesaler effective?",
    "section": "",
    "text": "Nikkei reported on November 17, 2021 that Ministry of Economy, Trade and Industry (METI) is considering a subsidy to gasoline wholesalers to suppress gasoline retail prices when they rise to higher than 170 yen per litre.\nNikkei showed a skeptical view saying, “As the number of retailers has decreased, the retailers may not reduce retail prices even if wholesale prices fall.”\nSo I study retail and wholesale gasoline prices in Japan using the data from Agency for National Resources Energy.\nDifferences between retail and wholesale prices have been increasing since 2016. The mean difference was 12 yen per litre from 2000 July to 2015 December, and is 18 in 2021 September. This may reflect the reduced competition among retailers.\nIf the gasoline market is completely competitive, the proposed subsidy makes sense. However, the wholesaler market is dominated by the Big 3, who have also some influence on the retailers under their brands. When the proposed subsidy is enacted, they might be incentivized to raise prices. I will continue to watch."
  },
  {
    "objectID": "posts/2022-02-13-must-fiscal-stimulus-aim-to-enhance-long-term-economic-growth/index.html",
    "href": "posts/2022-02-13-must-fiscal-stimulus-aim-to-enhance-long-term-economic-growth/index.html",
    "title": "Must fiscal stimulus aim to enhance long term economic growth?",
    "section": "",
    "text": "Prof Masahiro Hori at Hitotsubashi University published an article titled “The effects of public spending on economy has been decreasing” (Japanese) in “Lecture on Economics” in Nikkei news paper on February 11, 2022.\nHe states that considering budget constraints, fiscal stimulus can be justified only if it also enhance long term economic growth path. As this article is the second in the series on government expenditures to enhance productivity, he writes those expenditures may be investment in R&D and education at the last paragraph very briefly. So I guess he basically denies economic stabilization policy by public works, tax cuts, and money filled bottles buried in disused coalmines proposed by Keynes.\nHe also states that orthodox economists believe in budget constraints, though MMTers don’t. I strongly disagree. When we are in the liquidity trap, and real government bond yield rates are negative, the market is requesting the government to spend more. Orthodox economists including me ignore budget constraints in such a situation.\nThe purpose of economic stabilization policy by fiscal stimulus is full employment. Period. If some spending in fiscal stimulus also enhances productivity in the long term, we are lucky, as most economists, including Prof Hori and me, don’t know which spending will lead to enhanced productivity."
  },
  {
    "objectID": "posts/2022-02-15-what-is-your-specialty-prof-kobayashi/index.html",
    "href": "posts/2022-02-15-what-is-your-specialty-prof-kobayashi/index.html",
    "title": "What is your specialty, Prof Kobayashi?",
    "section": "",
    "text": "Dear Prof Keiichiro Kobayashi of Keio University,\nI have read an article titled “Government and people should be equal partners in policy making” (Japanese) in “Economics Trend” in Nikkei news paper on February 15, 2022.\nYou draw a recursive diagram, which I think shows Keynes’s “beauty contest”, and surprise me by calling it “economics of rational expectations theory.” I think Keynes’s “beauty contest” may destroy “efficient market hypothesis” and can’t be a part of “rational expectation theory.” You also draw a recursive diagram which I think shows “observer effect”, and surprise me by calling it “quantum mechanics.” Next you state the progress of rational expectation theory over Keynesian economics can be compared to the leap of quantum mechanics over classical physics. This statement doesn’t make any sense.\nIn the middle of your article, you write government and people are equally intellectual. I know this is an assumption of “rational expectations theory.” You also attack paternalism by government. I know you belong to Chicago school.\nNext you state that such government officials fail to achieve policy goals, as they underestimate intellectual levels of people, and don’t seriously consider how people will react to the enacted policy. Wait. If you assert only Chicago school can say “Policy makers fail, when they don’t consider how people will react,” you are wrong. It is a common sense that policy makers should consider reaction by people, regardless of whether it is rational or not.\nNext you list the government handling of banks which hold vast amount of bad loans in 1990s as an example of failures to consider people reaction. I agree that paternalism of the Ministry of Finance towards banks led to corruption and lax regulation, which made dubious loans ballooning. After the bubble burst, however, I don’t think the government could have move more quickly, if it had regarded population’s voices more intellectual, as population then strongly opposed to the public money usage to rescue the banking system, which was the first necessary step to distinguish good and bad loans.\nFinally, you list restraints in Covid-19 testing as another example of policy failures. Maybe, as true positives can receive effective treatment earlier. Maybe not, due to social costs from false positives and false negatives, and capacity constraints of hospitals. Either way, you had better admit that you don’t have any specialty in this field."
  },
  {
    "objectID": "posts/2022-10-17-crowd-out-by-zero-interest-rate/index.html",
    "href": "posts/2022-10-17-crowd-out-by-zero-interest-rate/index.html",
    "title": "Crowd out by zero interest rate?",
    "section": "",
    "text": "Prof Keiichiro Kobayashi of Keio University mentioned an article he co-authored with Prof Kozo Ueda of Waseda University in his “Lecture on Economics” in Nikkei news paper on October 12, 2022 (Japanese).\nI briefly read “Secular Stagnation and Low Interest Rates under the Fear of a Government Debt Crisis” by Keiichiro Kobayashi and Kozo Ueda, Journal of Money, Credit and Banking, Volume 54, Issue 4, June 2022. The authors build a model, and assert that a government debt crisis, which surely happens at some point with increasing probability as time goes, causes persistent economic slowdown in normal times.\nTheir basic logic, in my understanding, proceeds as follows.\n\nThe Japanese government will avoid default on government bond by levying heavy tax on capital stock, when a crisis happens.\nPeople know that. So, government bond yield can be zero, as is currently observed.\nRequired rate of capital increases, as people expect capital will lose value in a crisis.\nHigher required rate of capital reduces productive capital investment, and the economy stagnates.\n\nIf the cause is an earthquake crisis, I would have agreed with them. However, when the cause is a government debt crisis, I can’t agree. The difference between an earthquake crisis and a government debt crisis is whether capital loses value or not. Capital will be physically damaged and lose value in an earthquake crisis, while capital with heavy tax burden will lose value for investors but create value for the government, so not lose value in a total society in a government debt crisis.\nHow can zero yield of government bond crowd out capital investment in their model? It turns out there is a hidden and unrealistic assumption. They assume people can’t take leverage to finance capital investment. If we assume people can take leverage, their logic 3 is wrong. When people can borrow government bonds from bond holders, sell them, and buy capital goods, they can invest in projects whose yield is higher than zero yield of government bonds. In other words, required rate of capital does not increase.\nIf the government is expected to nationalize some of capital assets, so that return for investors will be negative when a sure-to-come crisis happens, investors can’t invest in any projects. If the authors mean a revolution of this kind when they say a government debt crisis in their model, it is hard to imagine government bond yield stays at zero, while people know regime change is coming."
  },
  {
    "objectID": "posts/2023-06-15-migrated-to-quarto/index.html",
    "href": "posts/2023-06-15-migrated-to-quarto/index.html",
    "title": "Migrated to Quarto",
    "section": "",
    "text": "Today, I migrated from Blogdown/Hugo to Quarto. I basically followed an article by Art Steinmetz in r-bloggers. Thank you, Art.\nWhat pushed me for migration was code-fold and code-tools options. To echo, or not to echo, that is no longer a question. Great! I added the lines below to _metadata.yml in posts.\ncode-fold: true\ncode-tools: true\n\nfig-width: 6\nfig-height: 3.708\nI also added the lines below to yaml header of each post which includes figures to make figures look consistent.\nknitr: \n  opts_chunk: \n    out.width: '70%'\nIt took me four days to migrate my 13 Rmd posts and 77 md posts. md posts were easy: just delete tags: and slug: lines. Rmd posts were hard, as I changed them into qmd and re-rendered. I also added ‘fig-’ and ‘tbl-’ prefix to figure and table label. I believe migration was the right choice, as Quarto is the future."
  }
]